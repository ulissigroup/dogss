{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext ipycache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# sys.path.insert(0,'/home/junwoony/.local/lib/python3.6/site-packages')\n",
    "# sys.path.insert(0,'/home/zulissi/software/adamwr')\n",
    "import numpy as np\n",
    "#Select which GPU to use if necessary\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "import mongo\n",
    "# from torchviz import make_dot, make_dot_from_trace\n",
    "import time\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import pickle\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mongo\n",
    "# from cgcnn.data_icgcnn import StructureData, ListDataset, StructureDataTransformer\n",
    "from cgcnn.data_grad_surface2_orbital import StructureData, ListDataset, StructureDataTransformer, collate_pool, MergeDataset\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "import multiprocess as mp\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDT_training = pickle.load(open('./surface_orbital/SDT_training.pkl', 'rb'))\n",
    "SDT_test = pickle.load(open('./surface_orbital/SDT_test.pkl', 'rb'))\n",
    "target_training = pickle.load(open('./surface_orbital/target_training.pkl', 'rb'))\n",
    "target_test = pickle.load(open('./surface_orbital/target_test.pkl', 'rb'))\n",
    "docs_train = pickle.load(open('./surface_orbital/docs_train.pkl', 'rb'))\n",
    "docs_test = pickle.load(open('./surface_orbital/docs_test.pkl', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "structures = SDT_training[0]\n",
    "orig_atom_fea_len = structures[0].shape[-1]\n",
    "nbr_fea_len = structures[1].shape[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2952"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = pickle.load(open('docs_surface.pkl', 'rb'))\n",
    "\n",
    "for doc in docs:\n",
    "    doc[\"atoms\"] = doc['thinnest_structure']['atoms']\n",
    "    doc[\"results\"] = doc['thinnest_structure']['results']\n",
    "    doc[\"initial_configuration\"] = doc['thinnest_structure']['initial_configuration']\n",
    "    del doc[\"thinnest_structure\"]\n",
    "    \n",
    "docs = [doc for doc in docs if 'N' not in doc['atoms']['chemical_symbols'] #no nitrides\n",
    "                               and 'C' not in doc['atoms']['chemical_symbols'] #no carbides\n",
    "                               and 'S' not in doc['atoms']['chemical_symbols'] #no sulfides\n",
    "                               and 'Se' not in doc['atoms']['chemical_symbols'] #no selenides\n",
    "                               and 'P' not in doc['atoms']['chemical_symbols'] #no selenides\n",
    "                               and 'H' not in doc['atoms']['chemical_symbols']]\n",
    "print(len(docs))\n",
    "\n",
    "new_docs = []\n",
    "atom_types = []\n",
    "for idx, doc in enumerate(docs):\n",
    "    if np.max(doc['results']['forces']) < 0.05 and len(np.where(doc['distances_per_step'] == 0)[0]) == 1:\n",
    "        new_docs.append(doc)\n",
    "    else:\n",
    "        atoms = doc['atoms']['chemical_symbols']\n",
    "        atom_types.extend(atoms)\n",
    "\n",
    "\n",
    "len(new_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = {}\n",
    "for doc in docs:\n",
    "    for element in doc['atoms']['chemical_symbols']:\n",
    "        if element in symbols:\n",
    "            symbols[element] += 1\n",
    "        else:\n",
    "            symbols[element] = 1\n",
    "            \n",
    "sorted_list = sorted(symbols, key=symbols.get, reverse=True)\n",
    "sorted_symbols = {}\n",
    "for element in sorted_list:\n",
    "    sorted_symbols[element] = symbols[element]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Al': 559,\n",
       " 'Cu': 452,\n",
       " 'Si': 440,\n",
       " 'Pt': 437,\n",
       " 'Ca': 358,\n",
       " 'Sb': 328,\n",
       " 'Au': 295,\n",
       " 'As': 269,\n",
       " 'Pd': 264,\n",
       " 'Ga': 262,\n",
       " 'Ni': 255,\n",
       " 'Rh': 246,\n",
       " 'Sn': 235,\n",
       " 'Fe': 209,\n",
       " 'Ge': 198,\n",
       " 'Co': 195,\n",
       " 'Zn': 176,\n",
       " 'Ti': 166,\n",
       " 'In': 145,\n",
       " 'Ir': 126,\n",
       " 'V': 121,\n",
       " 'W': 105,\n",
       " 'Ru': 102,\n",
       " 'Ag': 92,\n",
       " 'Os': 77,\n",
       " 'Nb': 77,\n",
       " 'Mn': 75,\n",
       " 'Mo': 67,\n",
       " 'Pb': 63,\n",
       " 'Na': 57,\n",
       " 'Re': 36,\n",
       " 'Cr': 25}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s1', 's2', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'd10', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14']\n"
     ]
    }
   ],
   "source": [
    "orbitals = []\n",
    "for i in range(1,3):\n",
    "    orbitals.append('s%d' %i)\n",
    "for i in range(1,7):\n",
    "    orbitals.append('p%d' %i)\n",
    "for i in range(1,11):\n",
    "    orbitals.append('d%d' %i)\n",
    "for i in range(1,15):\n",
    "    orbitals.append('f%d' %i)\n",
    "print(orbitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = {'Al':['s2','p1'], 'Cu':['s1','d10'], 'Si':['s2','p2'], 'Pt':['s1','d9','f14'], 'Ca': ['s2'], 'Sb':['s2','p3','d10'],\n",
    "'Au': ['s1','f14','d10'], 'As':['s2','d10','p3'], 'Pd':['d10'], 'Ga':['s2','p1','d10'], 'Ni':['s2','d8'],\n",
    "'Rh':['s1','d8'], 'Sn':['s2','d10','p2'], 'Fe':['s2','d6'], 'Ge':['s2','d10','p2'], 'Co':['s2','d7'], 'Zn':['s2','d10'],\n",
    " 'Ti':['s2','d2'], 'In':['s2','d10','p1'], 'Ir':['s2','f14','d7'], 'V':['s2','d3'], 'W':['s2','f14','d4'], 'Ru':['s1','d7'],\n",
    " 'Ag':['s1','d10'], 'Os':['s2','f14','d6'], 'Nb':['s1','d4'], 'Mn':['s2','d5'], 'Mo':['s1','d5'], 'Pb':['s2','f14','d10','p2'],\n",
    " 'Na':['s1'], 'Re':['s2','f14','d5'], 'Cr':['s1','d5']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms = mongo.make_atoms_from_doc(docs[0], is_initial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orbital_fea = []\n",
    "for element in atoms.get_chemical_symbols():\n",
    "    base = np.zeros(len(orbitals), dtype = int)\n",
    "    for orb in symbols[element]:\n",
    "        idx = orbitals.index(orb)\n",
    "        base[idx] = 1\n",
    "    orbital_fea.append(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_docs(docs):\n",
    "    nbr_check = []\n",
    "    nbr_check_final = []\n",
    "    filtered_docs = []\n",
    "    differences = []\n",
    "    num_atoms = []\n",
    "    num_free_atoms = []\n",
    "    for doc in tqdm.tqdm(docs):\n",
    "        nbr_check_doc = []\n",
    "        nbr_check_doc_final = []\n",
    "        radius = 7\n",
    "        max_num_nbr = 12\n",
    "        min_free_atom = 1\n",
    "\n",
    "        atoms = mongo.make_atoms_from_doc(doc['initial_configuration'])\n",
    "        crystal = AseAtomsAdaptor.get_structure(atoms)\n",
    "        atoms_final = mongo.make_atoms_from_doc(doc)\n",
    "    #     crystal_final = AseAtomsAdaptor.get_structure(atoms_final)\n",
    "\n",
    "        fixed_atom_idx = atoms.constraints[0].index\n",
    "        base = np.ones(len(atoms.positions))\n",
    "        base[fixed_atom_idx] = 0\n",
    "        free_atom_idx = np.where(base==1)[0]\n",
    "\n",
    "        difference = atoms.positions[free_atom_idx] - atoms_final.positions[free_atom_idx]\n",
    "        differences.append(difference)\n",
    "\n",
    "        all_nbrs = crystal.get_all_neighbors(radius, include_index=True)\n",
    "        all_nbrs = [sorted(nbrs, key=lambda x: x[1]) for nbrs in all_nbrs]\n",
    "\n",
    "    #     all_nbrs_final = crystal_final.get_all_neighbors(radius, include_index=True, include_image=True)\n",
    "    #     all_nbrs_final = [sorted(nbrs_final, key=lambda x: x[1]) for nbrs_final in all_nbrs_final]\n",
    "\n",
    "    #     assert len(all_nbrs) == len(all_nbrs_final)\n",
    "\n",
    "        for i in range(len(all_nbrs)):\n",
    "            nbr_check.append(len(all_nbrs[i]))\n",
    "            nbr_check_doc.append(len(all_nbrs[i]))\n",
    "    #         nbr_check_final.append(len(all_nbrs_final[i]))\n",
    "    #         nbr_check_doc_final.append(len(all_nbrs_final[i]))\n",
    "\n",
    "        if np.min(nbr_check_doc) >= max_num_nbr and 0.01 < np.max(np.abs(difference)) < 0.5 \\\n",
    "        and len(free_atom_idx) >= min_free_atom:\n",
    "            filtered_docs.append(doc)\n",
    "            num_atoms.append(len(atoms.positions))\n",
    "            num_free_atoms.append(len(free_atom_idx))\n",
    "            \n",
    "    return filtered_docs, num_atoms, num_free_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2952/2952 [00:35<00:00, 82.41it/s] \n"
     ]
    }
   ],
   "source": [
    "filtered_docs, num_atoms, num_free_atoms = filter_docs(new_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2455/2455 [00:20<00:00, 118.47it/s]\n"
     ]
    }
   ],
   "source": [
    "SDT = StructureDataTransformer(atom_init_loc='atom_init.json',\n",
    "                              max_num_nbr=12,\n",
    "                               step=0.4,\n",
    "                              radius=7,\n",
    "                              use_tag=False,\n",
    "                              use_fixed_info=True,\n",
    "                              is_initial=True,\n",
    "                              use_distance=False,\n",
    "                              bond_property=True,\n",
    "                               orbitals = orbitals,\n",
    "                               symbols = symbols\n",
    "                              )\n",
    "\n",
    "SDT_out = SDT.transform(filtered_docs)\n",
    "structures = SDT_out[0]\n",
    "\n",
    "#Settings necessary to build the model (since they are size of vectors as inputs)\n",
    "orig_atom_fea_len = structures[0].shape[-1]\n",
    "nbr_fea_len = structures[1].shape[-1]\n",
    "\n",
    "with mp.Pool(4) as pool:\n",
    "    SDT_list = list(tqdm.tqdm(pool.imap(lambda x: SDT_out[x],range(len(SDT_out)),chunksize=40),total=len(SDT_out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(SDT_list, open('../../cgcnn_Geometric_pos/SDT_list_surface.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (atom_fea, nbr_fea, nbr_fea_idx, nbr_fea_offset, atom_pos, nbr_pos, atom_pos_idx, cells, fixed_atom_idx, atom_pos_final)\n",
    "atom_fea = SDT_list[0][0]\n",
    "nbr_fea = SDT_list[0][1]\n",
    "nbr_fea_idx = SDT_list[0][2]\n",
    "nbr_fea_offset = SDT_list[0][3]\n",
    "atom_pos =SDT_list[0][4]\n",
    "nbr_pos = SDT_list[0][5] \n",
    "atom_pos_idx = SDT_list[0][6]\n",
    "cells = SDT_list[0][7]\n",
    "fixed_atom_idx = SDT_list[0][8]\n",
    "free_atom_idx = SDT_list[0][9]\n",
    "atom_pos_final = SDT_list[0][10]\n",
    "# atom_pos_final_free = SDT_list[0][11]\n",
    "target_list = np.array([sdt[-1].numpy() for sdt in SDT_list]).reshape(-1,1) #get final_pos of free atoms ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SDT_list= SDT_list\n",
    "target_list = target_list\n",
    "\n",
    "indices = np.arange(len(SDT_list))\n",
    "SDT_training, SDT_test, target_training, target_test, docs_train, docs_test \\\n",
    "= train_test_split(SDT_list, target_list, filtered_docs, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(docs_train, open('./surface_orbital/docs_train.pkl', 'wb'))\n",
    "pickle.dump(docs_test, open('./surface_orbital/docs_test.pkl', 'wb'))\n",
    "pickle.dump(SDT_training, open('./surface_orbital/SDT_training.pkl', 'wb'))\n",
    "pickle.dump(SDT_test, open('./surface_orbital/SDT_test.pkl', 'wb'))\n",
    "pickle.dump(target_training, open('./surface_orbital/target_training.pkl', 'wb'))\n",
    "pickle.dump(target_test, open('./surface_orbital/target_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from skorch.callbacks import Checkpoint, LoadInitState #needs skorch 0.4.0, conda-forge version at 0.3.0 doesn't cut it\n",
    "\n",
    "from cgcnn.model_grad_simple import CrystalGraphConvNet\n",
    "from skorch import NeuralNetRegressor\n",
    "import torch\n",
    "import skorch.callbacks.base\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device='cpu'\n",
    "\n",
    "#Make a checkpoint to save parameters every time there is a new best for validation lost\n",
    "cp = Checkpoint(monitor='valid_loss_best',fn_prefix='./surface_orbital/valid_best_')\n",
    "\n",
    "#Callback to load the checkpoint with the best validation loss at the end of training\n",
    "\n",
    "class train_end_load_best_valid_loss(skorch.callbacks.base.Callback):\n",
    "    def on_train_end(self, net, X, y):\n",
    "        net.load_params('./surface_orbital/valid_best_params.pt')\n",
    "        \n",
    "load_best_valid_loss = train_end_load_best_valid_loss()\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12837468"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def diff(sdt, target):\n",
    "#     free_atom_idx = list(set(list(range(len(target[0]))))-set(sdt[-2].numpy()))\n",
    "    fixed_base = np.zeros((sdt[0].shape[0], 1))\n",
    "    fixed_base[sdt[8]] = 1\n",
    "    free_atom_idx = np.where(fixed_base == 0)[0]\n",
    "    free_atom_idx = torch.LongTensor(free_atom_idx)   \n",
    "    diff = np.sum(((target[0] - sdt[4].numpy())[free_atom_idx])**2.,axis=1)**0.5 \n",
    "    return diff\n",
    "\n",
    "# def diff(sdt, target):\n",
    "# #     free_atom_idx = list(set(list(range(len(target[0]))))-set(sdt[-2].numpy()))\n",
    "#     fixed_base = np.zeros((sdt[0].shape[0], 1))\n",
    "#     fixed_base[sdt[5]] = 1\n",
    "#     free_atom_idx = np.where(fixed_base == 0)[0]\n",
    "#     free_atom_idx = torch.LongTensor(free_atom_idx)\n",
    "\n",
    "#     diff = np.sum(((target[0] - sdt[3].numpy())[free_atom_idx].reshape(-1,3))**2.,axis=1)**0.5 \n",
    "#     return diff\n",
    "\n",
    "np.mean(np.abs(np.concatenate([diff(sdt, target) for sdt,target in zip(SDT_training, target_training)])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skorch.dataset import CVSplit\n",
    "from skorch.callbacks.lr_scheduler import WarmRestartLR, LRScheduler\n",
    "from adamwr.adamw import AdamW\n",
    "from torch.optim.lbfgs import LBFGS\n",
    "\n",
    "from adamwr.cosine_scheduler import CosineLRWithRestarts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_test_splitter = ShuffleSplit(test_size=0.1, random_state=42)\n",
    "\n",
    "batchsize = 48\n",
    "# warm restart scheduling from https://arxiv.org/pdf/1711.05101.pdf\n",
    "LR_schedule = LRScheduler(CosineLRWithRestarts, batch_size=batchsize, epoch_size=len(SDT_training), restart_period=10, t_mult=1.2)\n",
    "\n",
    "#############\n",
    "# To extract intermediate features, set the forward takes only the first return value to calculate loss\n",
    "class MyNet(NeuralNetRegressor):\n",
    "    def get_loss(self, y_pred, y_true, **kwargs):        \n",
    "        y_pred = y_pred[0] if isinstance(y_pred, tuple) else y_pred  # discard the 2nd output\n",
    "        differ=torch.sum((y_pred-y_true.cuda())**2.0,dim=1)\n",
    "        if torch.nonzero(differ).shape[0] != differ.shape[0]:\n",
    "            print('zero sqrt for Loss')\n",
    "#             zero_idx = (differ == 0).nonzero()\n",
    "#             differ[zero_idx] = 1e-6\n",
    "        differ = torch.clamp(differ, min=1e-8)\n",
    "\n",
    "        return torch.mean(torch.sqrt(differ))\n",
    "#         return torch.mean(torch.sqrt(torch.sum((y_pred-y_true.cuda())**2.0,dim=1)))\n",
    "#         return super().get_loss(y_pred, y_true, **kwargs)\n",
    "## return features = net.forward(SDT_test)\n",
    "\n",
    "\n",
    "# nbr_fea_len = SDT_list[0][9].shape[-1]\n",
    "\n",
    "\n",
    "net = MyNet(\n",
    "    CrystalGraphConvNet,\n",
    "    module__orig_atom_fea_len = orig_atom_fea_len,\n",
    "    module__nbr_fea_len = nbr_fea_len,\n",
    "#     module__angle_fea_len = 8, #angle_fea_len,\n",
    "    batch_size=batchsize, #214\n",
    "    module__classification=False,\n",
    "    lr=0.0056,\n",
    "    max_epochs= 2000,\n",
    "    module__radius = 7,\n",
    "    module__step_size = 0.4,\n",
    "    module__atom_fea_len=62, #46,\n",
    "    module__h_fea_len=83, #83\n",
    "    module__n_conv=6, #8\n",
    "    module__n_h=8,\n",
    "    module__max_num_nbr=12, #9\n",
    "    module__opt_step_size=0.3, #0.3\n",
    "    module__min_opt_steps=30,\n",
    "    module__max_opt_steps=300,\n",
    "    module__momentum=0.8,\n",
    "    module__dropout1=0.0,\n",
    "    module__dropout2=0.0,\n",
    "    module__dropout_dist=0.0,\n",
    "    module__dropout_const=0.0,\n",
    "#     module__steps=4,\n",
    "    optimizer__weight_decay=1e-3,\n",
    "    optimizer=AdamW,\n",
    "    iterator_train__pin_memory=True,\n",
    "    iterator_train__num_workers=0,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__collate_fn = collate_pool,\n",
    "    iterator_valid__pin_memory=True,\n",
    "    iterator_valid__num_workers=0,\n",
    "    iterator_valid__collate_fn = collate_pool,\n",
    "    device=device,\n",
    "#     criterion=torch.nn.MSELoss,\n",
    "    criterion=torch.nn.L1Loss,\n",
    "    dataset=MergeDataset,\n",
    "    train_split = CVSplit(cv=train_test_splitter),\n",
    "    callbacks=[cp, LR_schedule, load_best_valid_loss] #    callbacks=[cp, load_best_valid_loss, LR_schedule]\n",
    "\n",
    ")\n",
    "\n",
    "net.initialize()\n",
    "net.load_params(f_history = './surface_orbital/valid_best_history.json',\n",
    "               f_optimizer = './surface_orbital/valid_best_optimizer.pt',\n",
    "               f_params = './surface_orbital/valid_best_params.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "    247        0.0388        0.0715        99.8563\n",
      "    248        0.0421        0.0702        97.2901\n",
      "    249        0.0433        0.0690        100.0909\n",
      "    250        0.0425        0.0683        100.9409\n",
      "    251        0.0385        0.0675        97.9750\n",
      "    252        0.0363        0.0675        96.0473\n",
      "    253        0.0346        0.0667        103.8353\n",
      "    254        \u001b[36m0.0329\u001b[0m        0.0666        95.8008\n",
      "    255        \u001b[36m0.0304\u001b[0m        \u001b[32m0.0665\u001b[0m     +  97.3598\n",
      "    256        0.0309        \u001b[32m0.0663\u001b[0m     +  97.8730\n",
      "    257        0.0360        0.0703        99.0411\n",
      "    258        0.0416        0.0682        91.4773\n",
      "    259        0.0435        0.0726        90.5319\n",
      "    260        0.0409        0.0677        94.1155\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 1.64 GiB already allocated; 15.12 MiB free; 19.82 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f6af3f15f0d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0056\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSDT_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/skorch/net.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_train_begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/skorch/net.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0myi_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myi\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my_train_is_ph\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_batch_begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myi_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                 \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_batch_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/skorch/net.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, Xi, yi, **fit_params)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0mstep_accumulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_accumulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/adamwr/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/skorch/net.py\u001b[0m in \u001b[0;36mstep_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mstep_accumulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_step_accumulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m             \u001b[0mstep_accumulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/skorch/net.py\u001b[0m in \u001b[0;36mtrain_step_single\u001b[0;34m(self, Xi, yi, **fit_params)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/skorch/net.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, x, **fit_params)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_x_and_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/cgcnn/model_grad_simple.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, atom_fea, nbr_fea, nbr_fea_idx, nbr_fea_offset, crystal_atom_idx, atom_pos, nbr_pos, atom_pos_idx, cells, fixed_atom_mask, atom_pos_final)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mgrad_E\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbond_energy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#+ ((atom_pos - orig_atom_pos)**2).sum()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_E\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matom_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;31m#             grad = torch.clamp(grad, min=1e-4, max=8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    147\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.78 GiB total capacity; 1.64 GiB already allocated; 15.12 MiB free; 19.82 MiB cached)"
     ]
    }
   ],
   "source": [
    "net.module_.max_epochs=500\n",
    "net.module_.max_epochs = 0.0056 * 0.01\n",
    "net.partial_fit(SDT_training, target_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: atom_fea_len, classification, dropout1, dropout2, dropout_const, dropout_dist, h_fea_len, max_num_nbr, max_opt_steps, min_opt_steps, momentum, n_conv, n_h, nbr_fea_len, opt_step_size, orig_atom_fea_len, radius, step_size.\n",
      "Re-initializing optimizer because the following parameters were re-set: weight_decay.\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1        \u001b[36m0.1805\u001b[0m        \u001b[32m0.1283\u001b[0m     +  26.9694\n",
      "blow up\n",
      "blow up\n",
      "      2        \u001b[36m0.1187\u001b[0m        \u001b[32m0.1205\u001b[0m     +  27.0310\n",
      "blow up\n",
      "blow up\n",
      "      3        \u001b[36m0.1080\u001b[0m        \u001b[32m0.1173\u001b[0m     +  22.7122\n",
      "blow up\n",
      "      4        \u001b[36m0.1053\u001b[0m        \u001b[32m0.1123\u001b[0m     +  22.2148\n",
      "blow up\n",
      "      5        \u001b[36m0.1005\u001b[0m        \u001b[32m0.1107\u001b[0m     +  21.4569\n",
      "      6        0.1016        \u001b[32m0.1032\u001b[0m     +  21.0949\n",
      "      7        \u001b[36m0.0999\u001b[0m        \u001b[32m0.0991\u001b[0m     +  20.4045\n",
      "      8        0.1053        \u001b[32m0.0986\u001b[0m     +  20.0595\n",
      "      9        0.1077        0.1001        20.3625\n",
      "     10        \u001b[36m0.0947\u001b[0m        \u001b[32m0.0984\u001b[0m     +  20.6926\n",
      "     11        0.1025        0.0999        20.3461\n",
      "     12        0.1014        0.0996        19.7945\n",
      "     13        0.0996        \u001b[32m0.0968\u001b[0m     +  20.2666\n",
      "     14        0.0961        \u001b[32m0.0954\u001b[0m     +  18.3651\n",
      "     15        0.0957        0.0959        16.0531\n",
      "     16        \u001b[36m0.0894\u001b[0m        \u001b[32m0.0944\u001b[0m     +  19.8531\n",
      "     17        \u001b[36m0.0891\u001b[0m        \u001b[32m0.0928\u001b[0m     +  19.6795\n",
      "     18        0.0906        \u001b[32m0.0919\u001b[0m     +  19.4138\n",
      "     19        0.0948        \u001b[32m0.0910\u001b[0m     +  19.7377\n",
      "     20        \u001b[36m0.0883\u001b[0m        \u001b[32m0.0902\u001b[0m     +  19.3264\n",
      "     21        0.0884        \u001b[32m0.0898\u001b[0m     +  20.1725\n",
      "     22        \u001b[36m0.0871\u001b[0m        0.0899        20.0977\n",
      "     23        0.0893        0.0939        19.6364\n",
      "     24        0.0912        0.0954        17.7460\n",
      "     25        0.0899        0.0908        15.7367\n",
      "     26        0.0929        0.0941        14.1529\n",
      "     27        0.0957        \u001b[32m0.0875\u001b[0m     +  14.1717\n",
      "     28        0.0873        0.0879        14.1592\n",
      "     29        \u001b[36m0.0848\u001b[0m        \u001b[32m0.0865\u001b[0m     +  14.0137\n",
      "     30        \u001b[36m0.0846\u001b[0m        \u001b[32m0.0856\u001b[0m     +  14.7056\n",
      "     31        \u001b[36m0.0816\u001b[0m        \u001b[32m0.0842\u001b[0m     +  14.5606\n",
      "     32        \u001b[36m0.0807\u001b[0m        \u001b[32m0.0830\u001b[0m     +  14.8938\n",
      "     33        \u001b[36m0.0791\u001b[0m        \u001b[32m0.0821\u001b[0m     +  14.4735\n",
      "     34        \u001b[36m0.0761\u001b[0m        \u001b[32m0.0820\u001b[0m     +  14.9395\n",
      "     35        0.0791        \u001b[32m0.0812\u001b[0m     +  14.8457\n",
      "     36        0.0790        \u001b[32m0.0812\u001b[0m     +  15.0223\n",
      "     37        \u001b[36m0.0754\u001b[0m        0.0812        15.0102\n",
      "     38        0.0894        0.0894        15.5383\n",
      "     39        0.0885        0.0895        16.0452\n",
      "     40        0.0828        0.0881        14.8834\n",
      "     41        0.0823        0.0848        15.0193\n",
      "     42        0.0787        0.0853        15.0304\n",
      "     43        0.0777        0.0828        15.2970\n",
      "     44        0.0778        0.0817        15.1334\n",
      "     45        0.0777        \u001b[32m0.0810\u001b[0m     +  15.6907\n",
      "     46        0.0782        \u001b[32m0.0805\u001b[0m     +  15.5407\n",
      "     47        \u001b[36m0.0752\u001b[0m        \u001b[32m0.0804\u001b[0m     +  15.7798\n",
      "     48        \u001b[36m0.0704\u001b[0m        \u001b[32m0.0787\u001b[0m     +  15.0882\n",
      "     49        \u001b[36m0.0702\u001b[0m        0.0825        15.6833\n",
      "     50        \u001b[36m0.0691\u001b[0m        \u001b[32m0.0761\u001b[0m     +  15.5463\n",
      "     51        \u001b[36m0.0691\u001b[0m        \u001b[32m0.0757\u001b[0m     +  16.0475\n",
      "     52        \u001b[36m0.0679\u001b[0m        \u001b[32m0.0752\u001b[0m     +  16.2948\n",
      "     53        \u001b[36m0.0643\u001b[0m        0.0752        15.7478\n",
      "     54        0.0656        \u001b[32m0.0751\u001b[0m     +  16.3589\n",
      "     55        0.0687        0.0751        15.9668\n",
      "     56        0.0784        0.0849        16.1209\n",
      "     57        0.0787        0.0827        15.9629\n",
      "     58        0.0771        0.0846        16.6678\n",
      "     59        0.0735        0.0848        22.6865\n",
      "     60        0.0772        0.0828        23.1933\n",
      "     61        0.0733        0.0785        23.9160\n",
      "     62        0.0767        0.0784        21.7432\n",
      "     63        0.0717        0.0785        22.3767\n",
      "     64        0.0678        0.0768        23.1601\n",
      "     65        0.0691        0.0761        24.4580\n",
      "     66        0.0662        0.0766        23.4216\n",
      "     67        0.0690        \u001b[32m0.0743\u001b[0m     +  23.2813\n",
      "     68        \u001b[36m0.0637\u001b[0m        \u001b[32m0.0740\u001b[0m     +  24.4706\n",
      "     69        \u001b[36m0.0608\u001b[0m        \u001b[32m0.0728\u001b[0m     +  25.1531\n",
      "     70        0.0633        0.0731        23.7440\n",
      "     71        0.0611        \u001b[32m0.0716\u001b[0m     +  24.3749\n",
      "     72        \u001b[36m0.0603\u001b[0m        0.0719        25.0123\n",
      "     73        0.0624        0.0716        24.6266\n",
      "     74        \u001b[36m0.0589\u001b[0m        \u001b[32m0.0712\u001b[0m     +  24.9694\n",
      "     75        0.0602        0.0712        23.8605\n",
      "     76        \u001b[36m0.0540\u001b[0m        0.0713        24.2908\n",
      "     77        0.0755        0.0804        23.8857\n",
      "     78        0.0696        0.0774        22.9904\n",
      "     79        0.0739        0.0789        23.8470\n",
      "     80        0.0643        0.0795        23.7442\n",
      "     81        0.0704        0.0782        23.7445\n",
      "     82        0.0659        0.0746        23.6108\n",
      "     83        0.0659        0.0764        24.7575\n",
      "     84        0.0660        0.0749        24.0321\n",
      "     85        0.0653        0.0771        21.7130\n",
      "     86        0.0632        0.0735        20.2189\n",
      "     87        0.0617        0.0743        22.0383\n",
      "     88        0.0607        0.0713        19.2552\n",
      "     89        0.0590        0.0720        18.8417\n",
      "     90        0.0565        0.0715        18.4794\n",
      "     91        0.0576        0.0713        18.1409\n",
      "     92        0.0571        \u001b[32m0.0705\u001b[0m     +  18.1358\n",
      "     93        0.0544        \u001b[32m0.0696\u001b[0m     +  19.3788\n",
      "     94        0.0556        0.0704        19.0576\n",
      "     95        0.0549        \u001b[32m0.0695\u001b[0m     +  19.5660\n",
      "     96        0.0550        \u001b[32m0.0694\u001b[0m     +  18.8435\n",
      "     97        \u001b[36m0.0533\u001b[0m        0.0694        19.5066\n",
      "     98        \u001b[36m0.0501\u001b[0m        \u001b[32m0.0690\u001b[0m     +  19.0256\n",
      "     99        0.0517        0.0691        19.5156\n",
      "    100        0.0511        \u001b[32m0.0690\u001b[0m     +  19.5676\n",
      "    101        0.0513        0.0691        19.7172\n",
      "    102        0.0657        0.0774        18.5648\n",
      "    103        0.0652        0.0781        17.4448\n",
      "    104        0.0679        0.0763        18.0524\n",
      "    105        0.0632        0.0746        18.3570\n",
      "    106        0.0650        0.0731        19.3080\n",
      "    107        0.0615        0.0755        18.2774\n",
      "    108        0.0650        0.0735        19.4397\n",
      "    109        0.0605        0.0720        27.0056\n",
      "    110        0.0591        0.0729        19.9007\n",
      "    111        0.0597        0.0721        18.3530\n",
      "    112        0.0593        0.0716        24.0253\n",
      "    113        0.0562        0.0715        24.6936\n",
      "    114        0.0555        0.0719        19.4491\n",
      "    115        0.0549        0.0695        20.1529\n",
      "    116        0.0538        0.0702        27.0984\n",
      "    117        0.0535        0.0709        26.7318\n",
      "    118        0.0514        0.0693        28.1159\n",
      "    119        0.0523        0.0706        28.2307\n",
      "    120        \u001b[36m0.0501\u001b[0m        \u001b[32m0.0689\u001b[0m     +  25.8969\n",
      "    121        \u001b[36m0.0491\u001b[0m        \u001b[32m0.0687\u001b[0m     +  21.2892\n",
      "    122        \u001b[36m0.0477\u001b[0m        \u001b[32m0.0682\u001b[0m     +  21.4893\n",
      "    123        \u001b[36m0.0463\u001b[0m        0.0685        25.7178\n",
      "    124        0.0482        0.0683        29.0330\n",
      "    125        0.0465        0.0683        29.2106\n",
      "    126        \u001b[36m0.0459\u001b[0m        0.0682        29.4037\n",
      "    127        0.0491        \u001b[32m0.0680\u001b[0m     +  26.5631\n",
      "    128        \u001b[36m0.0442\u001b[0m        \u001b[32m0.0680\u001b[0m     +  25.4994\n",
      "    129        0.0449        0.0680        21.2806\n",
      "    130        0.0448        \u001b[32m0.0679\u001b[0m     +  19.8287\n",
      "    131        \u001b[36m0.0430\u001b[0m        0.0679        20.7086\n",
      "    132        0.0603        0.0751        19.2778\n",
      "    133        0.0607        0.0764        18.7316\n",
      "    134        0.0548        0.0734        19.5307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    135        0.0566        0.0736        19.7884\n",
      "    136        0.0574        0.0745        23.6744\n",
      "    137        0.0561        0.0706        29.7166\n",
      "    138        0.0571        0.0715        28.1629\n",
      "    139        0.0549        0.0703        28.6109\n",
      "    140        0.0544        0.0704        28.9503\n",
      "    141        0.0521        0.0708        25.9643\n",
      "    142        0.0536        0.0701        28.5881\n",
      "    143        0.0521        0.0694        26.2120\n",
      "    144        0.0512        0.0687        20.7219\n",
      "    145        0.0522        0.0703        19.7607\n",
      "    146        0.0493        0.0694        20.3011\n",
      "    147        0.0490        0.0688        20.4489\n",
      "    148        0.0496        0.0690        20.3999\n",
      "    149        0.0490        0.0701        20.6116\n",
      "    150        0.0464        0.0701        20.3715\n",
      "    151        0.0435        0.0681        20.8919\n",
      "    152        0.0450        0.0693        23.3634\n",
      "    153        0.0432        0.0681        30.4100\n",
      "    154        0.0454        0.0682        30.4606\n",
      "    155        \u001b[36m0.0405\u001b[0m        0.0684        29.4156\n",
      "    156        0.0441        0.0683        29.7357\n",
      "    157        0.0409        0.0681        29.0628\n",
      "    158        0.0429        0.0679        28.4544\n",
      "    159        0.0413        0.0681        22.8447\n",
      "    160        0.0435        0.0679        20.4761\n",
      "    161        \u001b[36m0.0405\u001b[0m        \u001b[32m0.0677\u001b[0m     +  20.5268\n",
      "    162        \u001b[36m0.0400\u001b[0m        0.0680        21.2106\n",
      "    163        0.0419        0.0679        21.0322\n",
      "    164        \u001b[36m0.0368\u001b[0m        0.0677        20.9863\n",
      "    165        0.0412        \u001b[32m0.0677\u001b[0m     +  20.7693\n",
      "    166        0.0389        0.0677        27.2940\n",
      "    167        0.0392        0.0677        30.2208\n",
      "    168        0.0495        0.0760        28.5933\n",
      "    169        0.0567        0.0740        28.7378\n",
      "    170        0.0547        0.0709        28.7995\n",
      "    171        0.0557        0.0736        29.2897\n",
      "    172        0.0509        0.0716        24.2417\n",
      "    173        0.0498        0.0707        21.7133\n",
      "    174        0.0517        0.0706        19.5874\n",
      "    175        0.0512        0.0712        20.0385\n",
      "    176        0.0529        0.0702        20.0068\n",
      "    177        0.0493        0.0694        20.1617\n",
      "    178        0.0469        0.0726        20.9714\n",
      "    179        0.0483        0.0687        19.8217\n",
      "    180        0.0488        0.0708        22.4366\n",
      "    181        0.0482        0.0689        29.4177\n",
      "    182        0.0469        0.0700        29.8556\n",
      "    183        0.0482        0.0687        31.0979\n",
      "    184        0.0452        0.0681        29.9857\n",
      "    185        0.0461        0.0683        29.9840\n",
      "    186        0.0444        0.0688        29.8181\n",
      "    187        0.0435        0.0680        22.6343\n",
      "    188        0.0472        0.0685        20.6034\n",
      "    189        0.0431        0.0697        20.3828\n",
      "    190        0.0409        0.0679        21.0482\n",
      "    191        0.0404        \u001b[32m0.0672\u001b[0m     +  20.9820\n",
      "    192        0.0404        0.0672        21.5798\n",
      "    193        0.0416        \u001b[32m0.0670\u001b[0m     +  21.3823\n",
      "    194        0.0390        0.0672        25.7623\n",
      "    195        0.0384        0.0677        32.1654\n",
      "    196        0.0387        0.0678        30.5352\n",
      "    197        0.0372        0.0674        29.8945\n",
      "    198        0.0381        \u001b[32m0.0669\u001b[0m     +  30.2295\n",
      "    199        \u001b[36m0.0354\u001b[0m        0.0673        30.7053\n",
      "    200        \u001b[36m0.0352\u001b[0m        0.0670        29.0818\n",
      "    201        \u001b[36m0.0351\u001b[0m        \u001b[32m0.0667\u001b[0m     +  22.9105\n",
      "    202        0.0359        0.0670        21.3643\n",
      "    203        \u001b[36m0.0332\u001b[0m        0.0668        21.5185\n",
      "    204        0.0340        \u001b[32m0.0667\u001b[0m     +  21.9904\n",
      "    205        0.0348        0.0668        21.3299\n",
      "    206        0.0348        0.0669        22.1950\n",
      "    207        0.0347        0.0668        23.2553\n",
      "    208        0.0348        \u001b[32m0.0667\u001b[0m     +  32.0738\n",
      "    209        0.0343        0.0669        32.4739\n",
      "    210        0.0360        0.0668        31.3534\n",
      "    211        0.0467        0.0719        31.1910\n",
      "    212        0.0489        0.0730        28.6525\n",
      "    213        0.0470        0.0690        29.4042\n",
      "    214        0.0478        0.0704        24.6307\n",
      "    215        0.0495        0.0700        20.3742\n",
      "    216        0.0470        0.0699        21.2454\n",
      "    217        0.0463        0.0703        21.2557\n",
      "    218        0.0465        0.0690        21.2843\n",
      "    219        0.0468        0.0697        20.7697\n",
      "    220        0.0453        0.0699        22.6676\n",
      "    221        0.0433        0.0706        24.8536\n",
      "    222        0.0456        0.0695        30.0442\n",
      "    223        0.0443        0.0697        29.5380\n",
      "    224        0.0446        0.0688        30.3927\n",
      "    225        0.0438        0.0681        29.8496\n",
      "    226        0.0440        0.0683        30.7522\n",
      "    227        0.0417        0.0677        31.4943\n",
      "    228        0.0422        0.0679        28.5620\n",
      "    229        0.0414        0.0697        34.5212\n",
      "    230        0.0423        0.0675        29.5255\n",
      "    231        0.0400        0.0699        22.7343\n",
      "    232        0.0424        0.0692        21.7586\n",
      "    233        0.0401        0.0682        25.3866\n",
      "    234        0.0388        0.0688        26.5150\n",
      "    235        0.0382        0.0683        27.1253\n",
      "    236        0.0388        0.0674        25.9426\n",
      "    237        0.0369        0.0677        30.5251\n",
      "    238        0.0385        0.0673        37.2787\n",
      "    239        0.0353        0.0678        37.2861\n",
      "    240        0.0385        0.0673        38.2452\n",
      "    241        0.0350        0.0671        35.3478\n",
      "    242        0.0355        0.0675        37.1154\n",
      "    243        0.0347        0.0671        41.6266\n",
      "    244        0.0341        0.0678        38.6444\n",
      "    245        0.0352        0.0667        37.2396\n",
      "    246        0.0333        \u001b[32m0.0665\u001b[0m     +  40.5978\n",
      "    247        0.0336        0.0669        30.9930\n",
      "    248        \u001b[36m0.0326\u001b[0m        0.0670        26.1588\n",
      "    249        \u001b[36m0.0324\u001b[0m        0.0666        23.9471\n",
      "    250        0.0324        0.0671        24.5096\n",
      "    251        \u001b[36m0.0316\u001b[0m        0.0667        22.9228\n",
      "    252        \u001b[36m0.0310\u001b[0m        0.0669        24.6000\n",
      "    253        \u001b[36m0.0307\u001b[0m        0.0669        24.0746\n",
      "    254        \u001b[36m0.0293\u001b[0m        0.0666        24.1181\n",
      "    255        0.0313        0.0666        23.6178\n",
      "    256        0.0317        0.0668        23.0376\n",
      "    257        0.0300        0.0667        23.1425\n",
      "    258        0.0303        0.0666        32.3833\n",
      "    259        0.0304        0.0665        31.8192\n",
      "    260        0.0296        0.0666        33.2188\n",
      "    261        0.0310        0.0667        32.0786\n",
      "    262        0.0297        0.0665        32.2156\n",
      "    263        0.0405        0.0724        32.4834\n",
      "    264        0.0461        0.0704        29.5427\n",
      "    265        0.0441        0.0700        30.3774\n",
      "    266        0.0452        0.0691        31.2049\n",
      "    267        0.0450        0.0698        25.6511\n",
      "    268        0.0443        0.0690        29.7554\n",
      "    269        0.0433        0.0683        30.5573\n",
      "    270        0.0457        0.0692        33.0054\n",
      "    271        0.0405        0.0695        29.5850\n",
      "    272        0.0416        0.0672        21.6526\n",
      "    273        0.0397        0.0694        22.2772\n",
      "    274        0.0412        0.0709        29.4239\n",
      "    275        0.0418        0.0686        48.7035\n",
      "    276        0.0408        0.0687        22.3909\n",
      "    277        0.0406        0.0691        22.9945\n",
      "    278        0.0383        0.0689        38.8617\n",
      "    279        0.0408        0.0687        22.0440\n",
      "    280        0.0397        0.0688        31.6924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class '__main__.MyNet'>[initialized](\n",
       "  module_=CrystalGraphConvNet(\n",
       "    (embedding): Linear(in_features=125, out_features=62, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0): ConvLayer(\n",
       "        (fc_full): Linear(in_features=143, out_features=124, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): LeakyReLU(negative_slope=0.01)\n",
       "        (bn1): BatchNorm1d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): ConvLayer(\n",
       "        (fc_full): Linear(in_features=143, out_features=124, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): LeakyReLU(negative_slope=0.01)\n",
       "        (bn1): BatchNorm1d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (2): ConvLayer(\n",
       "        (fc_full): Linear(in_features=143, out_features=124, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): LeakyReLU(negative_slope=0.01)\n",
       "        (bn1): BatchNorm1d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (3): ConvLayer(\n",
       "        (fc_full): Linear(in_features=143, out_features=124, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): LeakyReLU(negative_slope=0.01)\n",
       "        (bn1): BatchNorm1d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (4): ConvLayer(\n",
       "        (fc_full): Linear(in_features=143, out_features=124, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): LeakyReLU(negative_slope=0.01)\n",
       "        (bn1): BatchNorm1d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (5): ConvLayer(\n",
       "        (fc_full): Linear(in_features=143, out_features=124, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): LeakyReLU(negative_slope=0.01)\n",
       "        (bn1): BatchNorm1d(124, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (conv_to_fc): Linear(in_features=143, out_features=83, bias=True)\n",
       "    (conv_to_fc_softplus): LeakyReLU(negative_slope=0.01)\n",
       "    (dist_fcs): ModuleList(\n",
       "      (0): Linear(in_features=83, out_features=83, bias=True)\n",
       "      (1): Linear(in_features=83, out_features=83, bias=True)\n",
       "      (2): Linear(in_features=83, out_features=83, bias=True)\n",
       "      (3): Linear(in_features=83, out_features=83, bias=True)\n",
       "      (4): Linear(in_features=83, out_features=83, bias=True)\n",
       "      (5): Linear(in_features=83, out_features=83, bias=True)\n",
       "      (6): Linear(in_features=83, out_features=83, bias=True)\n",
       "    )\n",
       "    (dist_softpluses): ModuleList(\n",
       "      (0): Sigmoid()\n",
       "      (1): Sigmoid()\n",
       "      (2): Sigmoid()\n",
       "      (3): Sigmoid()\n",
       "      (4): Sigmoid()\n",
       "      (5): Sigmoid()\n",
       "      (6): Sigmoid()\n",
       "    )\n",
       "    (dist_bn): ModuleList(\n",
       "      (0): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dist_dropout): ModuleList(\n",
       "      (0): Dropout(p=0.0, inplace=False)\n",
       "      (1): Dropout(p=0.0, inplace=False)\n",
       "      (2): Dropout(p=0.0, inplace=False)\n",
       "      (3): Dropout(p=0.0, inplace=False)\n",
       "      (4): Dropout(p=0.0, inplace=False)\n",
       "      (5): Dropout(p=0.0, inplace=False)\n",
       "      (6): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (const_fcs): ModuleList(\n",
       "      (0): Linear(in_features=83, out_features=83, bias=True)\n",
       "      (1): Linear(in_features=83, out_features=83, bias=True)\n",
       "      (2): Linear(in_features=83, out_features=83, bias=True)\n",
       "      (3): Linear(in_features=83, out_features=83, bias=True)\n",
       "      (4): Linear(in_features=83, out_features=83, bias=True)\n",
       "      (5): Linear(in_features=83, out_features=83, bias=True)\n",
       "      (6): Linear(in_features=83, out_features=83, bias=True)\n",
       "    )\n",
       "    (const_softpluses): ModuleList(\n",
       "      (0): Sigmoid()\n",
       "      (1): Sigmoid()\n",
       "      (2): Sigmoid()\n",
       "      (3): Sigmoid()\n",
       "      (4): Sigmoid()\n",
       "      (5): Sigmoid()\n",
       "      (6): Sigmoid()\n",
       "    )\n",
       "    (const_bn): ModuleList(\n",
       "      (0): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (const_dropout): ModuleList(\n",
       "      (0): Dropout(p=0.0, inplace=False)\n",
       "      (1): Dropout(p=0.0, inplace=False)\n",
       "      (2): Dropout(p=0.0, inplace=False)\n",
       "      (3): Dropout(p=0.0, inplace=False)\n",
       "      (4): Dropout(p=0.0, inplace=False)\n",
       "      (5): Dropout(p=0.0, inplace=False)\n",
       "      (6): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (fc_to_bond_distance): Linear(in_features=143, out_features=83, bias=True)\n",
       "    (bond_distance_bn): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc_to_bond_distance2): Linear(in_features=83, out_features=1, bias=True)\n",
       "    (bond_distance_softplus): Softplus(beta=1, threshold=20)\n",
       "    (fc_to_bond_constant): Linear(in_features=143, out_features=83, bias=True)\n",
       "    (bond_constant_bn): BatchNorm1d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc_to_bond_constant2): Linear(in_features=83, out_features=1, bias=True)\n",
       "    (bond_const_softplus): Softplus(beta=1, threshold=20)\n",
       "    (dropout1): Dropout(p=0.0, inplace=False)\n",
       "    (dropout2): Dropout(p=0.0, inplace=False)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize()\n",
    "net.fit(SDT_training, target_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDT_train, SDT_valid, target_train, target_valid = train_test_split(SDT_training, target_training, \n",
    "                                                                    test_size=0.1, random_state=42)\n",
    "def get_targets(dummy_SDT, dummy_targets):\n",
    "    targets = []\n",
    "    for i, target in enumerate(dummy_targets):\n",
    "        free_atom_idx = dummy_SDT[i][-2]\n",
    "        \n",
    "        targets.append(target[0][free_atom_idx].reshape(-1,3))\n",
    "    return np.concatenate(targets)\n",
    "\n",
    "def get_distance(pred, true):\n",
    "    diff = np.sum((pred - true)**2, axis=1)\n",
    "    return np.sqrt(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = net.predict(SDT_train)\n",
    "true_train = get_targets(SDT_train, target_train)\n",
    "distance_train = get_distance(pred_train, true_train)\n",
    "MAE_train = np.mean(distance_train)\n",
    "\n",
    "pred_val = net.predict(SDT_valid)\n",
    "true_val = get_targets(SDT_valid, target_valid)\n",
    "distance_val = get_distance(pred_val, true_val)\n",
    "MAE_val = np.mean(distance_val)\n",
    "\n",
    "pred_test = net.predict(SDT_test)\n",
    "true_test = get_targets(SDT_test, target_test)\n",
    "distance_test = get_distance(pred_test, true_test)\n",
    "MAE_test = np.mean(distance_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029203234 0.06679936 0.06923193\n"
     ]
    }
   ],
   "source": [
    "print(MAE_train, MAE_val, MAE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988 221 246\n"
     ]
    }
   ],
   "source": [
    "print(len(SDT_train), len(SDT_valid), len(SDT_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'test result')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(distance_test, bins=20)\n",
    "plt.title('test result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_per_surface = []\n",
    "total_atoms = 0\n",
    "for sdt in SDT_test:\n",
    "    num_atoms = sdt[-2].shape[0]\n",
    "    dist_per_surface.append(np.mean(distance_test[total_atoms: total_atoms+num_atoms]))\n",
    "    total_atoms += num_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =[]\n",
    "reduced = []\n",
    "best = []\n",
    "for dist, doc in zip(dist_per_surface, docs_test):\n",
    "    total_steps = len(doc['distances_per_step'])\n",
    "    reduced_steps = len(np.where(doc['distances_per_step'] >= dist)[0])\n",
    "    results.append([total_steps, reduced_steps, reduced_steps/total_steps])\n",
    "    reduced.append(reduced_steps/total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '% Reduced')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(reduced)\n",
    "plt.title(\"Train\")\n",
    "plt.xlabel(\"% Reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23738151760454085\n",
      "0.12615249681269708\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(reduced))\n",
    "print(np.std(reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
