{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'/home/junwoony/Desktop/Differentiable_Optimization_GCN/Differentiable_Optimization_GCN/')\n",
    "\n",
    "import numpy as np\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "import mongo\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocess as mp\n",
    "\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lbfgs import LBFGS\n",
    "from cgcnn.data_orbital_sigopt import StructureData, ListDataset, StructureDataTransformer, collate_pool, MergeDataset\n",
    "from cgcnn.model_sigopt import CrystalGraphConvNet\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split\n",
    "from sklearn.metrics import get_scorer\n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.callbacks import Checkpoint, LoadInitState #needs skorch 0.4.0, conda-forge version at 0.3.0 doesn't cut it\n",
    "import skorch.callbacks.base\n",
    "from skorch.dataset import CVSplit\n",
    "from skorch.callbacks.lr_scheduler import WarmRestartLR, LRScheduler\n",
    "\n",
    "from utils.adamwr.adamw import AdamW\n",
    "from utils.adamwr.cosine_scheduler import CosineLRWithRestarts\n",
    "\n",
    "\n",
    "from sigopt_sklearn.search import SigOptSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDT_list = pickle.load(open('../../inputs/input_7_nbrs_40_steps/SDT_list.pkl', 'rb'))\n",
    "docs = pickle.load(open('../../inputs/input_7_nbrs_40_steps/final_docs.pkl', 'rb'))\n",
    "\n",
    "target_list = []\n",
    "for sdt in SDT_list:\n",
    "    free_atom_idx = sdt[-2]\n",
    "    target_list.append(sdt[-1][free_atom_idx].numpy())\n",
    "target_list = np.array(target_list).reshape(-1,1)\n",
    "\n",
    "structures = SDT_list[0]\n",
    "orig_atom_fea_len = structures[0].shape[-1]\n",
    "nbr_fea_len = structures[1].shape[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDT_training, SDT_test, target_training, target_test, docs_training, docs_test \\\n",
    "= train_test_split(SDT_list, target_list, docs, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# atom_fea = SDT_list[0][0]\n",
    "# nbr_fea = SDT_list[0][1]\n",
    "# nbr_fea_idx = SDT_list[0][2]\n",
    "# nbr_fea_offset = SDT_list[0][3]\n",
    "# atom_pos =SDT_list[0][4]\n",
    "# nbr_pos = SDT_list[0][5] \n",
    "# atom_pos_idx = SDT_list[0][6]\n",
    "# cells = SDT_list[0][7]\n",
    "# fixed_base = SDT_list[0][8]\n",
    "# free_atom_idx = SDT_list[0][9]\n",
    "# atom_pos_final = SDT_list[0][10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device='cpu'\n",
    "\n",
    "#Make a checkpoint to save parameters every time there is a new best for validation lost\n",
    "cp = Checkpoint(monitor='valid_loss_best',fn_prefix='./surface_slab_harmonic2/valid_best_')\n",
    "\n",
    "#Callback to load the checkpoint with the best validation loss at the end of training\n",
    "\n",
    "class train_end_load_best_valid_loss(skorch.callbacks.base.Callback):\n",
    "    def on_train_end(self, net, X, y):\n",
    "        net.load_params('./surface_slab_harmonic2/valid_best_params.pt')\n",
    "        \n",
    "load_best_valid_loss = train_end_load_best_valid_loss()\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.122171804"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def diff(sdt, target):\n",
    "    fixed_base = sdt[8]\n",
    "    free_atom_idx = np.where(fixed_base == 0)[0]\n",
    "    free_atom_idx = torch.LongTensor(free_atom_idx)   \n",
    "    diff = np.sum(((target[0] - sdt[4].numpy()[free_atom_idx]))**2.,axis=1)**0.5 \n",
    "    return diff\n",
    "\n",
    "np.mean(np.abs(np.concatenate([diff(sdt, target) for sdt,target in zip(SDT_list, target_list)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054590654"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def diff_position(sdt, target):\n",
    "    fixed_base = sdt[8]\n",
    "    free_atom_idx = np.where(fixed_base == 0)[0]\n",
    "    free_atom_idx = torch.LongTensor(free_atom_idx)   \n",
    "    diff = (target[0] - sdt[4].numpy()[free_atom_idx])\n",
    "    return diff\n",
    "\n",
    "differences = []\n",
    "for sdt, target in zip(SDT_list, target_list):\n",
    "    differences.append(diff_position(sdt, target))\n",
    "differences = np.concatenate(differences)\n",
    "np.mean(np.abs(differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_test_splitter = ShuffleSplit(test_size=0.1, random_state=42)\n",
    "\n",
    "batchsize = 100\n",
    "# warm restart scheduling from https://arxiv.org/pdf/1711.05101.pdf\n",
    "LR_schedule = LRScheduler(CosineLRWithRestarts, batch_size=batchsize, epoch_size=len(SDT_training), restart_period=10, t_mult=1.2)\n",
    "\n",
    "#############\n",
    "# To extract intermediate features, set the forward takes only the first return value to calculate loss\n",
    "class MyNet(NeuralNetRegressor):\n",
    "    def get_loss(self, y_pred, y_true, **kwargs):        \n",
    "        y_pred = y_pred[0] if isinstance(y_pred, tuple) else y_pred  # discard the 2nd output\n",
    "        differ=torch.sum((y_pred - y_true.cuda())**2.0,dim=1)\n",
    "        if torch.nonzero(differ).shape[0] != differ.shape[0]:\n",
    "            print('zero sqrt for Loss')\n",
    "\n",
    "        differ = torch.clamp(differ, min=1e-8)\n",
    "        return torch.mean(torch.sqrt(differ))\n",
    "\n",
    "net = MyNet(\n",
    "    CrystalGraphConvNet,\n",
    "    module__orig_atom_fea_len = orig_atom_fea_len,\n",
    "    module__nbr_fea_len = nbr_fea_len,\n",
    "    batch_size=batchsize, #214\n",
    "    module__classification=False,\n",
    "    lr=0.0056,\n",
    "    max_epochs= 500,\n",
    "    module__energy_mode=\"Harmonic\", #[\"Harmonic\", \"Morse\", \"LJ\"], Default = \"Harmonic\"\n",
    "    module__atom_fea_len=46, #46,\n",
    "    module__h_fea_len=83,\n",
    "    module__h_fea_len_dist=83,\n",
    "    module__h_fea_len_const=83,\n",
    "    module__h_fea_len_D=83,\n",
    "    module__n_conv=6, #8\n",
    "    module__n_h_dist=8,\n",
    "    module__n_h_const=8,\n",
    "    module__n_h_D=8,\n",
    "    module__max_num_nbr=12, #9\n",
    "    module__opt_step_size=0.3, #0.3\n",
    "    module__min_opt_steps=30,\n",
    "    module__max_opt_steps=300,\n",
    "    module__momentum=0.8,\n",
    "    optimizer__weight_decay=1e-3,\n",
    "    optimizer=AdamW,\n",
    "    iterator_train__pin_memory=True,\n",
    "    iterator_train__num_workers=0,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__collate_fn = collate_pool,\n",
    "    iterator_valid__pin_memory=True,\n",
    "    iterator_valid__num_workers=0,\n",
    "    iterator_valid__collate_fn = collate_pool,\n",
    "    device=device,\n",
    "#     criterion=torch.nn.MSELoss,\n",
    "    criterion=torch.nn.L1Loss,\n",
    "    dataset=MergeDataset,\n",
    "    train_split = CVSplit(cv=train_test_splitter),\n",
    "    callbacks=[cp, LR_schedule, load_best_valid_loss]\n",
    ")\n",
    "net.initialize()\n",
    "net.load_params(f_history = './surface_slab_harmonic2/valid_best_history.json',\n",
    "               f_optimizer = './surface_slab_harmonic2/valid_best_optimizer.pt',\n",
    "               f_params = './surface_slab_harmonic2/valid_best_params.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: atom_fea_len, classification, energy_mode, h_fea_len, h_fea_len_D, h_fea_len_const, h_fea_len_dist, max_num_nbr, max_opt_steps, min_opt_steps, momentum, n_conv, n_h_D, n_h_const, n_h_dist, nbr_fea_len, opt_step_size, orig_atom_fea_len.\n",
      "Re-initializing optimizer because the following parameters were re-set: weight_decay.\n",
      "blow up\n",
      "blow up\n",
      "  epoch    train_loss    valid_loss    cp       dur\n",
      "-------  ------------  ------------  ----  --------\n",
      "      1        \u001b[36m0.9093\u001b[0m        \u001b[32m1.8402\u001b[0m     +  285.3992\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "      2        1.5457        \u001b[32m0.4217\u001b[0m     +  353.3929\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "      3        \u001b[36m0.4387\u001b[0m        0.6599        242.6621\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "blow up\n",
      "      4        0.5306        \u001b[32m0.2629\u001b[0m     +  238.2346\n",
      "      5        \u001b[36m0.2264\u001b[0m        \u001b[32m0.1735\u001b[0m     +  207.0725\n",
      "      6        \u001b[36m0.1505\u001b[0m        \u001b[32m0.1481\u001b[0m     +  199.3052\n",
      "      7        0.1509        \u001b[32m0.1370\u001b[0m     +  192.7559\n",
      "      8        \u001b[36m0.1474\u001b[0m        0.1386        183.5124\n",
      "      9        \u001b[36m0.1275\u001b[0m        \u001b[32m0.1328\u001b[0m     +  172.0618\n",
      "     10        0.1421        0.1340        184.0427\n",
      "     11        \u001b[36m0.1189\u001b[0m        \u001b[32m0.1193\u001b[0m     +  174.4572\n",
      "     12        0.1225        \u001b[32m0.1146\u001b[0m     +  168.3247\n",
      "     13        \u001b[36m0.1125\u001b[0m        \u001b[32m0.1112\u001b[0m     +  171.8831\n",
      "     14        0.1131        \u001b[32m0.1072\u001b[0m     +  170.8781\n",
      "     15        \u001b[36m0.1119\u001b[0m        \u001b[32m0.1059\u001b[0m     +  167.2542\n",
      "     16        \u001b[36m0.1048\u001b[0m        0.1060        162.8773\n",
      "     17        0.1082        \u001b[32m0.1042\u001b[0m     +  141.9678\n",
      "     18        0.1092        0.1058        89.4174\n",
      "     19        0.1124        \u001b[32m0.1041\u001b[0m     +  95.1781\n",
      "     20        \u001b[36m0.1018\u001b[0m        \u001b[32m0.1039\u001b[0m     +  96.7787\n",
      "     21        0.1054        \u001b[32m0.1033\u001b[0m     +  92.2097\n",
      "     22        0.1028        \u001b[32m0.1024\u001b[0m     +  96.6276\n",
      "     23        0.1076        0.1042        94.7980\n",
      "     24        0.1183        0.1042        92.4492\n",
      "     25        \u001b[36m0.0989\u001b[0m        0.1050        93.5896\n",
      "     26        0.1026        \u001b[32m0.0996\u001b[0m     +  93.0614\n",
      "     27        \u001b[36m0.0967\u001b[0m        0.1006        92.7269\n",
      "     28        0.1012        0.1012        95.3167\n",
      "     29        \u001b[36m0.0963\u001b[0m        0.0997        96.0170\n",
      "     30        \u001b[36m0.0951\u001b[0m        0.1026        92.7536\n",
      "     31        0.0951        \u001b[32m0.0975\u001b[0m     +  95.2073\n",
      "     32        \u001b[36m0.0928\u001b[0m        0.0992        88.8913\n",
      "     33        0.0965        \u001b[32m0.0974\u001b[0m     +  92.5308\n",
      "     34        0.1020        0.0976        93.5502\n",
      "     35        0.0932        \u001b[32m0.0967\u001b[0m     +  92.5722\n",
      "     36        0.0989        \u001b[32m0.0964\u001b[0m     +  94.4915\n",
      "     37        0.0961        0.0969        92.0522\n",
      "     38        0.1033        0.0967        96.5001\n",
      "     39        0.1009        0.0999        90.7678\n",
      "     40        0.1001        0.1054        94.1104\n",
      "     41        0.0997        0.0985        96.1249\n",
      "     42        0.0999        0.0976        91.7141\n",
      "     43        0.1029        \u001b[32m0.0952\u001b[0m     +  95.0113\n",
      "     44        0.1001        0.1019        87.1443\n",
      "     45        \u001b[36m0.0923\u001b[0m        0.0966        96.0466\n",
      "     46        0.0959        \u001b[32m0.0947\u001b[0m     +  90.0175\n",
      "     47        0.0934        0.1018        93.2888\n",
      "     48        0.0938        \u001b[32m0.0946\u001b[0m     +  89.0676\n",
      "     49        0.0977        0.0950        91.2310\n",
      "     50        \u001b[36m0.0873\u001b[0m        \u001b[32m0.0929\u001b[0m     +  94.2587\n",
      "     51        0.0917        \u001b[32m0.0927\u001b[0m     +  90.8847\n",
      "     52        0.0937        0.0928        98.4609\n",
      "     53        0.0967        0.0933        95.8275\n",
      "     54        0.0885        0.0930        90.6398\n",
      "     55        0.0933        0.0931        91.7510\n",
      "     56        0.0992        0.0955        87.3700\n",
      "     57        0.0941        0.1064        91.6253\n",
      "     58        0.0966        0.0993        93.3453\n",
      "     59        0.0952        0.0958        88.0362\n",
      "     60        0.0946        0.1034        85.5197\n",
      "     61        0.0925        0.0950        85.1941\n",
      "     62        0.0958        \u001b[32m0.0920\u001b[0m     +  86.2377\n",
      "     63        0.0962        0.0956        84.2994\n",
      "     64        0.0880        \u001b[32m0.0908\u001b[0m     +  88.1458\n",
      "     65        \u001b[36m0.0839\u001b[0m        0.0923        85.2593\n",
      "     66        0.0924        \u001b[32m0.0903\u001b[0m     +  85.7677\n",
      "     67        0.0904        \u001b[32m0.0896\u001b[0m     +  83.6753\n",
      "     68        0.0884        \u001b[32m0.0892\u001b[0m     +  82.4670\n",
      "     69        0.0860        0.0898        85.0896\n",
      "     70        0.0957        0.0894        77.5396\n",
      "     71        0.0852        \u001b[32m0.0890\u001b[0m     +  85.0801\n",
      "     72        0.0882        0.0909        82.3982\n",
      "     73        0.0886        \u001b[32m0.0887\u001b[0m     +  84.5163\n",
      "     74        0.0870        0.0887        81.2513\n",
      "     75        0.0857        0.0888        84.8258\n",
      "     76        0.0865        \u001b[32m0.0885\u001b[0m     +  85.1292\n",
      "     77        0.0972        0.0962        80.6047\n",
      "     78        0.0939        0.1305        84.5298\n",
      "     79        0.0892        0.0919        84.2342\n",
      "     80        0.0926        0.0894        88.2228\n",
      "     81        0.0902        0.0947        87.3801\n",
      "     82        0.0928        0.0948        82.9307\n",
      "     83        0.0909        0.0907        82.4392\n",
      "     84        0.0908        0.0888        87.8089\n",
      "     85        0.0872        0.0889        82.3587\n",
      "     86        0.0872        \u001b[32m0.0880\u001b[0m     +  85.3091\n",
      "     87        0.0851        0.0881        78.4965\n",
      "     88        0.0881        0.0908        79.4816\n",
      "     89        0.0876        \u001b[32m0.0864\u001b[0m     +  81.8152\n",
      "     90        0.0862        \u001b[32m0.0863\u001b[0m     +  82.9859\n",
      "     91        \u001b[36m0.0822\u001b[0m        \u001b[32m0.0862\u001b[0m     +  80.3536\n",
      "     92        0.0848        \u001b[32m0.0855\u001b[0m     +  80.5252\n",
      "     93        0.0833        \u001b[32m0.0853\u001b[0m     +  80.8942\n",
      "     94        \u001b[36m0.0811\u001b[0m        0.0854        85.3626\n",
      "     95        \u001b[36m0.0804\u001b[0m        0.0858        89.8444\n",
      "     96        0.0860        \u001b[32m0.0853\u001b[0m     +  88.2316\n",
      "     97        0.0809        \u001b[32m0.0843\u001b[0m     +  88.3939\n",
      "     98        0.0828        0.0843        82.2489\n",
      "     99        0.0839        0.0844        86.5192\n",
      "    100        0.0843        0.0846        78.5819\n",
      "    101        0.0830        \u001b[32m0.0842\u001b[0m     +  80.8555\n",
      "    102        0.0902        0.0919        86.4679\n",
      "    103        0.0889        0.1076        87.9291\n",
      "    104        0.0907        0.0879        80.9348\n",
      "    105        0.0828        0.0959        86.1368\n",
      "    106        0.0847        0.0894        77.6989\n",
      "    107        0.0851        0.0869        86.5586\n",
      "    108        0.0833        0.0858        80.7877\n",
      "    109        0.0858        0.0859        82.2460\n",
      "    110        0.0945        0.0885        87.4442\n",
      "    111        0.0827        0.0879        78.1760\n",
      "    112        0.0830        0.0851        84.3650\n",
      "    113        0.0851        0.0896        77.5912\n",
      "    114        0.0814        0.0918        75.7676\n",
      "    115        \u001b[36m0.0761\u001b[0m        0.0929        86.7904\n",
      "    116        0.0856        0.0923        84.0627\n",
      "    117        0.0837        \u001b[32m0.0832\u001b[0m     +  86.8508\n",
      "    118        0.0791        \u001b[32m0.0825\u001b[0m     +  85.9146\n",
      "    119        0.0797        0.0876        83.7036\n",
      "    120        0.0806        \u001b[32m0.0822\u001b[0m     +  88.1033\n",
      "    121        0.0781        \u001b[32m0.0808\u001b[0m     +  86.6856\n",
      "    122        0.0795        0.0814        83.0980\n",
      "    123        0.0770        0.0827        84.6456\n",
      "    124        \u001b[36m0.0760\u001b[0m        0.0813        83.9756\n",
      "    125        0.0804        0.0813        87.6052\n",
      "    126        0.0767        0.0809        84.4246\n",
      "    127        \u001b[36m0.0747\u001b[0m        \u001b[32m0.0803\u001b[0m     +  78.8567\n",
      "    128        0.0787        0.0803        76.0380\n",
      "    129        0.0760        \u001b[32m0.0802\u001b[0m     +  76.4607\n",
      "    130        \u001b[36m0.0737\u001b[0m        \u001b[32m0.0801\u001b[0m     +  85.6498\n",
      "    131        0.0754        0.0802        86.1884\n",
      "    132        0.0841        0.0838        89.3555\n",
      "    133        0.0870        0.1126        83.3812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    134        0.0840        0.0906        84.6439\n",
      "    135        0.0840        0.1129        76.3375\n",
      "    136        0.0890        0.0832        83.4143\n",
      "    137        0.0830        0.0820        87.7290\n",
      "    138        0.0841        0.0858        80.2441\n",
      "    139        0.0894        0.0879        87.1121\n",
      "    140        0.0804        0.0851        81.5386\n",
      "    141        0.0770        0.0853        83.8086\n",
      "    142        0.0827        0.0847        79.1177\n",
      "    143        0.0797        0.0823        78.7545\n",
      "    144        0.0756        0.0922        84.7394\n",
      "    145        0.0773        0.1091        84.9418\n",
      "    146        0.0785        \u001b[32m0.0789\u001b[0m     +  78.4321\n",
      "    147        \u001b[36m0.0717\u001b[0m        0.0794        85.9226\n",
      "    148        0.0768        0.0873        82.6602\n",
      "    149        0.0759        0.0833        72.6876\n",
      "    150        0.0769        \u001b[32m0.0772\u001b[0m     +  82.8383\n",
      "    151        0.0749        0.0791        85.3816\n",
      "    152        0.0733        \u001b[32m0.0766\u001b[0m     +  87.4208\n",
      "    153        0.0728        0.0825        88.8927\n",
      "    154        \u001b[36m0.0690\u001b[0m        0.0775        85.3032\n",
      "    155        0.0737        \u001b[32m0.0754\u001b[0m     +  85.6613\n",
      "    156        0.0725        0.0764        90.7668\n",
      "    157        0.0753        0.0777        84.3797\n",
      "    158        0.0743        0.0761        92.5471\n",
      "    159        \u001b[36m0.0681\u001b[0m        \u001b[32m0.0749\u001b[0m     +  83.2845\n",
      "    160        0.0737        0.0755        92.8346\n",
      "    161        0.0706        0.0752        85.0059\n",
      "    162        0.0694        0.0753        89.0666\n",
      "    163        \u001b[36m0.0680\u001b[0m        0.0749        82.9565\n",
      "    164        0.0681        0.0751        82.7709\n",
      "    165        0.0693        0.0751        85.5086\n",
      "    166        \u001b[36m0.0662\u001b[0m        0.0750        90.7625\n",
      "    167        0.0692        \u001b[32m0.0748\u001b[0m     +  83.4317\n",
      "    168        0.0776        0.0801        88.9947\n",
      "    169        0.0784        0.0835        84.5132\n",
      "    170        0.0767        0.0805        95.4891\n",
      "    171        0.0816        0.0953        100.0274\n",
      "    172        0.0844        0.0840        93.3902\n",
      "    173        0.0773        0.0875        84.7108\n",
      "    174        0.0781        0.0805        84.7220\n",
      "    175        0.0777        0.0857        88.3277\n",
      "    176        0.0731        0.0791        85.9270\n",
      "    177        0.0753        0.0792        85.9596\n",
      "    178        0.0702        0.0811        99.8191\n",
      "    179        0.0774        0.0795        91.1148\n",
      "    180        0.0713        0.0763        94.7591\n",
      "    181        0.0725        0.0783        90.8109\n",
      "    182        0.0716        0.0799        94.2981\n",
      "    183        0.0715        0.0828        99.0706\n",
      "    184        0.0740        0.0755        90.5067\n",
      "    185        0.0718        0.0788        95.3811\n",
      "    186        0.0718        0.0754        103.8327\n",
      "    187        0.0728        0.0752        94.6396\n",
      "    188        0.0685        0.0782        95.9094\n",
      "    189        0.0723        0.0754        99.6930\n",
      "    190        0.0707        \u001b[32m0.0745\u001b[0m     +  106.4908\n",
      "    191        \u001b[36m0.0659\u001b[0m        \u001b[32m0.0741\u001b[0m     +  103.2828\n",
      "    192        0.0700        0.0748        96.6347\n",
      "    193        0.0664        0.0746        103.0827\n",
      "    194        \u001b[36m0.0652\u001b[0m        \u001b[32m0.0731\u001b[0m     +  87.5860\n",
      "    195        \u001b[36m0.0644\u001b[0m        0.0734        102.3777\n",
      "    196        0.0684        0.0769        108.7813\n",
      "    197        0.0687        0.0742        110.6254\n",
      "    198        0.0663        \u001b[32m0.0722\u001b[0m     +  107.7177\n",
      "    199        0.0663        0.0727        107.8368\n",
      "    200        0.0681        0.0733        111.0676\n",
      "    201        \u001b[36m0.0642\u001b[0m        \u001b[32m0.0712\u001b[0m     +  112.6594\n",
      "    202        \u001b[36m0.0623\u001b[0m        0.0724        111.4215\n",
      "    203        0.0632        0.0727        110.8174\n",
      "    204        0.0627        0.0734        113.8205\n",
      "    205        0.0654        0.0714        103.8663\n",
      "    206        \u001b[36m0.0585\u001b[0m        0.0722        111.9265\n",
      "    207        0.0645        0.0726        120.1288\n",
      "    208        0.0622        0.0719        121.3009\n",
      "    209        0.0639        0.0715        107.3841\n",
      "    210        0.0633        \u001b[32m0.0711\u001b[0m     +  109.3239\n",
      "    211        0.0751        0.0897        102.2575\n",
      "    212        0.0752        0.0779        95.5928\n",
      "    213        0.0803        0.0845        92.7092\n",
      "    214        0.0780        0.0778        98.6265\n",
      "    215        0.0796        0.0852        96.7097\n",
      "    216        0.0728        0.0903        100.4917\n",
      "    217        0.0740        0.0792        89.7412\n",
      "    218        0.0745        0.0779        115.5868\n",
      "    219        0.0736        0.1002        106.3086\n",
      "    220        0.0752        0.0763        106.0687\n",
      "    221        0.0739        0.0739        111.0983\n",
      "    222        0.0725        0.0931        103.1407\n",
      "    223        0.0782        0.0869        101.8112\n",
      "    224        0.0751        0.0750        99.5720\n",
      "    225        0.0699        0.0753        105.9892\n",
      "    226        0.0695        0.0782        100.8863\n",
      "    227        0.0723        0.0803        104.8752\n",
      "    228        0.0687        0.0736        104.6140\n",
      "    229        0.0709        0.0746        113.6920\n",
      "    230        0.0676        0.0758        100.7458\n",
      "    231        0.0667        0.0732        121.4821\n",
      "    232        0.0704        0.0757        101.2324\n",
      "    233        0.0666        0.0785        114.9134\n",
      "    234        0.0662        0.0730        116.2032\n",
      "    235        0.0653        0.0744        114.9487\n",
      "    236        0.0645        0.0727        116.9279\n",
      "    237        0.0634        0.0739        117.8350\n",
      "    238        0.0671        \u001b[32m0.0710\u001b[0m     +  111.4218\n",
      "    239        0.0651        0.0714        109.7687\n",
      "    240        0.0597        \u001b[32m0.0709\u001b[0m     +  123.0965\n",
      "    241        0.0612        0.0719        116.4290\n",
      "    242        0.0611        0.0713        113.5457\n",
      "    243        0.0615        0.0762        127.9567\n",
      "    244        \u001b[36m0.0569\u001b[0m        \u001b[32m0.0701\u001b[0m     +  123.3498\n",
      "    245        0.0640        0.0713        111.1924\n",
      "    246        0.0569        \u001b[32m0.0700\u001b[0m     +  109.0124\n",
      "    247        0.0600        0.0702        114.5141\n",
      "    248        0.0600        \u001b[32m0.0696\u001b[0m     +  128.6477\n",
      "    249        0.0584        0.0763        108.3098\n",
      "    250        0.0583        \u001b[32m0.0694\u001b[0m     +  128.3312\n",
      "    251        \u001b[36m0.0568\u001b[0m        0.0696        116.5127\n",
      "    252        \u001b[36m0.0555\u001b[0m        \u001b[32m0.0691\u001b[0m     +  122.6147\n",
      "    253        0.0557        0.0694        125.8425\n",
      "    254        0.0599        0.0693        131.7220\n",
      "    255        0.0570        0.0692        122.1426\n",
      "    256        0.0597        0.0693        134.7629\n",
      "    257        0.0597        0.0695        134.0075\n",
      "    258        \u001b[36m0.0537\u001b[0m        \u001b[32m0.0690\u001b[0m     +  129.9122\n",
      "    259        \u001b[36m0.0536\u001b[0m        0.0691        129.5155\n",
      "    260        0.0586        0.0692        41.3003\n",
      "    261        0.0599        0.0692        36.2406\n",
      "    262        0.0604        0.0691        34.7064\n",
      "    263        0.0712        0.0912        35.0232\n",
      "    264        0.0771        0.0807        32.4310\n",
      "    265        0.0775        0.0798        31.5197\n",
      "    266        0.0729        0.0971        31.5915\n",
      "    267        0.0693        0.0861        32.2366\n",
      "    268        0.0686        0.0854        31.7448\n",
      "    269        0.0702        0.0893        32.1547\n",
      "    270        0.0726        0.0761        31.8568\n",
      "    271        0.0723        0.0952        32.0028\n",
      "    272        0.0721        0.0859        33.9723\n",
      "    273        0.0711        0.1110        32.2865\n",
      "    274        0.0780        0.0722        33.1196\n",
      "    275        0.0694        0.0735        32.0264\n",
      "    276        0.0666        0.0951        31.0791\n",
      "    277        0.0735        0.0917        31.5423\n",
      "    278        0.0681        0.0754        33.4257\n",
      "    279        0.0644        0.0734        32.9513\n",
      "    280        0.0714        0.0780        33.4142\n",
      "    281        0.0644        0.0737        37.1480\n",
      "    282        0.0666        0.0744        31.8308\n",
      "    283        0.0646        0.0725        32.2032\n",
      "    284        0.0634        0.0806        31.7709\n",
      "    285        0.0683        0.0705        32.8348\n",
      "    286        0.0620        0.0714        36.1218\n",
      "    287        0.0653        0.0719        32.1202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    288        0.0615        0.0904        33.4310\n",
      "    289        0.0659        0.0725        36.6947\n",
      "    290        0.0656        0.0807        36.4099\n",
      "    291        0.0632        0.0756        35.1100\n",
      "    292        0.0621        0.0708        33.1181\n",
      "    293        0.0602        0.0717        33.7198\n",
      "    294        0.0584        0.0825        34.5700\n",
      "    295        0.0587        0.0698        36.2929\n",
      "    296        0.0604        0.0690        32.9684\n",
      "    297        0.0576        0.0707        35.8311\n",
      "    298        0.0589        0.0737        34.8728\n",
      "    299        0.0588        0.0710        34.5565\n",
      "    300        0.0547        0.0695        34.0523\n",
      "    301        0.0574        0.0699        35.3289\n",
      "    302        0.0561        \u001b[32m0.0686\u001b[0m     +  33.1720\n",
      "    303        0.0574        \u001b[32m0.0683\u001b[0m     +  34.1559\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.05 GiB already allocated; 4.88 MiB free; 215.39 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0cf85e7ab73c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSDT_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/skorch/regressor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# this is actually a pylint bug:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# https://github.com/PyCQA/pylint/issues/1085\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeuralNetRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_train_begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0myi_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myi\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my_valid_is_ph\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_batch_begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myi_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m                 \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid_batch_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, Xi, yi, **fit_params)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;31m#with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         return {\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, x, **fit_params)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_x_and_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Differentiable_Optimization_GCN/Differentiable_Optimization_GCN/cgcnn/model_sigopt.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, atom_fea, nbr_fea, nbr_fea_idx, nbr_fea_offset, crystal_atom_idx, atom_pos, nbr_pos, atom_pos_idx, cells, fixed_atom_mask, atom_pos_final)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mgrad_E\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpotential_E\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#.sum()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_E\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matom_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfixed_atom_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    147\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.78 GiB total capacity; 2.05 GiB already allocated; 4.88 MiB free; 215.39 MiB cached)"
     ]
    }
   ],
   "source": [
    "net.initialize()\n",
    "net.fit(SDT_training, target_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1        \u001b[36m0.1185\u001b[0m        \u001b[32m0.1218\u001b[0m     +  32.2326\n",
      "      2        0.1203        \u001b[32m0.1210\u001b[0m     +  31.6294\n",
      "      3        0.1190        0.1211        31.7579\n",
      "      4        \u001b[36m0.1180\u001b[0m        0.1211        31.8141\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-32a99a96616a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     n_jobs=1, n_iter=50, scoring=get_scorer('neg_mean_absolute_error'))\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSDT_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/sigopt_sklearn/search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munsupervised\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \"\"\"\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/sigopt_sklearn/search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable, **fit_params)\u001b[0m\n\u001b[1;32m    377\u001b[0m                                             \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                                             error_score=self.error_score)\n\u001b[0;32m--> 379\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_configs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m                         for train, test in cv_iter)\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/joblib-0.14.1.dev0-py3.7.egg/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/joblib-0.14.1.dev0-py3.7.egg/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/joblib-0.14.1.dev0-py3.7.egg/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/joblib-0.14.1.dev0-py3.7.egg/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/joblib-0.14.1.dev0-py3.7.egg/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/joblib-0.14.1.dev0-py3.7.egg/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/joblib-0.14.1.dev0-py3.7.egg/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \"\"\"\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \"\"\"\n\u001b[0;32m-> 1049\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \"\"\"\n\u001b[1;32m   1012\u001b[0m         \u001b[0my_probas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0myp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0myp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0myp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0my_probas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mforward_iter\u001b[0;34m(self, X, training, device)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m             \u001b[0myp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;31m#                print('n',yp[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[0;34m(self, Xi, training)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;31m#with torch.set_grad_enabled(training):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, x, **fit_params)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_x_and_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Differentiable_Optimization_GCN/Differentiable_Optimization_GCN/cgcnn/model_sigopt.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, atom_fea, nbr_fea, nbr_fea_idx, nbr_fea_offset, crystal_atom_idx, atom_pos, nbr_pos, atom_pos_idx, cells, fixed_atom_mask, atom_pos_final)\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'grad_E becomes inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;31m#detect if step is going off the rails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0matom_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfree_atom_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "client_token = \"TSRIPFKLRAIMUDDVQEBJHVBQRVBCDJOSKJMKEQTXWCYZDNED\"\n",
    "net_parameters = {\n",
    "                'batch_size':(20,120),\n",
    "                'lr':(np.exp(-15),np.exp(-3)),\n",
    "                'max_epochs':(50,300),\n",
    "                'module__atom_fea_len':(3,256), #46,\n",
    "                'module__h_fea_len':(3,256),\n",
    "                'module__h_fea_len_dist':(3,256),\n",
    "                'module__h_fea_len_const':(3,256),\n",
    "                'module__h_fea_len_D':(3,256),\n",
    "                'module__n_conv':(1,12), #8\n",
    "                'module__n_h_dist':(1,12),\n",
    "                'module__n_h_const':(1,12),\n",
    "                'module__n_h_D':(1,12),\n",
    "                'module__opt_step_size':(0.1,0.7),\n",
    "                'optimizer__weight_decay':(np.exp(-10),np.exp(-2))\n",
    "                }\n",
    "\n",
    "cv=ShuffleSplit(n_splits=1, test_size=0.1)\n",
    "\n",
    "clf = SigOptSearchCV(net, net_parameters, cv=train_test_splitter, client_token=client_token,\n",
    "                    n_jobs=1, n_iter=50, scoring=get_scorer('neg_mean_absolute_error'))\n",
    "\n",
    "clf.fit(SDT_training, target_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDT_train, SDT_valid, target_train, target_valid = train_test_split(SDT_training, target_training, \n",
    "                                                                    test_size=0.1, random_state=42)\n",
    "def get_targets(dummy_SDT, dummy_targets):\n",
    "    targets = []\n",
    "    for i, target in enumerate(dummy_targets):\n",
    "        free_atom_idx = dummy_SDT[i][-2]\n",
    "        \n",
    "        targets.append(target[0].reshape(-1,3))\n",
    "    return np.concatenate(targets)\n",
    "\n",
    "def get_distance(pred, true):\n",
    "    diff = np.sum((pred - true)**2, axis=1)\n",
    "    return np.sqrt(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = net.predict(SDT_train)\n",
    "true_train = get_targets(SDT_train, target_train)\n",
    "distance_train = get_distance(pred_train, true_train)\n",
    "MAE_train = np.mean(distance_train)\n",
    "\n",
    "# pred_val = net.predict(SDT_valid)\n",
    "# true_val = get_targets(SDT_valid, target_valid)\n",
    "# distance_val = get_distance(pred_val, true_val)\n",
    "# MAE_val = np.mean(distance_val)\n",
    "\n",
    "pred_test = net.predict(SDT_test)\n",
    "true_test = get_targets(SDT_test, target_test)\n",
    "distance_test = get_distance(pred_test, true_test)\n",
    "MAE_test = np.mean(distance_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0338591"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(pred_test - true_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e6d9f1bb7e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdifferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdifferences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdifferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-88ec556f998c>\u001b[0m in \u001b[0;36mdiff_position\u001b[0;34m(sdt, target)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdiff_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfixed_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfree_atom_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_base\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfree_atom_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_atom_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfree_atom_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "differences = []\n",
    "for sdt, target in zip(pred_test, true_test):\n",
    "    differences.append(diff_position(sdt, target))\n",
    "differences = np.concatenate(differences)\n",
    "np.mean(np.abs(differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.074342854 0.074342854\n"
     ]
    }
   ],
   "source": [
    "print(MAE_test, MAE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3709 413 459\n"
     ]
    }
   ],
   "source": [
    "print(len(SDT_train), len(SDT_valid), len(SDT_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'test result')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(distance_test, bins=20)\n",
    "plt.title('test result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train, docs_val = train_test_split(docs_training, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(SDT, docs, distance):\n",
    "    dist_per_surface = []\n",
    "    total_atoms = 0\n",
    "    for sdt in SDT:\n",
    "        num_atoms = sdt[-2].shape[0]\n",
    "        dist_per_surface.append(np.mean(distance[total_atoms: total_atoms+num_atoms]))\n",
    "        total_atoms += num_atoms\n",
    "    results =[]\n",
    "    reduced = []\n",
    "    best = []\n",
    "    bad_docs = []\n",
    "    bad_result =[]\n",
    "    good_docs=[]\n",
    "    good_result=[]\n",
    "    f = 0\n",
    "    for dist, doc in zip(dist_per_surface, docs):\n",
    "        total_steps = len(doc['distances_per_step'])\n",
    "        reduced_steps = len(np.where(doc['distances_per_step'] >= dist)[0])\n",
    "        results.append([total_steps, reduced_steps, reduced_steps/total_steps])\n",
    "        reduced.append(reduced_steps/total_steps)\n",
    "        if reduced_steps/total_steps < 0.1:\n",
    "            bad_docs.append(doc)\n",
    "            bad_result.append([total_steps, reduced_steps, reduced_steps/total_steps, dist])\n",
    "        else:\n",
    "            good_docs.append(doc)\n",
    "            good_result.append([total_steps, reduced_steps, reduced_steps/total_steps,dist])\n",
    "    \n",
    "    return results, reduced, bad_docs, bad_result,good_docs, good_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, reduced, bad_docs, bad_result,good_docs,good_result = analysis(SDT_test, docs_test, distance_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[26, 5, 0.19230769230769232, 0.1175502],\n",
       " [26, 6, 0.23076923076923078, 0.15778206],\n",
       " [19, 6, 0.3157894736842105, 0.027491713],\n",
       " [15, 4, 0.26666666666666666, 0.04570685],\n",
       " [32, 9, 0.28125, 0.10456716],\n",
       " [19, 3, 0.15789473684210525, 0.06258627],\n",
       " [18, 4, 0.2222222222222222, 0.07884418],\n",
       " [34, 9, 0.2647058823529412, 0.17137583],\n",
       " [17, 5, 0.29411764705882354, 0.031291526],\n",
       " [21, 11, 0.5238095238095238, 0.055237968],\n",
       " [18, 4, 0.2222222222222222, 0.039373104],\n",
       " [25, 10, 0.4, 0.10506768],\n",
       " [12, 4, 0.3333333333333333, 0.04470617],\n",
       " [22, 4, 0.18181818181818182, 0.07571136],\n",
       " [26, 12, 0.46153846153846156, 0.09256738],\n",
       " [28, 5, 0.17857142857142858, 0.055534203],\n",
       " [11, 4, 0.36363636363636365, 0.0897941],\n",
       " [20, 4, 0.2, 0.058384757],\n",
       " [9, 1, 0.1111111111111111, 0.05287528],\n",
       " [14, 4, 0.2857142857142857, 0.084015235],\n",
       " [14, 3, 0.21428571428571427, 0.0542026],\n",
       " [18, 9, 0.5, 0.055651605],\n",
       " [21, 4, 0.19047619047619047, 0.046196893],\n",
       " [12, 2, 0.16666666666666666, 0.04654707],\n",
       " [16, 7, 0.4375, 0.012803385],\n",
       " [13, 4, 0.3076923076923077, 0.04300588],\n",
       " [17, 5, 0.29411764705882354, 0.048455175],\n",
       " [16, 9, 0.5625, 0.04820825],\n",
       " [13, 2, 0.15384615384615385, 0.09489951],\n",
       " [20, 7, 0.35, 0.068869136],\n",
       " [19, 5, 0.2631578947368421, 0.065287404],\n",
       " [21, 3, 0.14285714285714285, 0.055641666],\n",
       " [16, 2, 0.125, 0.043725263],\n",
       " [25, 3, 0.12, 0.085807145],\n",
       " [31, 12, 0.3870967741935484, 0.0933302],\n",
       " [13, 4, 0.3076923076923077, 0.15437767],\n",
       " [13, 7, 0.5384615384615384, 0.049105603],\n",
       " [21, 4, 0.19047619047619047, 0.08942874],\n",
       " [13, 4, 0.3076923076923077, 0.035454363],\n",
       " [18, 6, 0.3333333333333333, 0.08185808],\n",
       " [13, 3, 0.23076923076923078, 0.053989675],\n",
       " [16, 6, 0.375, 0.04190819],\n",
       " [12, 2, 0.16666666666666666, 0.08933683],\n",
       " [24, 6, 0.25, 0.06953669],\n",
       " [12, 7, 0.5833333333333334, 0.020201266],\n",
       " [19, 2, 0.10526315789473684, 0.096504785],\n",
       " [13, 6, 0.46153846153846156, 0.09371514],\n",
       " [24, 10, 0.4166666666666667, 0.07377656],\n",
       " [37, 7, 0.1891891891891892, 0.16267692],\n",
       " [7, 2, 0.2857142857142857, 0.034888476],\n",
       " [16, 2, 0.125, 0.08579684],\n",
       " [11, 3, 0.2727272727272727, 0.05394612],\n",
       " [11, 2, 0.18181818181818182, 0.033852477],\n",
       " [26, 5, 0.19230769230769232, 0.055370133],\n",
       " [13, 2, 0.15384615384615385, 0.03232052],\n",
       " [12, 5, 0.4166666666666667, 0.018032562],\n",
       " [24, 6, 0.25, 0.06463171],\n",
       " [18, 14, 0.7777777777777778, 0.018139534],\n",
       " [21, 7, 0.3333333333333333, 0.019914376],\n",
       " [5, 1, 0.2, 0.03319385],\n",
       " [17, 2, 0.11764705882352941, 0.042204265],\n",
       " [27, 7, 0.25925925925925924, 0.08556518],\n",
       " [22, 5, 0.22727272727272727, 0.044168226],\n",
       " [14, 5, 0.35714285714285715, 0.034229867],\n",
       " [19, 2, 0.10526315789473684, 0.106571786],\n",
       " [14, 3, 0.21428571428571427, 0.050115664],\n",
       " [17, 3, 0.17647058823529413, 0.060335923],\n",
       " [12, 4, 0.3333333333333333, 0.058511667],\n",
       " [15, 3, 0.2, 0.053137418],\n",
       " [25, 4, 0.16, 0.12982492],\n",
       " [13, 4, 0.3076923076923077, 0.057614945],\n",
       " [13, 4, 0.3076923076923077, 0.07043577],\n",
       " [23, 4, 0.17391304347826086, 0.100635745],\n",
       " [23, 4, 0.17391304347826086, 0.10515034],\n",
       " [31, 4, 0.12903225806451613, 0.16440363],\n",
       " [20, 5, 0.25, 0.09782046],\n",
       " [28, 3, 0.10714285714285714, 0.10090029],\n",
       " [20, 7, 0.35, 0.054444853],\n",
       " [28, 9, 0.32142857142857145, 0.08932468],\n",
       " [11, 2, 0.18181818181818182, 0.05606486],\n",
       " [17, 4, 0.23529411764705882, 0.05867237],\n",
       " [19, 6, 0.3157894736842105, 0.031048493],\n",
       " [17, 2, 0.11764705882352941, 0.14332798],\n",
       " [15, 3, 0.2, 0.051539402],\n",
       " [15, 2, 0.13333333333333333, 0.014057791],\n",
       " [17, 2, 0.11764705882352941, 0.058251012],\n",
       " [5, 1, 0.2, 0.036675286],\n",
       " [22, 11, 0.5, 0.041907094],\n",
       " [14, 3, 0.21428571428571427, 0.046492986],\n",
       " [20, 5, 0.25, 0.07353595],\n",
       " [26, 5, 0.19230769230769232, 0.055336934],\n",
       " [11, 2, 0.18181818181818182, 0.03938392],\n",
       " [16, 4, 0.25, 0.0632218],\n",
       " [16, 3, 0.1875, 0.10509849],\n",
       " [15, 4, 0.26666666666666666, 0.03381626],\n",
       " [15, 2, 0.13333333333333333, 0.05754051],\n",
       " [10, 2, 0.2, 0.04054502],\n",
       " [28, 7, 0.25, 0.062439647],\n",
       " [29, 13, 0.4482758620689655, 0.12307203],\n",
       " [26, 5, 0.19230769230769232, 0.15842797],\n",
       " [35, 8, 0.22857142857142856, 0.13842574],\n",
       " [30, 5, 0.16666666666666666, 0.061807584],\n",
       " [19, 9, 0.47368421052631576, 0.04031808],\n",
       " [17, 7, 0.4117647058823529, 0.0471012],\n",
       " [16, 2, 0.125, 0.08255981],\n",
       " [11, 2, 0.18181818181818182, 0.05116613],\n",
       " [20, 4, 0.2, 0.07904879],\n",
       " [13, 3, 0.23076923076923078, 0.051541127],\n",
       " [7, 5, 0.7142857142857143, 0.014712341],\n",
       " [17, 8, 0.47058823529411764, 0.033546418],\n",
       " [19, 4, 0.21052631578947367, 0.080736876],\n",
       " [13, 2, 0.15384615384615385, 0.06326729],\n",
       " [14, 5, 0.35714285714285715, 0.043651488],\n",
       " [21, 3, 0.14285714285714285, 0.07797196],\n",
       " [22, 4, 0.18181818181818182, 0.20742446],\n",
       " [11, 2, 0.18181818181818182, 0.088960245],\n",
       " [15, 4, 0.26666666666666666, 0.040394045],\n",
       " [16, 6, 0.375, 0.040866647],\n",
       " [21, 8, 0.38095238095238093, 0.11855636],\n",
       " [36, 8, 0.2222222222222222, 0.12754437],\n",
       " [12, 5, 0.4166666666666667, 0.03638817],\n",
       " [13, 4, 0.3076923076923077, 0.056018032],\n",
       " [17, 2, 0.11764705882352941, 0.037837267],\n",
       " [28, 11, 0.39285714285714285, 0.030346543],\n",
       " [10, 1, 0.1, 0.040089954],\n",
       " [10, 4, 0.4, 0.028722465],\n",
       " [21, 3, 0.14285714285714285, 0.05120994],\n",
       " [14, 2, 0.14285714285714285, 0.049133524],\n",
       " [32, 9, 0.28125, 0.12087138],\n",
       " [18, 4, 0.2222222222222222, 0.03502474],\n",
       " [19, 9, 0.47368421052631576, 0.060803864],\n",
       " [23, 3, 0.13043478260869565, 0.08667297],\n",
       " [11, 6, 0.5454545454545454, 0.012125151],\n",
       " [13, 2, 0.15384615384615385, 0.12234199],\n",
       " [17, 2, 0.11764705882352941, 0.16158925],\n",
       " [22, 4, 0.18181818181818182, 0.12977493],\n",
       " [30, 6, 0.2, 0.07319846],\n",
       " [23, 3, 0.13043478260869565, 0.06467216],\n",
       " [28, 3, 0.10714285714285714, 0.09684515],\n",
       " [22, 5, 0.22727272727272727, 0.06390911],\n",
       " [15, 4, 0.26666666666666666, 0.047680154],\n",
       " [12, 4, 0.3333333333333333, 0.06296874],\n",
       " [18, 3, 0.16666666666666666, 0.041178524],\n",
       " [12, 6, 0.5, 0.024142211],\n",
       " [13, 6, 0.46153846153846156, 0.023551598],\n",
       " [18, 2, 0.1111111111111111, 0.07320491],\n",
       " [12, 2, 0.16666666666666666, 0.031890508],\n",
       " [10, 1, 0.1, 0.04190429],\n",
       " [11, 2, 0.18181818181818182, 0.06110678],\n",
       " [7, 3, 0.42857142857142855, 0.03516112],\n",
       " [12, 3, 0.25, 0.044880338],\n",
       " [11, 2, 0.18181818181818182, 0.08992187],\n",
       " [15, 2, 0.13333333333333333, 0.07512745],\n",
       " [15, 2, 0.13333333333333333, 0.086702295],\n",
       " [30, 4, 0.13333333333333333, 0.043100968],\n",
       " [18, 3, 0.16666666666666666, 0.053312674],\n",
       " [29, 11, 0.3793103448275862, 0.10659294],\n",
       " [22, 3, 0.13636363636363635, 0.14074005],\n",
       " [16, 5, 0.3125, 0.028484188],\n",
       " [15, 8, 0.5333333333333333, 0.028201735],\n",
       " [6, 5, 0.8333333333333334, 0.016229577],\n",
       " [21, 4, 0.19047619047619047, 0.124342635],\n",
       " [16, 2, 0.125, 0.07343537],\n",
       " [17, 3, 0.17647058823529413, 0.036613267],\n",
       " [18, 4, 0.2222222222222222, 0.056291196],\n",
       " [21, 12, 0.5714285714285714, 0.042667408],\n",
       " [17, 8, 0.47058823529411764, 0.023014752],\n",
       " [37, 18, 0.4864864864864865, 0.10018177],\n",
       " [22, 16, 0.7272727272727273, 0.024922455],\n",
       " [21, 4, 0.19047619047619047, 0.05794631],\n",
       " [17, 11, 0.6470588235294118, 0.034692343],\n",
       " [29, 5, 0.1724137931034483, 0.11180302],\n",
       " [18, 9, 0.5, 0.027860025],\n",
       " [24, 7, 0.2916666666666667, 0.08404938],\n",
       " [19, 6, 0.3157894736842105, 0.027877472],\n",
       " [13, 2, 0.15384615384615385, 0.057358474],\n",
       " [10, 4, 0.4, 0.03409291],\n",
       " [23, 5, 0.21739130434782608, 0.091311105],\n",
       " [23, 4, 0.17391304347826086, 0.051713552],\n",
       " [20, 2, 0.1, 0.1675251],\n",
       " [16, 3, 0.1875, 0.08065844],\n",
       " [10, 5, 0.5, 0.021308318],\n",
       " [7, 1, 0.14285714285714285, 0.047478955],\n",
       " [17, 4, 0.23529411764705882, 0.04876547],\n",
       " [26, 13, 0.5, 0.031773],\n",
       " [11, 2, 0.18181818181818182, 0.05043797],\n",
       " [28, 14, 0.5, 0.120660834],\n",
       " [9, 4, 0.4444444444444444, 0.056328993],\n",
       " [13, 6, 0.46153846153846156, 0.021736868],\n",
       " [21, 7, 0.3333333333333333, 0.064752884],\n",
       " [10, 4, 0.4, 0.019712636],\n",
       " [16, 4, 0.25, 0.053417522],\n",
       " [8, 2, 0.25, 0.060692392],\n",
       " [20, 7, 0.35, 0.040211268],\n",
       " [13, 6, 0.46153846153846156, 0.039755408],\n",
       " [13, 3, 0.23076923076923078, 0.03997905],\n",
       " [28, 3, 0.10714285714285714, 0.19778866],\n",
       " [31, 5, 0.16129032258064516, 0.09796424],\n",
       " [9, 1, 0.1111111111111111, 0.057330847],\n",
       " [28, 4, 0.14285714285714285, 0.1679723],\n",
       " [8, 2, 0.25, 0.04638957],\n",
       " [12, 5, 0.4166666666666667, 0.04104831],\n",
       " [11, 6, 0.5454545454545454, 0.031563874],\n",
       " [16, 2, 0.125, 0.093603685],\n",
       " [14, 4, 0.2857142857142857, 0.05546373],\n",
       " [30, 10, 0.3333333333333333, 0.07063229],\n",
       " [13, 4, 0.3076923076923077, 0.041859224],\n",
       " [15, 5, 0.3333333333333333, 0.06824579],\n",
       " [19, 5, 0.2631578947368421, 0.07276793],\n",
       " [24, 5, 0.20833333333333334, 0.16326283],\n",
       " [12, 9, 0.75, 0.037168518],\n",
       " [11, 2, 0.18181818181818182, 0.058170073],\n",
       " [12, 6, 0.5, 0.036075827],\n",
       " [24, 6, 0.25, 0.0636565],\n",
       " [12, 3, 0.25, 0.04530174],\n",
       " [21, 6, 0.2857142857142857, 0.096656695],\n",
       " [22, 4, 0.18181818181818182, 0.034190785],\n",
       " [17, 3, 0.17647058823529413, 0.048745364],\n",
       " [17, 5, 0.29411764705882354, 0.034691162],\n",
       " [13, 2, 0.15384615384615385, 0.07202729],\n",
       " [14, 3, 0.21428571428571427, 0.043795295],\n",
       " [17, 5, 0.29411764705882354, 0.047709078],\n",
       " [16, 2, 0.125, 0.078586206],\n",
       " [29, 6, 0.20689655172413793, 0.10929839],\n",
       " [23, 3, 0.13043478260869565, 0.15665051],\n",
       " [8, 2, 0.25, 0.029112624],\n",
       " [19, 6, 0.3157894736842105, 0.043330126],\n",
       " [25, 12, 0.48, 0.043029115],\n",
       " [10, 1, 0.1, 0.055145502],\n",
       " [7, 4, 0.5714285714285714, 0.030834451],\n",
       " [22, 7, 0.3181818181818182, 0.029519245],\n",
       " [19, 2, 0.10526315789473684, 0.037706178],\n",
       " [16, 4, 0.25, 0.053949576],\n",
       " [18, 4, 0.2222222222222222, 0.04665152],\n",
       " [12, 3, 0.25, 0.03915396],\n",
       " [13, 2, 0.15384615384615385, 0.11042948],\n",
       " [11, 2, 0.18181818181818182, 0.029858898],\n",
       " [20, 5, 0.25, 0.062902644],\n",
       " [21, 10, 0.47619047619047616, 0.027044293],\n",
       " [18, 2, 0.1111111111111111, 0.18379463],\n",
       " [18, 7, 0.3888888888888889, 0.07906426],\n",
       " [19, 4, 0.21052631578947367, 0.056678016],\n",
       " [30, 5, 0.16666666666666666, 0.11935483],\n",
       " [10, 4, 0.4, 0.029962214],\n",
       " [28, 4, 0.14285714285714285, 0.08867528],\n",
       " [15, 2, 0.13333333333333333, 0.08788375],\n",
       " [18, 7, 0.3888888888888889, 0.039368305],\n",
       " [21, 3, 0.14285714285714285, 0.054519564],\n",
       " [14, 2, 0.14285714285714285, 0.054367177],\n",
       " [20, 4, 0.2, 0.029992508],\n",
       " [13, 3, 0.23076923076923078, 0.054006286],\n",
       " [12, 3, 0.25, 0.06445576],\n",
       " [9, 1, 0.1111111111111111, 0.040233046],\n",
       " [15, 6, 0.4, 0.05108502],\n",
       " [22, 3, 0.13636363636363635, 0.04510475],\n",
       " [28, 6, 0.21428571428571427, 0.13247238],\n",
       " [30, 6, 0.2, 0.026025333],\n",
       " [28, 3, 0.10714285714285714, 0.08618416],\n",
       " [20, 7, 0.35, 0.09249371],\n",
       " [28, 5, 0.17857142857142858, 0.13520241],\n",
       " [14, 2, 0.14285714285714285, 0.026398659],\n",
       " [12, 4, 0.3333333333333333, 0.039006926],\n",
       " [15, 2, 0.13333333333333333, 0.116758496],\n",
       " [12, 2, 0.16666666666666666, 0.06022475],\n",
       " [10, 2, 0.2, 0.03678969],\n",
       " [12, 6, 0.5, 0.031073669],\n",
       " [25, 7, 0.28, 0.11981537],\n",
       " [15, 4, 0.26666666666666666, 0.042766266],\n",
       " [16, 5, 0.3125, 0.031208826],\n",
       " [14, 2, 0.14285714285714285, 0.031629387],\n",
       " [13, 4, 0.3076923076923077, 0.05068242],\n",
       " [23, 14, 0.6086956521739131, 0.04176261],\n",
       " [6, 2, 0.3333333333333333, 0.021435693],\n",
       " [14, 4, 0.2857142857142857, 0.07211774],\n",
       " [18, 6, 0.3333333333333333, 0.023488037],\n",
       " [12, 5, 0.4166666666666667, 0.0237215],\n",
       " [27, 8, 0.2962962962962963, 0.12680116],\n",
       " [11, 3, 0.2727272727272727, 0.0571131],\n",
       " [18, 5, 0.2777777777777778, 0.034839828],\n",
       " [20, 5, 0.25, 0.1610678],\n",
       " [23, 3, 0.13043478260869565, 0.05445832],\n",
       " [30, 3, 0.1, 0.10871468],\n",
       " [20, 2, 0.1, 0.08819962],\n",
       " [12, 2, 0.16666666666666666, 0.0597789],\n",
       " [18, 5, 0.2777777777777778, 0.06712898],\n",
       " [14, 4, 0.2857142857142857, 0.029451406],\n",
       " [12, 4, 0.3333333333333333, 0.024222076],\n",
       " [18, 4, 0.2222222222222222, 0.11823789],\n",
       " [22, 5, 0.22727272727272727, 0.09165008],\n",
       " [13, 4, 0.3076923076923077, 0.05080585],\n",
       " [19, 4, 0.21052631578947367, 0.10855588],\n",
       " [12, 2, 0.16666666666666666, 0.037669104],\n",
       " [9, 7, 0.7777777777777778, 0.010424292],\n",
       " [14, 7, 0.5, 0.018239193],\n",
       " [37, 9, 0.24324324324324326, 0.16377865],\n",
       " [39, 9, 0.23076923076923078, 0.21095712],\n",
       " [17, 2, 0.11764705882352941, 0.03957658],\n",
       " [30, 3, 0.1, 0.099534094],\n",
       " [14, 3, 0.21428571428571427, 0.06739681],\n",
       " [15, 3, 0.2, 0.031505894],\n",
       " [26, 4, 0.15384615384615385, 0.13305391],\n",
       " [13, 2, 0.15384615384615385, 0.07047596],\n",
       " [23, 5, 0.21739130434782608, 0.064497195],\n",
       " [26, 5, 0.19230769230769232, 0.06946342],\n",
       " [17, 4, 0.23529411764705882, 0.05113423],\n",
       " [17, 9, 0.5294117647058824, 0.031893328],\n",
       " [16, 4, 0.25, 0.095810175],\n",
       " [16, 3, 0.1875, 0.06821135],\n",
       " [19, 4, 0.21052631578947367, 0.122454524],\n",
       " [23, 4, 0.17391304347826086, 0.04963891],\n",
       " [17, 6, 0.35294117647058826, 0.054979797],\n",
       " [9, 3, 0.3333333333333333, 0.037720222],\n",
       " [20, 8, 0.4, 0.08474234],\n",
       " [13, 6, 0.46153846153846156, 0.03280173],\n",
       " [15, 2, 0.13333333333333333, 0.079895325],\n",
       " [37, 14, 0.3783783783783784, 0.07225181],\n",
       " [20, 2, 0.1, 0.09262926],\n",
       " [13, 5, 0.38461538461538464, 0.05476376],\n",
       " [19, 4, 0.21052631578947367, 0.056951206],\n",
       " [20, 13, 0.65, 0.05038769],\n",
       " [21, 5, 0.23809523809523808, 0.09122369],\n",
       " [16, 5, 0.3125, 0.05522251],\n",
       " [31, 6, 0.1935483870967742, 0.093962245],\n",
       " [19, 4, 0.21052631578947367, 0.0963152],\n",
       " [22, 4, 0.18181818181818182, 0.06232163],\n",
       " [13, 5, 0.38461538461538464, 0.04130368],\n",
       " [23, 7, 0.30434782608695654, 0.09136312],\n",
       " [13, 8, 0.6153846153846154, 0.02576261],\n",
       " [36, 7, 0.19444444444444445, 0.09527315],\n",
       " [21, 5, 0.23809523809523808, 0.044137917],\n",
       " [18, 3, 0.16666666666666666, 0.0733241],\n",
       " [22, 4, 0.18181818181818182, 0.07488662],\n",
       " [22, 5, 0.22727272727272727, 0.05075661],\n",
       " [16, 5, 0.3125, 0.04130226],\n",
       " [16, 5, 0.3125, 0.07145742],\n",
       " [22, 4, 0.18181818181818182, 0.11300353],\n",
       " [23, 3, 0.13043478260869565, 0.09098654],\n",
       " [20, 3, 0.15, 0.14653502],\n",
       " [22, 7, 0.3181818181818182, 0.055820383],\n",
       " [11, 2, 0.18181818181818182, 0.048335467],\n",
       " [25, 6, 0.24, 0.08620256],\n",
       " [16, 2, 0.125, 0.070688486],\n",
       " [15, 6, 0.4, 0.025233809],\n",
       " [10, 5, 0.5, 0.010760397],\n",
       " [18, 4, 0.2222222222222222, 0.044057418],\n",
       " [14, 4, 0.2857142857142857, 0.033392992],\n",
       " [15, 4, 0.26666666666666666, 0.08161182],\n",
       " [11, 3, 0.2727272727272727, 0.03871792],\n",
       " [8, 1, 0.125, 0.06636937],\n",
       " [24, 5, 0.20833333333333334, 0.05330441],\n",
       " [8, 1, 0.125, 0.039183438],\n",
       " [21, 4, 0.19047619047619047, 0.05111884],\n",
       " [11, 6, 0.5454545454545454, 0.016534641],\n",
       " [20, 7, 0.35, 0.06144538],\n",
       " [14, 3, 0.21428571428571427, 0.033711],\n",
       " [26, 7, 0.2692307692307692, 0.14835432],\n",
       " [20, 5, 0.25, 0.04511258],\n",
       " [11, 8, 0.7272727272727273, 0.014141483],\n",
       " [28, 3, 0.10714285714285714, 0.11620183],\n",
       " [28, 7, 0.25, 0.22251678],\n",
       " [22, 4, 0.18181818181818182, 0.18941694],\n",
       " [22, 7, 0.3181818181818182, 0.057896767],\n",
       " [20, 3, 0.15, 0.055632688],\n",
       " [28, 6, 0.21428571428571427, 0.08695105],\n",
       " [20, 5, 0.25, 0.06290323],\n",
       " [26, 4, 0.15384615384615385, 0.06931349],\n",
       " [23, 8, 0.34782608695652173, 0.07172046],\n",
       " [10, 6, 0.6, 0.022434004],\n",
       " [12, 6, 0.5, 0.018175183],\n",
       " [12, 6, 0.5, 0.024823753],\n",
       " [27, 14, 0.5185185185185185, 0.05846082],\n",
       " [18, 4, 0.2222222222222222, 0.055036575],\n",
       " [18, 2, 0.1111111111111111, 0.10111412],\n",
       " [21, 3, 0.14285714285714285, 0.09062365],\n",
       " [33, 7, 0.21212121212121213, 0.10046143],\n",
       " [13, 5, 0.38461538461538464, 0.045394517],\n",
       " [13, 5, 0.38461538461538464, 0.10139558],\n",
       " [23, 6, 0.2608695652173913, 0.056313816],\n",
       " [22, 8, 0.36363636363636365, 0.12175186],\n",
       " [26, 5, 0.19230769230769232, 0.06261373],\n",
       " [23, 3, 0.13043478260869565, 0.12316726],\n",
       " [26, 11, 0.4230769230769231, 0.09037086],\n",
       " [12, 7, 0.5833333333333334, 0.015318009],\n",
       " [30, 5, 0.16666666666666666, 0.14774916],\n",
       " [29, 3, 0.10344827586206896, 0.056821406],\n",
       " [21, 4, 0.19047619047619047, 0.09521351]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(good_docs[3]['energies_per_step'])\n",
    "plt.show()\n",
    "plt.plot(good_docs[3]['distances_per_step'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, reduced, bad_docs, bad_result,good_docs,good_result = analysis(SDT_valid, docs_val, distance_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '% Reduced')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(reduced, bins=40)\n",
    "plt.title(\"Train\")\n",
    "plt.xlabel(\"% Reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'slab'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_train[0]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for doc in good_docs:\n",
    "    f.append(doc['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'surface': 228, 'slab': 367})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23540377362260173"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "natoms =[]\n",
    "types = []\n",
    "steps = []\n",
    "distances = []\n",
    "filtered_idx = []\n",
    "\n",
    "for doc in bad_docs:\n",
    "    natoms.append(doc['atoms']['natoms'])\n",
    "    types.extend(doc['atoms']['chemical_symbols'])\n",
    "    atoms = mongo.make_atoms_from_doc(doc, is_initial=True)\n",
    "    atoms_final = mongo.make_atoms_from_doc(doc, is_initial=False)\n",
    "    if atoms.constraints:\n",
    "        fixed_atom_idx = atoms.constraints[0].index\n",
    "        base = np.ones(len(atoms.positions))\n",
    "        base[fixed_atom_idx] = 0\n",
    "        free_atom_idx = np.where(base==1)[0]\n",
    "        \n",
    "    else:\n",
    "        free_atom_idx = np.arange(len(atoms))\n",
    "    difference = atoms.positions[free_atom_idx] - atoms_final.positions[free_atom_idx]\n",
    "    dist = np.sqrt(np.sum(difference**2, axis=1))\n",
    "    distances.append(dist)    \n",
    "    if np.mean(dist) > 0.05:\n",
    "        filtered_idx.append(doc['idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mean=[]\n",
    "for dist in distances:\n",
    "    d_mean.append(np.mean(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9., 5., 9., 3., 2., 2., 7., 8., 2., 4., 7., 4., 3., 2., 1., 1., 3.,\n",
       "        2., 1., 5., 3., 1., 1., 3., 1., 1., 1., 2., 0., 2., 0., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 2., 3., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.]),\n",
       " array([0.04009705, 0.04491276, 0.04972846, 0.05454417, 0.05935988,\n",
       "        0.06417559, 0.06899129, 0.073807  , 0.07862271, 0.08343841,\n",
       "        0.08825412, 0.09306983, 0.09788553, 0.10270124, 0.10751695,\n",
       "        0.11233266, 0.11714836, 0.12196407, 0.12677978, 0.13159548,\n",
       "        0.13641119, 0.1412269 , 0.14604261, 0.15085831, 0.15567402,\n",
       "        0.16048973, 0.16530543, 0.17012114, 0.17493685, 0.17975255,\n",
       "        0.18456826, 0.18938397, 0.19419968, 0.19901538, 0.20383109,\n",
       "        0.2086468 , 0.2134625 , 0.21827821, 0.22309392, 0.22790962,\n",
       "        0.23272533, 0.23754104, 0.24235675, 0.24717245, 0.25198816,\n",
       "        0.25680387, 0.26161957, 0.26643528, 0.27125099, 0.2760667 ,\n",
       "        0.2808824 ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(d_mean, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9., 5., 9., 3., 2., 2., 7., 8., 2., 4., 7., 4., 3., 2., 1., 1., 3.,\n",
       "        2., 1., 5., 3., 1., 1., 3., 1., 1., 1., 2., 0., 2., 0., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 2., 3., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.]),\n",
       " array([0.04009705, 0.04491276, 0.04972846, 0.05454417, 0.05935988,\n",
       "        0.06417559, 0.06899129, 0.073807  , 0.07862271, 0.08343841,\n",
       "        0.08825412, 0.09306983, 0.09788553, 0.10270124, 0.10751695,\n",
       "        0.11233266, 0.11714836, 0.12196407, 0.12677978, 0.13159548,\n",
       "        0.13641119, 0.1412269 , 0.14604261, 0.15085831, 0.15567402,\n",
       "        0.16048973, 0.16530543, 0.17012114, 0.17493685, 0.17975255,\n",
       "        0.18456826, 0.18938397, 0.19419968, 0.19901538, 0.20383109,\n",
       "        0.2086468 , 0.2134625 , 0.21827821, 0.22309392, 0.22790962,\n",
       "        0.23272533, 0.23754104, 0.24235675, 0.24717245, 0.25198816,\n",
       "        0.25680387, 0.26161957, 0.26643528, 0.27125099, 0.2760667 ,\n",
       "        0.2808824 ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(d_mean, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
