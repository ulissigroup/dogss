{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "import mongo\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import mongo\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocess as mp\n",
    "\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lbfgs import LBFGS\n",
    "from cgcnn.data_orbital_sigopt import StructureData, ListDataset, StructureDataTransformer, collate_pool, MergeDataset\n",
    "from cgcnn.model_sigopt import CrystalGraphConvNet\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split\n",
    "\n",
    "from utils.skorch import NeuralNetRegressor\n",
    "from utils.skorch.callbacks import Checkpoint, LoadInitState #needs skorch 0.4.0, conda-forge version at 0.3.0 doesn't cut it\n",
    "import utils.skorch.callbacks.base\n",
    "from utils.skorch.dataset import CVSplit\n",
    "from utils.skorch.callbacks.lr_scheduler import WarmRestartLR, LRScheduler\n",
    "\n",
    "from utils.adamwr.adamw import AdamW\n",
    "from utils.adamwr.cosine_scheduler import CosineLRWithRestarts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDT_list = pickle.load(open('./input_12_nbrs_40_steps/SDT_list.pkl', 'rb'))\n",
    "docs = pickle.load(open('./input_12_nbrs_40_steps/final_docs.pkl', 'rb'))\n",
    "\n",
    "target_list = []\n",
    "for sdt in SDT_list:\n",
    "    free_atom_idx = sdt[-2]\n",
    "    target_list.append(sdt[-1][free_atom_idx].numpy())\n",
    "target_list = np.array(target_list).reshape(-1,1)\n",
    "\n",
    "structures = SDT_list[0]\n",
    "orig_atom_fea_len = structures[0].shape[-1]\n",
    "nbr_fea_len = structures[1].shape[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDT_training, SDT_test, target_training, target_test, docs_training, docs_test \\\n",
    "= train_test_split(SDT_list, target_list, docs, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# atom_fea = SDT_list[0][0]\n",
    "# nbr_fea = SDT_list[0][1]\n",
    "# nbr_fea_idx = SDT_list[0][2]\n",
    "# nbr_fea_offset = SDT_list[0][3]\n",
    "# atom_pos =SDT_list[0][4]\n",
    "# nbr_pos = SDT_list[0][5] \n",
    "# atom_pos_idx = SDT_list[0][6]\n",
    "# cells = SDT_list[0][7]\n",
    "# fixed_base = SDT_list[0][8]\n",
    "# free_atom_idx = SDT_list[0][9]\n",
    "# atom_pos_final = SDT_list[0][10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device='cpu'\n",
    "\n",
    "#Make a checkpoint to save parameters every time there is a new best for validation lost\n",
    "cp = Checkpoint(monitor='valid_loss_best',fn_prefix='./surface_slab/valid_best_')\n",
    "\n",
    "#Callback to load the checkpoint with the best validation loss at the end of training\n",
    "\n",
    "class train_end_load_best_valid_loss(skorch.callbacks.base.Callback):\n",
    "    def on_train_end(self, net, X, y):\n",
    "        net.load_params('./surface_slab/valid_best_params.pt')\n",
    "        \n",
    "load_best_valid_loss = train_end_load_best_valid_loss()\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13180643"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def diff(sdt, target):\n",
    "    fixed_base = sdt[8]\n",
    "    free_atom_idx = np.where(fixed_base == 0)[0]\n",
    "    free_atom_idx = torch.LongTensor(free_atom_idx)   \n",
    "    diff = np.sum(((target[0] - sdt[4].numpy()[free_atom_idx]))**2.,axis=1)**0.5 \n",
    "    return diff\n",
    "\n",
    "np.mean(np.abs(np.concatenate([diff(sdt, target) for sdt,target in zip(SDT_list, target_list)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059983693"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def diff_position(sdt, target):\n",
    "    fixed_base = sdt[8]\n",
    "    free_atom_idx = np.where(fixed_base == 0)[0]\n",
    "    free_atom_idx = torch.LongTensor(free_atom_idx)   \n",
    "    diff = (target[0] - sdt[4].numpy()[free_atom_idx])\n",
    "    return diff\n",
    "\n",
    "differences = []\n",
    "for sdt, target in zip(SDT_list, target_list):\n",
    "    differences.append(diff_position(sdt, target))\n",
    "differences = np.concatenate(differences)\n",
    "np.mean(np.abs(differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_test_splitter = ShuffleSplit(test_size=0.1, random_state=42)\n",
    "\n",
    "batchsize = 60\n",
    "# warm restart scheduling from https://arxiv.org/pdf/1711.05101.pdf\n",
    "LR_schedule = LRScheduler(CosineLRWithRestarts, batch_size=batchsize, epoch_size=len(SDT_training), restart_period=10, t_mult=1.2)\n",
    "\n",
    "#############\n",
    "# To extract intermediate features, set the forward takes only the first return value to calculate loss\n",
    "class MyNet(NeuralNetRegressor):\n",
    "    def get_loss(self, y_pred, y_true, **kwargs):        \n",
    "        y_pred = y_pred[0] if isinstance(y_pred, tuple) else y_pred  # discard the 2nd output\n",
    "        differ=torch.sum((y_pred - y_true.cuda())**2.0,dim=1)\n",
    "        if torch.nonzero(differ).shape[0] != differ.shape[0]:\n",
    "            print('zero sqrt for Loss')\n",
    "\n",
    "#         differ = torch.clamp(differ, min=1e-8)\n",
    "        return torch.mean(torch.sqrt(differ))\n",
    "\n",
    "net = MyNet(\n",
    "    CrystalGraphConvNet,\n",
    "    module__orig_atom_fea_len = orig_atom_fea_len,\n",
    "    module__nbr_fea_len = nbr_fea_len,\n",
    "    batch_size=batchsize, #214\n",
    "    module__classification=False,\n",
    "    lr=0.0056,\n",
    "    max_epochs= 400,\n",
    "    module__energy_mode=\"Harmonic\", #[\"Harmonic\", \"Morse\", \"LJ\"], Default = \"Harmonic\"\n",
    "    module__atom_fea_len=46, #46,\n",
    "    module__h_fea_len=83,\n",
    "    module__h_fea_len_dist=83,\n",
    "    module__h_fea_len_const=83,\n",
    "    module__h_fea_len_D=83,\n",
    "    module__n_conv=6, #8\n",
    "    module__n_h_dist=8,\n",
    "    module__n_h_const=8,\n",
    "    module__n_h_D=8,\n",
    "    module__max_num_nbr=12, #9\n",
    "    module__opt_step_size=0.3, #0.3\n",
    "    module__min_opt_steps=30,\n",
    "    module__max_opt_steps=300,\n",
    "    module__momentum=0.8,\n",
    "    optimizer__weight_decay=1e-3,\n",
    "    optimizer=AdamW,\n",
    "    iterator_train__pin_memory=True,\n",
    "    iterator_train__num_workers=0,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__collate_fn = collate_pool,\n",
    "    iterator_valid__pin_memory=True,\n",
    "    iterator_valid__num_workers=0,\n",
    "    iterator_valid__collate_fn = collate_pool,\n",
    "    device=device,\n",
    "#     criterion=torch.nn.MSELoss,\n",
    "    criterion=torch.nn.L1Loss,\n",
    "    dataset=MergeDataset,\n",
    "    train_split = CVSplit(cv=train_test_splitter),\n",
    "    callbacks=[cp, LR_schedule, load_best_valid_loss]\n",
    ")\n",
    "# net.initialize()\n",
    "# net.load_params(f_history = './surface_slab_orbital5/valid_best_history.json',\n",
    "#                f_optimizer = './surface_slab_orbital5/valid_best_optimizer.pt',\n",
    "#                f_params = './surface_slab_orbital5/valid_best_params.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: atom_fea_len, classification, energy_mode, h_fea_len, h_fea_len_D, h_fea_len_const, h_fea_len_dist, max_num_nbr, max_opt_steps, min_opt_steps, momentum, n_conv, n_h_D, n_h_const, n_h_dist, nbr_fea_len, opt_step_size, orig_atom_fea_len.\n",
      "Re-initializing optimizer because the following parameters were re-set: weight_decay.\n",
      "blow up\n",
      "blow up\n",
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "      1        \u001b[36m0.1814\u001b[0m        \u001b[32m0.1226\u001b[0m     +  34.3449\n",
      "      2        \u001b[36m0.1113\u001b[0m        \u001b[32m0.1113\u001b[0m     +  36.4282\n",
      "      3        \u001b[36m0.1071\u001b[0m        \u001b[32m0.1055\u001b[0m     +  37.5195\n",
      "      4        \u001b[36m0.1024\u001b[0m        0.1115        38.0404\n",
      "      5        \u001b[36m0.0977\u001b[0m        \u001b[32m0.1054\u001b[0m     +  38.4290\n",
      "      6        \u001b[36m0.0961\u001b[0m        \u001b[32m0.0985\u001b[0m     +  38.5251\n",
      "      7        \u001b[36m0.0922\u001b[0m        \u001b[32m0.0968\u001b[0m     +  38.6952\n",
      "      8        0.0924        \u001b[32m0.0944\u001b[0m     +  94.1553\n",
      "      9        \u001b[36m0.0904\u001b[0m        \u001b[32m0.0918\u001b[0m     +  93.6456\n",
      "     10        \u001b[36m0.0861\u001b[0m        \u001b[32m0.0917\u001b[0m     +  89.7869\n",
      "     11        0.1079        0.1014        86.2800\n",
      "     12        0.0960        0.0986        88.3226\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './surface_slab/valid_best_params.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0cf85e7ab73c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSDT_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Differentiable_Optimization_GCN/skorch/regressor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Differentiable_Optimization_GCN/skorch/net.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Differentiable_Optimization_GCN/skorch/net.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Differentiable_Optimization_GCN/skorch/net.py\u001b[0m in \u001b[0;36mnotify\u001b[0;34m(self, method_name, **cb_kwargs)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-4dacc7a7d2fb>\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self, net, X, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mtrain_end_load_best_valid_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./surface_slab/valid_best_params.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mload_best_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_end_load_best_valid_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Differentiable_Optimization_GCN/skorch/net.py\u001b[0m in \u001b[0;36mload_params\u001b[0;34m(self, f, f_params, f_optimizer, f_history, checkpoint)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Differentiable_Optimization_GCN/skorch/net.py\u001b[0m in \u001b[0;36m_get_state_dict\u001b[0;34m(f)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './surface_slab/valid_best_params.pt'"
     ]
    }
   ],
   "source": [
    "net.initialize()\n",
    "net.fit(SDT_training, target_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    197        0.0567        0.0743        78.2388\n",
      "    198        0.0595        0.0738        76.9012\n",
      "    199        0.0578        0.0760        77.5858\n",
      "    200        0.0564        0.0731        83.0572\n",
      "    201        0.0554        0.0712        81.9666\n",
      "    202        0.0526        0.0702        82.6545\n",
      "    203        0.0509        0.0694        82.8548\n",
      "    204        0.0495        0.0694        84.6522\n",
      "    205        0.0496        \u001b[32m0.0691\u001b[0m     +  84.0187\n",
      "    206        0.0474        0.0691        83.7507\n",
      "    207        0.0611        0.0746        80.4206\n",
      "    208        0.0590        0.0739        74.8967\n",
      "    209        0.0574        0.0724        78.3725\n",
      "    210        0.0574        0.0716        80.0487\n",
      "    211        0.0548        0.0707        78.7660\n",
      "    212        0.0520        0.0702        77.7117\n",
      "    213        0.0522        0.0705        81.3962\n",
      "    214        0.0521        0.0703        81.3414\n",
      "    215        0.0470        0.0695        83.9399\n",
      "    216        0.0505        0.0691        84.7713\n",
      "    217        0.0477        \u001b[32m0.0690\u001b[0m     +  86.0599\n",
      "    218        \u001b[36m0.0450\u001b[0m        \u001b[32m0.0689\u001b[0m     +  82.1897\n",
      "    219        0.0557        0.0768        78.1830\n",
      "    220        0.0593        0.0762        76.0620\n",
      "    221        0.0574        0.0716        79.1726\n",
      "    222        0.0561        0.0716        80.6522\n",
      "    223        0.0542        0.0716        79.6125\n",
      "    224        0.0530        0.0715        80.5830\n",
      "    225        0.0548        0.0714        83.6573\n",
      "    226        0.0511        0.0698        85.3854\n",
      "    227        0.0495        0.0700        85.0340\n",
      "    228        0.0478        0.0696        83.3002\n",
      "    229        0.0488        0.0694        83.0210\n",
      "    230        0.0457        0.0692        83.3727\n",
      "    231        0.0465        \u001b[32m0.0688\u001b[0m     +  86.1135\n",
      "    232        0.0451        0.0688        84.8372\n",
      "    233        \u001b[36m0.0449\u001b[0m        0.0690        90.1095\n",
      "    234        0.0533        0.0736        78.5942\n",
      "    235        0.0555        0.0755        83.2888\n",
      "    236        0.0538        0.0732        82.5109\n",
      "    237        0.0558        0.0724        77.3559\n",
      "    238        0.0536        0.0715        82.5340\n",
      "    239        0.0531        0.0727        81.1901\n",
      "    240        0.0517        0.0708        81.0769\n",
      "    241        0.0514        0.0705        80.6069\n",
      "    242        0.0506        0.0703        83.6348\n",
      "    243        0.0493        0.0699        83.9217\n",
      "    244        0.0491        0.0695        85.0243\n",
      "    245        0.0476        0.0693        84.6589\n",
      "    246        0.0466        0.0690        87.3068\n",
      "    247        0.0452        0.0691        88.5765\n",
      "    248        0.0458        0.0691        84.8046\n",
      "    249        0.0449        \u001b[32m0.0687\u001b[0m     +  85.1936\n",
      "    250        \u001b[36m0.0443\u001b[0m        0.0688        87.2131\n",
      "    251        0.0450        0.0692        88.3106\n",
      "    252        0.0552        0.0731        78.7002\n",
      "    253        0.0560        0.0736        81.4467\n",
      "    254        0.0543        0.0725        81.6648\n",
      "    255        0.0553        0.0728        78.8030\n",
      "    256        0.0554        0.0727        79.2763\n",
      "    257        0.0539        0.0717        78.3534\n",
      "    258        0.0527        0.0712        80.6509\n",
      "    259        0.0514        0.0713        81.3061\n",
      "    260        0.0484        0.0709        82.8562\n",
      "    261        0.0491        0.0710        86.8385\n",
      "    262        0.0501        0.0702        81.5321\n",
      "    263        0.0478        0.0696        84.1414\n",
      "    264        0.0468        0.0702        82.1772\n",
      "    265        0.0465        0.0696        86.7123\n",
      "    266        0.0455        0.0698        83.9874\n",
      "    267        \u001b[36m0.0441\u001b[0m        0.0690        86.9826\n",
      "    268        0.0450        0.0694        83.9078\n",
      "    269        0.0451        \u001b[32m0.0686\u001b[0m     +  88.0674\n",
      "    270        0.0444        0.0688        87.6774\n",
      "    271        \u001b[36m0.0429\u001b[0m        0.0691        88.6245\n",
      "    272        \u001b[36m0.0414\u001b[0m        0.0691        88.3353\n",
      "    273        0.0549        0.0722        80.8565\n",
      "    274        0.0544        0.0734        78.5093\n",
      "    275        0.0518        0.0728        82.9484\n",
      "    276        0.0541        0.0724        82.1188\n",
      "    277        0.0528        0.0716        84.2206\n",
      "    278        0.0528        0.0713        81.7217\n",
      "    279        0.0518        0.0718        79.3933\n",
      "    280        0.0513        0.0710        83.5628\n",
      "    281        0.0493        0.0714        83.0706\n",
      "    282        0.0512        0.0713        86.0516\n",
      "    283        0.0491        0.0708        86.4527\n",
      "    284        0.0493        0.0697        87.5172\n",
      "    285        0.0478        0.0698        83.2620\n",
      "    286        0.0478        0.0699        86.9298\n",
      "    287        0.0457        0.0695        85.9379\n",
      "    288        0.0479        0.0695        83.8898\n",
      "    289        0.0433        0.0697        84.5488\n",
      "    290        0.0428        0.0693        86.1673\n",
      "    291        0.0438        0.0690        87.1962\n",
      "    292        \u001b[36m0.0412\u001b[0m        0.0688        86.4820\n",
      "    293        0.0420        0.0689        88.4243\n",
      "    294        0.0415        0.0691        83.6773\n",
      "    295        0.0427        0.0687        86.9785\n",
      "    296        0.0430        0.0688        89.1500\n",
      "    297        0.0432        0.0687        87.6765\n",
      "    298        0.0499        0.0735        84.7487\n",
      "    299        0.0549        0.0727        83.3582\n",
      "    300        0.0529        0.0722        82.0113\n",
      "    301        0.0522        0.0723        82.4588\n",
      "    302        0.0545        0.0729        83.8906\n",
      "    303        0.0525        0.0712        82.7839\n",
      "    304        0.0504        0.0716        81.9504\n",
      "    305        0.0515        0.0709        82.3725\n",
      "    306        0.0504        0.0708        79.5186\n",
      "    307        0.0489        0.0714        85.5756\n",
      "    308        0.0495        0.0709        85.4002\n",
      "    309        0.0505        0.0707        83.7879\n",
      "    310        0.0476        0.0707        87.1696\n",
      "    311        0.0463        0.0702        85.3450\n",
      "    312        0.0468        0.0700        86.1111\n",
      "    313        0.0465        0.0693        86.4957\n",
      "    314        0.0444        0.0695        86.5990\n",
      "    315        0.0460        0.0698        84.4598\n",
      "    316        0.0432        0.0694        87.7481\n",
      "    317        0.0456        0.0688        88.9357\n",
      "    318        0.0429        0.0689        83.7598\n",
      "    319        0.0439        0.0689        88.6166\n",
      "    320        0.0432        0.0688        88.6485\n",
      "    321        \u001b[36m0.0406\u001b[0m        0.0688        87.1728\n",
      "    322        0.0420        0.0687        88.8576\n",
      "    323        \u001b[36m0.0402\u001b[0m        0.0691        84.8996\n",
      "    324        0.0410        0.0687        86.5527\n",
      "    325        0.0417        0.0687        88.2508\n",
      "    326        0.0423        0.0688        89.2826\n",
      "    327        0.0420        \u001b[32m0.0686\u001b[0m     +  87.7706\n",
      "    328        0.0498        0.0713        85.1374\n",
      "    329        0.0514        0.0717        83.8400\n",
      "    330        0.0525        0.0719        85.0176\n",
      "    331        0.0503        0.0722        79.6414\n",
      "    332        0.0514        0.0724        80.3832\n",
      "    333        0.0504        0.0707        82.9475\n",
      "    334        0.0511        0.0715        83.5754\n",
      "    335        0.0506        0.0713        84.1739\n",
      "    336        0.0497        0.0719        80.8799\n",
      "    337        0.0503        0.0714        79.7768\n",
      "    338        0.0489        0.0707        82.2290\n",
      "    339        0.0484        0.0719        85.1811\n",
      "    340        0.0478        0.0709        85.3036\n",
      "    341        0.0460        0.0701        84.2420\n",
      "    342        0.0457        0.0707        84.8613\n",
      "    343        0.0472        0.0695        80.4426\n",
      "    344        0.0451        0.0698        86.0196\n",
      "    345        0.0464        0.0701        86.5257\n",
      "    346        0.0452        0.0700        86.9791\n",
      "    347        0.0442        0.0702        86.3164\n",
      "    348        0.0441        0.0699        86.8391\n",
      "    349        0.0433        0.0693        85.4126\n",
      "    350        0.0443        0.0692        91.5895\n",
      "    351        0.0430        0.0689        87.0238\n",
      "    352        0.0422        0.0694        84.3446\n",
      "    353        \u001b[36m0.0398\u001b[0m        0.0693        90.0782\n",
      "    354        0.0414        0.0694        87.4001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    355        \u001b[36m0.0393\u001b[0m        0.0692        88.9000\n",
      "    356        0.0415        0.0695        88.7149\n",
      "    357        0.0423        0.0690        90.6207\n",
      "    358        0.0414        0.0692        86.9399\n",
      "    359        0.0394        0.0691        91.8593\n",
      "    360        0.0399        0.0693        90.3180\n",
      "    361        0.0408        0.0689        88.7436\n",
      "    362        0.0403        0.0694        87.1956\n",
      "    363        0.0405        0.0693        90.8874\n",
      "    364        0.0484        0.0731        85.3265\n",
      "    365        0.0515        0.0723        83.9805\n",
      "    366        0.0468        0.0712        84.6187\n",
      "    367        0.0502        0.0722        84.5870\n",
      "    368        0.0502        0.0726        82.8985\n",
      "    369        0.0501        0.0725        84.0306\n",
      "    370        0.0499        0.0725        84.6604\n",
      "    371        0.0491        0.0716        85.9311\n",
      "    372        0.0484        0.0705        82.3513\n",
      "    373        0.0490        0.0707        84.5397\n",
      "    374        0.0487        0.0705        81.8177\n",
      "    375        0.0475        0.0713        86.1502\n",
      "    376        0.0467        0.0709        83.9168\n",
      "    377        0.0474        0.0711        85.8923\n",
      "    378        0.0457        0.0708        82.1894\n",
      "    379        0.0477        0.0699        82.8658\n",
      "    380        0.0457        0.0698        87.1103\n",
      "    381        0.0446        0.0704        85.2281\n",
      "    382        0.0437        0.0698        87.7294\n",
      "    383        0.0447        0.0715        88.0055\n",
      "    384        0.0431        0.0698        87.6962\n",
      "    385        0.0431        0.0704        89.2285\n",
      "    386        0.0429        0.0701        86.6145\n",
      "    387        0.0425        0.0696        88.1914\n",
      "    388        0.0416        0.0696        89.4781\n",
      "    389        0.0420        0.0699        91.2140\n",
      "    390        0.0435        0.0695        86.7278\n",
      "    391        0.0401        0.0694        90.4714\n",
      "    392        0.0424        0.0693        88.5847\n",
      "    393        0.0398        0.0694        92.2514\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.91 GiB total capacity; 9.81 GiB already allocated; 9.00 MiB free; 1.53 GiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-c28998b4d768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSDT_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/skorch/net.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_train_begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/skorch/net.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0myi_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myi\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my_valid_is_ph\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_batch_begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myi_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m                 \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid_batch_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/skorch/net.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, Xi, yi, **fit_params)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;31m#with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         return {\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/skorch/net.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, x, **fit_params)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_x_and_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/cgcnn/model_grad_simple.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, atom_fea, nbr_fea, nbr_fea_idx, nbr_fea_offset, crystal_atom_idx, atom_pos, nbr_pos, atom_pos_idx, cells, fixed_atom_mask, atom_pos_final)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mgrad_E\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbond_energy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#+ ((atom_pos - orig_atom_pos)**2).sum()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_E\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matom_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;31m#             grad = torch.clamp(grad, min=1e-4, max=8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    147\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.91 GiB total capacity; 9.81 GiB already allocated; 9.00 MiB free; 1.53 GiB cached)"
     ]
    }
   ],
   "source": [
    "net.module_.max_epochs=300\n",
    "net.partial_fit(SDT_training, target_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      dur\n",
      "-------  ------------  ------------  ----  -------\n",
      "    328        0.0496        0.0726        82.0476\n",
      "    329        0.0497        0.0718        83.5820\n",
      "    330        0.0510        0.0709        84.7089\n",
      "    331        0.0477        0.0712        81.4991\n",
      "    332        0.0467        0.0697        82.0114\n",
      "    333        0.0456        0.0701        85.2831\n",
      "    334        0.0441        0.0691        86.3869\n",
      "    335        0.0429        \u001b[32m0.0687\u001b[0m     +  87.5621\n",
      "    336        0.0418        0.0690        88.7625\n",
      "    337        0.0416        0.0689        89.8128\n",
      "    338        0.0515        0.0721        80.5939\n",
      "    339        0.0512        0.0712        82.4443\n",
      "    340        0.0511        0.0714        86.3513\n",
      "    341        0.0494        0.0706        87.3228\n",
      "    342        0.0486        0.0705        85.5411\n",
      "    343        0.0460        0.0703        84.4622\n",
      "    344        0.0459        0.0694        87.7820\n",
      "    345        0.0426        0.0695        88.7085\n",
      "    346        0.0443        0.0693        87.1104\n",
      "    347        0.0432        0.0691        88.9737\n",
      "    348        0.0424        0.0690        88.3447\n",
      "    349        0.0427        0.0690        89.5733\n",
      "    350        0.0497        0.0712        83.3500\n",
      "    351        0.0498        0.0715        80.6363\n",
      "    352        0.0499        0.0726        82.7286\n",
      "    353        0.0496        0.0713        88.2040\n",
      "    354        0.0480        0.0714        81.3807\n",
      "    355        0.0477        0.0701        82.4286\n",
      "    356        0.0484        0.0699        80.8456\n",
      "    357        0.0445        0.0700        84.9398\n",
      "    358        0.0437        0.0692        87.8527\n",
      "    359        0.0431        0.0690        85.6116\n",
      "    360        0.0415        0.0689        88.3291\n",
      "    361        0.0414        0.0688        85.2511\n",
      "    362        \u001b[36m0.0406\u001b[0m        0.0688        86.4850\n",
      "    363        0.0428        0.0688        88.7938\n",
      "    364        0.0408        0.0687        88.0216\n",
      "    365        0.0488        0.0784        84.5216\n",
      "    366        0.0508        0.0707        82.4405\n",
      "    367        0.0489        0.0707        82.5911\n",
      "    368        0.0491        0.0710        83.3190\n",
      "    369        0.0478        0.0707        81.1023\n",
      "    370        0.0495        0.0703        81.4980\n",
      "    371        0.0475        0.0706        85.4714\n",
      "    372        0.0460        0.0696        87.9810\n",
      "    373        0.0440        0.0701        84.8780\n",
      "    374        0.0436        0.0693        88.4159\n",
      "    375        0.0432        0.0694        87.3526\n",
      "    376        0.0443        0.0693        89.3426\n",
      "    377        0.0413        0.0691        87.8731\n",
      "    378        \u001b[36m0.0401\u001b[0m        0.0688        85.4933\n",
      "    379        \u001b[36m0.0395\u001b[0m        \u001b[32m0.0687\u001b[0m     +  89.0003\n",
      "    380        0.0399        0.0688        87.5417\n",
      "    381        \u001b[36m0.0394\u001b[0m        0.0687        86.6603\n",
      "    382        0.0404        0.0688        88.5055\n",
      "    383        0.0499        0.0718        83.8279\n",
      "    384        0.0483        0.0727        84.5368\n",
      "    385        0.0503        0.0726        80.7479\n",
      "    386        0.0485        0.0713        84.3473\n",
      "    387        0.0481        0.0710        80.6282\n",
      "    388        0.0469        0.0717        83.4427\n",
      "blow up\n",
      "    389        0.0474        0.0744        84.2861\n",
      "    390        0.0454        0.0700        88.2135\n",
      "    391        0.0456        0.0697        88.3745\n",
      "    392        0.0447        0.0702        87.2277\n",
      "    393        0.0443        0.0693        90.8531\n",
      "    394        0.0430        0.0697        86.7677\n",
      "    395        0.0421        0.0688        87.6986\n",
      "    396        0.0428        0.0691        89.8255\n",
      "    397        0.0402        0.0689        89.3668\n",
      "    398        0.0410        0.0691        92.3629\n",
      "    399        0.0405        0.0691        88.7383\n",
      "    400        \u001b[36m0.0392\u001b[0m        0.0687        91.9717\n",
      "    401        0.0402        \u001b[32m0.0687\u001b[0m     +  91.9590\n",
      "    402        0.0397        0.0690        90.0979\n",
      "    403        0.0396        0.0690        94.1817\n",
      "    404        0.0476        0.0715        84.7889\n",
      "    405        0.0490        0.0720        87.1814\n",
      "    406        0.0495        0.0709        81.8419\n",
      "    407        0.0494        0.0715        85.3959\n",
      "    408        0.0474        0.0710        83.9447\n",
      "    409        0.0490        0.0711        84.1502\n",
      "    410        0.0455        0.0708        84.6318\n",
      "    411        0.0455        0.0702        85.7954\n",
      "    412        0.0463        0.0710        86.1788\n",
      "    413        0.0450        0.0705        84.0642\n",
      "    414        0.0455        0.0698        88.4985\n",
      "    415        0.0421        0.0708        86.5975\n",
      "    416        0.0433        0.0703        89.7046\n",
      "    417        0.0422        0.0697        87.6355\n",
      "    418        0.0402        0.0693        88.4107\n",
      "    419        0.0424        0.0698        87.4299\n",
      "    420        0.0410        0.0694        89.7755\n",
      "    421        0.0404        0.0690        87.6144\n",
      "    422        0.0398        0.0691        90.4768\n",
      "    423        0.0401        0.0691        90.2230\n",
      "    424        0.0394        0.0692        91.2512\n",
      "    425        \u001b[36m0.0385\u001b[0m        0.0689        88.8415\n",
      "    426        0.0389        0.0692        88.9171\n",
      "    427        0.0395        0.0691        90.2238\n",
      "    428        \u001b[36m0.0377\u001b[0m        0.0690        89.5592\n",
      "    429        0.0463        0.0736        86.6062\n",
      "    430        0.0479        0.0720        87.7735\n",
      "    431        0.0487        0.0721        85.4516\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.91 GiB total capacity; 9.84 GiB already allocated; 9.00 MiB free; 1.51 GiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-46693dbffcc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0056\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSDT_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/skorch/net.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_train_begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/skorch/net.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0myi_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myi\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my_valid_is_ph\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_batch_begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myi_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m                 \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid_batch_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/skorch/net.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, Xi, yi, **fit_params)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;31m#with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         return {\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/skorch/net.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, x, **fit_params)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_x_and_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/cgcnn/bond_regression3/cgcnn/model_grad_simple.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, atom_fea, nbr_fea, nbr_fea_idx, nbr_fea_offset, crystal_atom_idx, atom_pos, nbr_pos, atom_pos_idx, cells, fixed_atom_mask, atom_pos_final)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mgrad_E\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbond_energy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#+ ((atom_pos - orig_atom_pos)**2).sum()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_E\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matom_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;31m#             grad = torch.clamp(grad, min=1e-4, max=8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    147\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.91 GiB total capacity; 9.84 GiB already allocated; 9.00 MiB free; 1.51 GiB cached)"
     ]
    }
   ],
   "source": [
    "net.module_.max_epochs = 0.0056 * 0.9\n",
    "net.module_.max_epochs = 300\n",
    "net.partial_fit(SDT_training, target_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.module_.max_epochs = 0.0056 * 0.8\n",
    "net.module_.max_epochs = 300\n",
    "net.partial_fit(SDT_training, target_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDT_train, SDT_valid, target_train, target_valid = train_test_split(SDT_training, target_training, \n",
    "                                                                    test_size=0.1, random_state=42)\n",
    "def get_targets(dummy_SDT, dummy_targets):\n",
    "    targets = []\n",
    "    for i, target in enumerate(dummy_targets):\n",
    "        free_atom_idx = dummy_SDT[i][-2]\n",
    "        \n",
    "        targets.append(target[0][free_atom_idx].reshape(-1,3))\n",
    "    return np.concatenate(targets)\n",
    "\n",
    "def get_distance(pred, true):\n",
    "    diff = np.sum((pred - true)**2, axis=1)\n",
    "    return np.sqrt(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = net.predict(SDT_train)\n",
    "true_train = get_targets(SDT_train, target_train)\n",
    "distance_train = get_distance(pred_train, true_train)\n",
    "MAE_train = np.mean(distance_train)\n",
    "\n",
    "# pred_val = net.predict(SDT_valid)\n",
    "# true_val = get_targets(SDT_valid, target_valid)\n",
    "# distance_val = get_distance(pred_val, true_val)\n",
    "# MAE_val = np.mean(distance_val)\n",
    "\n",
    "pred_test = net.predict(SDT_test)\n",
    "true_test = get_targets(SDT_test, target_test)\n",
    "distance_test = get_distance(pred_test, true_test)\n",
    "MAE_test = np.mean(distance_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03322467"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(pred_test - true_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = []\n",
    "for sdt, target in zip(pred_test, true_test):\n",
    "    differences.append(diff_position(sdt, target))\n",
    "differences = np.concatenate(differences)\n",
    "np.mean(np.abs(differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06864148 0.07131237\n"
     ]
    }
   ],
   "source": [
    "print(MAE_val, MAE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5696 633 704\n"
     ]
    }
   ],
   "source": [
    "print(len(SDT_train), len(SDT_valid), len(SDT_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'test result')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(distance_test, bins=20)\n",
    "plt.title('test result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train, docs_val = train_test_split(docs_training, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(SDT, docs, distance):\n",
    "    dist_per_surface = []\n",
    "    total_atoms = 0\n",
    "    for sdt in SDT:\n",
    "        num_atoms = sdt[-2].shape[0]\n",
    "        dist_per_surface.append(np.mean(distance[total_atoms: total_atoms+num_atoms]))\n",
    "        total_atoms += num_atoms\n",
    "    results =[]\n",
    "    reduced = []\n",
    "    best = []\n",
    "    bad_docs = []\n",
    "    bad_result =[]\n",
    "    good_docs=[]\n",
    "    good_result=[]\n",
    "    f = 0\n",
    "    for dist, doc in zip(dist_per_surface, docs):\n",
    "        total_steps = len(doc['distances_per_step'])\n",
    "        reduced_steps = len(np.where(doc['distances_per_step'] >= dist)[0])\n",
    "        results.append([total_steps, reduced_steps, reduced_steps/total_steps])\n",
    "        reduced.append(reduced_steps/total_steps)\n",
    "        if reduced_steps/total_steps < 0.1:\n",
    "            bad_docs.append(doc)\n",
    "            bad_result.append([total_steps, reduced_steps, reduced_steps/total_steps, dist])\n",
    "        else:\n",
    "            good_docs.append(doc)\n",
    "            good_result.append([total_steps, reduced_steps, reduced_steps/total_steps,dist])\n",
    "    \n",
    "    return results, reduced, bad_docs, bad_result,good_docs, good_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, reduced, bad_docs, bad_result,good_docs,good_result = analysis(SDT_test, docs_test, distance_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[13, 3, 0.23076923076923078, 0.037788287],\n",
       " [24, 4, 0.16666666666666666, 0.1601389],\n",
       " [19, 4, 0.21052631578947367, 0.100657105],\n",
       " [26, 5, 0.19230769230769232, 0.07394181],\n",
       " [18, 4, 0.2222222222222222, 0.072605565],\n",
       " [24, 3, 0.125, 0.1165643],\n",
       " [16, 5, 0.3125, 0.027258668],\n",
       " [13, 6, 0.46153846153846156, 0.030704457],\n",
       " [14, 2, 0.14285714285714285, 0.086650625],\n",
       " [27, 4, 0.14814814814814814, 0.15059583],\n",
       " [29, 11, 0.3793103448275862, 0.06253592],\n",
       " [22, 9, 0.4090909090909091, 0.018198594],\n",
       " [23, 7, 0.30434782608695654, 0.05976365],\n",
       " [27, 9, 0.3333333333333333, 0.14271776],\n",
       " [31, 5, 0.16129032258064516, 0.10060297],\n",
       " [28, 5, 0.17857142857142858, 0.08056004],\n",
       " [26, 5, 0.19230769230769232, 0.039741356],\n",
       " [15, 6, 0.4, 0.025563173],\n",
       " [21, 3, 0.14285714285714285, 0.11094116],\n",
       " [21, 6, 0.2857142857142857, 0.07893174],\n",
       " [24, 11, 0.4583333333333333, 0.04725724],\n",
       " [12, 7, 0.5833333333333334, 0.0161148],\n",
       " [15, 2, 0.13333333333333333, 0.07839171],\n",
       " [11, 5, 0.45454545454545453, 0.026526539],\n",
       " [14, 6, 0.42857142857142855, 0.03018268],\n",
       " [8, 6, 0.75, 0.056879345],\n",
       " [22, 3, 0.13636363636363635, 0.066247895],\n",
       " [16, 3, 0.1875, 0.04703171],\n",
       " [19, 2, 0.10526315789473684, 0.075992405],\n",
       " [33, 8, 0.24242424242424243, 0.061964694],\n",
       " [10, 7, 0.7, 0.011515702],\n",
       " [31, 14, 0.45161290322580644, 0.040814783],\n",
       " [28, 3, 0.10714285714285714, 0.056107834],\n",
       " [22, 4, 0.18181818181818182, 0.102166764],\n",
       " [21, 4, 0.19047619047619047, 0.07692646],\n",
       " [22, 3, 0.13636363636363635, 0.07722407],\n",
       " [24, 6, 0.25, 0.0577295],\n",
       " [10, 7, 0.7, 0.034317642],\n",
       " [27, 3, 0.1111111111111111, 0.120498314],\n",
       " [17, 7, 0.4117647058823529, 0.06740393],\n",
       " [18, 5, 0.2777777777777778, 0.048278067],\n",
       " [22, 3, 0.13636363636363635, 0.10992001],\n",
       " [28, 4, 0.14285714285714285, 0.23451585],\n",
       " [10, 4, 0.4, 0.032073595],\n",
       " [12, 6, 0.5, 0.025388146],\n",
       " [15, 4, 0.26666666666666666, 0.042877655],\n",
       " [24, 8, 0.3333333333333333, 0.062239278],\n",
       " [18, 6, 0.3333333333333333, 0.059407495],\n",
       " [21, 7, 0.3333333333333333, 0.071159676],\n",
       " [20, 5, 0.25, 0.05765297],\n",
       " [18, 4, 0.2222222222222222, 0.067043506],\n",
       " [14, 2, 0.14285714285714285, 0.10146183],\n",
       " [29, 12, 0.41379310344827586, 0.060646787],\n",
       " [18, 4, 0.2222222222222222, 0.07809097],\n",
       " [39, 16, 0.41025641025641024, 0.16673867],\n",
       " [15, 9, 0.6, 0.01423812],\n",
       " [23, 5, 0.21739130434782608, 0.025564872],\n",
       " [13, 3, 0.23076923076923078, 0.030970758],\n",
       " [16, 5, 0.3125, 0.046552345],\n",
       " [17, 10, 0.5882352941176471, 0.014057682],\n",
       " [29, 6, 0.20689655172413793, 0.091360845],\n",
       " [22, 7, 0.3181818181818182, 0.06595211],\n",
       " [17, 4, 0.23529411764705882, 0.05419192],\n",
       " [15, 4, 0.26666666666666666, 0.06855322],\n",
       " [16, 5, 0.3125, 0.051265977],\n",
       " [21, 8, 0.38095238095238093, 0.07735386],\n",
       " [23, 3, 0.13043478260869565, 0.041976593],\n",
       " [24, 12, 0.5, 0.077777706],\n",
       " [10, 2, 0.2, 0.033900555],\n",
       " [15, 5, 0.3333333333333333, 0.0448751],\n",
       " [18, 3, 0.16666666666666666, 0.032742992],\n",
       " [22, 7, 0.3181818181818182, 0.074033216],\n",
       " [18, 4, 0.2222222222222222, 0.056066737],\n",
       " [29, 5, 0.1724137931034483, 0.04278515],\n",
       " [9, 2, 0.2222222222222222, 0.04178766],\n",
       " [12, 7, 0.5833333333333334, 0.022272669],\n",
       " [15, 6, 0.4, 0.05229283],\n",
       " [31, 5, 0.16129032258064516, 0.106990196],\n",
       " [19, 5, 0.2631578947368421, 0.054646317],\n",
       " [22, 5, 0.22727272727272727, 0.054749683],\n",
       " [16, 4, 0.25, 0.062199842],\n",
       " [17, 8, 0.47058823529411764, 0.025843209],\n",
       " [15, 6, 0.4, 0.030928861],\n",
       " [16, 4, 0.25, 0.04984499],\n",
       " [19, 4, 0.21052631578947367, 0.09037325],\n",
       " [16, 7, 0.4375, 0.023152411],\n",
       " [18, 2, 0.1111111111111111, 0.083167784],\n",
       " [11, 3, 0.2727272727272727, 0.037742924],\n",
       " [9, 2, 0.2222222222222222, 0.03616104],\n",
       " [22, 11, 0.5, 0.082559384],\n",
       " [21, 8, 0.38095238095238093, 0.049025796],\n",
       " [21, 4, 0.19047619047619047, 0.083661325],\n",
       " [23, 6, 0.2608695652173913, 0.052329503],\n",
       " [12, 5, 0.4166666666666667, 0.04205164],\n",
       " [27, 4, 0.14814814814814814, 0.05222856],\n",
       " [13, 7, 0.5384615384615384, 0.031893723],\n",
       " [22, 6, 0.2727272727272727, 0.0490649],\n",
       " [22, 5, 0.22727272727272727, 0.07810327],\n",
       " [23, 3, 0.13043478260869565, 0.08845327],\n",
       " [8, 7, 0.875, 0.014550926],\n",
       " [32, 7, 0.21875, 0.043221194],\n",
       " [12, 6, 0.5, 0.024441427],\n",
       " [29, 3, 0.10344827586206896, 0.11398266],\n",
       " [22, 10, 0.45454545454545453, 0.109471805],\n",
       " [22, 4, 0.18181818181818182, 0.08246003],\n",
       " [19, 4, 0.21052631578947367, 0.029427027],\n",
       " [29, 22, 0.7586206896551724, 0.04387267],\n",
       " [18, 3, 0.16666666666666666, 0.06202428],\n",
       " [24, 5, 0.20833333333333334, 0.06424474],\n",
       " [8, 3, 0.375, 0.01885274],\n",
       " [26, 5, 0.19230769230769232, 0.081635475],\n",
       " [23, 4, 0.17391304347826086, 0.06514168],\n",
       " [15, 6, 0.4, 0.032428358],\n",
       " [20, 5, 0.25, 0.08021038],\n",
       " [11, 3, 0.2727272727272727, 0.039430004],\n",
       " [32, 6, 0.1875, 0.10436458],\n",
       " [24, 4, 0.16666666666666666, 0.018004654],\n",
       " [15, 4, 0.26666666666666666, 0.05173574],\n",
       " [26, 8, 0.3076923076923077, 0.081565894],\n",
       " [20, 7, 0.35, 0.077915005],\n",
       " [19, 12, 0.631578947368421, 0.023414621],\n",
       " [25, 8, 0.32, 0.055672426],\n",
       " [13, 3, 0.23076923076923078, 0.04409321],\n",
       " [11, 7, 0.6363636363636364, 0.023090096],\n",
       " [16, 6, 0.375, 0.027062044],\n",
       " [24, 10, 0.4166666666666667, 0.06673247],\n",
       " [30, 3, 0.1, 0.16977286],\n",
       " [25, 4, 0.16, 0.06963226],\n",
       " [18, 5, 0.2777777777777778, 0.0784209],\n",
       " [23, 7, 0.30434782608695654, 0.033791352],\n",
       " [27, 14, 0.5185185185185185, 0.0393809],\n",
       " [13, 2, 0.15384615384615385, 0.051478766],\n",
       " [15, 4, 0.26666666666666666, 0.08694999],\n",
       " [22, 5, 0.22727272727272727, 0.07477222],\n",
       " [29, 6, 0.20689655172413793, 0.13263775],\n",
       " [12, 3, 0.25, 0.050677706],\n",
       " [18, 5, 0.2777777777777778, 0.061843295],\n",
       " [20, 6, 0.3, 0.05431605],\n",
       " [10, 5, 0.5, 0.01612254],\n",
       " [16, 10, 0.625, 0.020188138],\n",
       " [17, 3, 0.17647058823529413, 0.14509901],\n",
       " [15, 5, 0.3333333333333333, 0.023484515],\n",
       " [15, 5, 0.3333333333333333, 0.05230419],\n",
       " [13, 6, 0.46153846153846156, 0.016911723],\n",
       " [28, 5, 0.17857142857142858, 0.17651284],\n",
       " [25, 8, 0.32, 0.07049044],\n",
       " [26, 6, 0.23076923076923078, 0.09389232],\n",
       " [25, 7, 0.28, 0.0613706],\n",
       " [31, 12, 0.3870967741935484, 0.105134405],\n",
       " [15, 5, 0.3333333333333333, 0.08910144],\n",
       " [22, 10, 0.45454545454545453, 0.058135793],\n",
       " [24, 7, 0.2916666666666667, 0.06290892],\n",
       " [22, 4, 0.18181818181818182, 0.03231591],\n",
       " [16, 6, 0.375, 0.050380554],\n",
       " [25, 14, 0.56, 0.016850999],\n",
       " [14, 6, 0.42857142857142855, 0.019648753],\n",
       " [15, 6, 0.4, 0.03989566],\n",
       " [15, 6, 0.4, 0.032818776],\n",
       " [12, 6, 0.5, 0.03336923],\n",
       " [33, 7, 0.21212121212121213, 0.087466754],\n",
       " [20, 7, 0.35, 0.015770484],\n",
       " [34, 10, 0.29411764705882354, 0.06706159],\n",
       " [12, 7, 0.5833333333333334, 0.020761473],\n",
       " [23, 11, 0.4782608695652174, 0.12197258],\n",
       " [13, 4, 0.3076923076923077, 0.050839677],\n",
       " [17, 5, 0.29411764705882354, 0.029720675],\n",
       " [17, 4, 0.23529411764705882, 0.07558367],\n",
       " [16, 8, 0.5, 0.026570009],\n",
       " [16, 3, 0.1875, 0.10927171],\n",
       " [22, 5, 0.22727272727272727, 0.040735595],\n",
       " [18, 10, 0.5555555555555556, 0.04586794],\n",
       " [17, 7, 0.4117647058823529, 0.06266555],\n",
       " [17, 6, 0.35294117647058826, 0.037719343],\n",
       " [20, 4, 0.2, 0.029225294],\n",
       " [16, 2, 0.125, 0.042477544],\n",
       " [19, 3, 0.15789473684210525, 0.04539078],\n",
       " [21, 3, 0.14285714285714285, 0.04740562],\n",
       " [24, 7, 0.2916666666666667, 0.08987689],\n",
       " [14, 3, 0.21428571428571427, 0.029331367],\n",
       " [11, 5, 0.45454545454545453, 0.01532491],\n",
       " [26, 6, 0.23076923076923078, 0.06100307],\n",
       " [19, 2, 0.10526315789473684, 0.08962053],\n",
       " [23, 17, 0.7391304347826086, 0.02088105],\n",
       " [37, 6, 0.16216216216216217, 0.054570958],\n",
       " [17, 6, 0.35294117647058826, 0.024366874],\n",
       " [35, 10, 0.2857142857142857, 0.104600266],\n",
       " [28, 15, 0.5357142857142857, 0.02611603],\n",
       " [11, 2, 0.18181818181818182, 0.040935867],\n",
       " [26, 9, 0.34615384615384615, 0.06472656],\n",
       " [13, 4, 0.3076923076923077, 0.052893512],\n",
       " [20, 3, 0.15, 0.12949719],\n",
       " [21, 8, 0.38095238095238093, 0.060171947],\n",
       " [13, 6, 0.46153846153846156, 0.024865972],\n",
       " [19, 8, 0.42105263157894735, 0.018163737],\n",
       " [16, 4, 0.25, 0.041761518],\n",
       " [20, 7, 0.35, 0.09639537],\n",
       " [23, 4, 0.17391304347826086, 0.12068351],\n",
       " [17, 5, 0.29411764705882354, 0.019990351],\n",
       " [24, 5, 0.20833333333333334, 0.07256704],\n",
       " [14, 6, 0.42857142857142855, 0.08510971],\n",
       " [28, 6, 0.21428571428571427, 0.14612053],\n",
       " [19, 8, 0.42105263157894735, 0.03493376],\n",
       " [8, 4, 0.5, 0.029493101],\n",
       " [12, 4, 0.3333333333333333, 0.066519514],\n",
       " [11, 6, 0.5454545454545454, 0.020892818],\n",
       " [23, 8, 0.34782608695652173, 0.14351413],\n",
       " [26, 6, 0.23076923076923078, 0.117937505],\n",
       " [13, 6, 0.46153846153846156, 0.019315183],\n",
       " [15, 4, 0.26666666666666666, 0.0572288],\n",
       " [21, 5, 0.23809523809523808, 0.17792366],\n",
       " [13, 4, 0.3076923076923077, 0.040183384],\n",
       " [10, 1, 0.1, 0.044775926],\n",
       " [18, 12, 0.6666666666666666, 0.023003893],\n",
       " [26, 11, 0.4230769230769231, 0.048754603],\n",
       " [19, 6, 0.3157894736842105, 0.0499233],\n",
       " [15, 7, 0.4666666666666667, 0.029413778],\n",
       " [22, 7, 0.3181818181818182, 0.06349589],\n",
       " [9, 7, 0.7777777777777778, 0.0080235],\n",
       " [15, 6, 0.4, 0.052238714],\n",
       " [15, 5, 0.3333333333333333, 0.07968731],\n",
       " [15, 4, 0.26666666666666666, 0.061799414],\n",
       " [25, 6, 0.24, 0.16731606],\n",
       " [7, 3, 0.42857142857142855, 0.026230015],\n",
       " [19, 6, 0.3157894736842105, 0.047850277],\n",
       " [16, 4, 0.25, 0.02657782],\n",
       " [21, 8, 0.38095238095238093, 0.083681144],\n",
       " [11, 2, 0.18181818181818182, 0.05714298],\n",
       " [13, 3, 0.23076923076923078, 0.042380348],\n",
       " [20, 8, 0.4, 0.092708856],\n",
       " [23, 7, 0.30434782608695654, 0.048637375],\n",
       " [19, 4, 0.21052631578947367, 0.08656857],\n",
       " [20, 9, 0.45, 0.040367614],\n",
       " [9, 2, 0.2222222222222222, 0.033777017],\n",
       " [37, 5, 0.13513513513513514, 0.19394946],\n",
       " [17, 8, 0.47058823529411764, 0.01688629],\n",
       " [13, 5, 0.38461538461538464, 0.033588096],\n",
       " [21, 5, 0.23809523809523808, 0.06598874],\n",
       " [14, 5, 0.35714285714285715, 0.05916006],\n",
       " [13, 4, 0.3076923076923077, 0.045298856],\n",
       " [11, 2, 0.18181818181818182, 0.04192112],\n",
       " [35, 7, 0.2, 0.09457766],\n",
       " [13, 4, 0.3076923076923077, 0.02805442],\n",
       " [19, 6, 0.3157894736842105, 0.022196425],\n",
       " [16, 4, 0.25, 0.036701567],\n",
       " [25, 8, 0.32, 0.057214856],\n",
       " [18, 3, 0.16666666666666666, 0.041777313],\n",
       " [20, 9, 0.45, 0.04926958],\n",
       " [10, 5, 0.5, 0.028623458],\n",
       " [14, 2, 0.14285714285714285, 0.039394643],\n",
       " [19, 4, 0.21052631578947367, 0.09591969],\n",
       " [11, 4, 0.36363636363636365, 0.017009111],\n",
       " [22, 5, 0.22727272727272727, 0.087463416],\n",
       " [21, 15, 0.7142857142857143, 0.026024956],\n",
       " [22, 8, 0.36363636363636365, 0.037054453],\n",
       " [28, 9, 0.32142857142857145, 0.11014192],\n",
       " [38, 12, 0.3157894736842105, 0.10055358],\n",
       " [20, 5, 0.25, 0.07052205],\n",
       " [35, 7, 0.2, 0.08339908],\n",
       " [14, 4, 0.2857142857142857, 0.048136715],\n",
       " [34, 5, 0.14705882352941177, 0.19019452],\n",
       " [19, 5, 0.2631578947368421, 0.089170426],\n",
       " [24, 4, 0.16666666666666666, 0.119400084],\n",
       " [27, 5, 0.18518518518518517, 0.0684986],\n",
       " [27, 6, 0.2222222222222222, 0.04618287],\n",
       " [15, 4, 0.26666666666666666, 0.042655785],\n",
       " [18, 3, 0.16666666666666666, 0.0667601],\n",
       " [11, 6, 0.5454545454545454, 0.016982172],\n",
       " [19, 4, 0.21052631578947367, 0.04455824],\n",
       " [10, 4, 0.4, 0.02743953],\n",
       " [19, 6, 0.3157894736842105, 0.14045158],\n",
       " [23, 5, 0.21739130434782608, 0.0638225],\n",
       " [11, 6, 0.5454545454545454, 0.007852666],\n",
       " [22, 10, 0.45454545454545453, 0.014662123],\n",
       " [23, 12, 0.5217391304347826, 0.065861404],\n",
       " [11, 2, 0.18181818181818182, 0.02144676],\n",
       " [13, 5, 0.38461538461538464, 0.020513752],\n",
       " [16, 4, 0.25, 0.054184664],\n",
       " [23, 5, 0.21739130434782608, 0.04503099],\n",
       " [16, 6, 0.375, 0.059854843],\n",
       " [22, 5, 0.22727272727272727, 0.115549244],\n",
       " [39, 4, 0.10256410256410256, 0.10058153],\n",
       " [18, 8, 0.4444444444444444, 0.047339734],\n",
       " [16, 2, 0.125, 0.083440825],\n",
       " [12, 5, 0.4166666666666667, 0.037333395],\n",
       " [17, 7, 0.4117647058823529, 0.047071636],\n",
       " [24, 3, 0.125, 0.10249593],\n",
       " [13, 4, 0.3076923076923077, 0.020605098],\n",
       " [20, 9, 0.45, 0.11541887],\n",
       " [11, 4, 0.36363636363636365, 0.045285176],\n",
       " [22, 12, 0.5454545454545454, 0.03227461],\n",
       " [12, 4, 0.3333333333333333, 0.051939245],\n",
       " [6, 4, 0.6666666666666666, 0.017410517],\n",
       " [21, 11, 0.5238095238095238, 0.038667012],\n",
       " [21, 10, 0.47619047619047616, 0.036781188],\n",
       " [15, 3, 0.2, 0.059347436],\n",
       " [15, 3, 0.2, 0.06505533],\n",
       " [15, 3, 0.2, 0.06630062],\n",
       " [21, 3, 0.14285714285714285, 0.10413544],\n",
       " [27, 3, 0.1111111111111111, 0.092146546],\n",
       " [7, 4, 0.5714285714285714, 0.026074365],\n",
       " [24, 12, 0.5, 0.046421323],\n",
       " [27, 12, 0.4444444444444444, 0.06615971],\n",
       " [15, 5, 0.3333333333333333, 0.054342315],\n",
       " [13, 4, 0.3076923076923077, 0.042383686],\n",
       " [15, 3, 0.2, 0.07093127],\n",
       " [12, 2, 0.16666666666666666, 0.07555901],\n",
       " [10, 3, 0.3, 0.03488048],\n",
       " [19, 3, 0.15789473684210525, 0.045657475],\n",
       " [10, 4, 0.4, 0.028234517],\n",
       " [11, 9, 0.8181818181818182, 0.023825297],\n",
       " [18, 3, 0.16666666666666666, 0.12116452],\n",
       " [27, 7, 0.25925925925925924, 0.07517491],\n",
       " [21, 8, 0.38095238095238093, 0.050686315],\n",
       " [22, 3, 0.13636363636363635, 0.10971447],\n",
       " [17, 3, 0.17647058823529413, 0.06920103],\n",
       " [25, 10, 0.4, 0.040440787],\n",
       " [14, 4, 0.2857142857142857, 0.034936525],\n",
       " [19, 2, 0.10526315789473684, 0.04556355],\n",
       " [18, 9, 0.5, 0.05196994],\n",
       " [22, 5, 0.22727272727272727, 0.075002074],\n",
       " [12, 7, 0.5833333333333334, 0.0069032907],\n",
       " [20, 2, 0.1, 0.067424305],\n",
       " [26, 8, 0.3076923076923077, 0.047212902],\n",
       " [24, 4, 0.16666666666666666, 0.086238384],\n",
       " [25, 7, 0.28, 0.060665414],\n",
       " [18, 2, 0.1111111111111111, 0.056144997],\n",
       " [29, 8, 0.27586206896551724, 0.052398965],\n",
       " [38, 16, 0.42105263157894735, 0.090827085],\n",
       " [11, 4, 0.36363636363636365, 0.035389215],\n",
       " [14, 4, 0.2857142857142857, 0.043262955],\n",
       " [20, 6, 0.3, 0.08051264],\n",
       " [20, 5, 0.25, 0.05735213],\n",
       " [13, 3, 0.23076923076923078, 0.043096732],\n",
       " [17, 16, 0.9411764705882353, 0.0037711232],\n",
       " [27, 5, 0.18518518518518517, 0.086366415],\n",
       " [9, 2, 0.2222222222222222, 0.036026005],\n",
       " [19, 2, 0.10526315789473684, 0.122348815],\n",
       " [13, 5, 0.38461538461538464, 0.026620418],\n",
       " [14, 6, 0.42857142857142855, 0.04652125],\n",
       " [22, 6, 0.2727272727272727, 0.10886037],\n",
       " [15, 5, 0.3333333333333333, 0.051957548],\n",
       " [20, 12, 0.6, 0.030651044],\n",
       " [20, 8, 0.4, 0.068327405],\n",
       " [13, 5, 0.38461538461538464, 0.028549362],\n",
       " [28, 11, 0.39285714285714285, 0.037661158],\n",
       " [12, 8, 0.6666666666666666, 0.018641265],\n",
       " [18, 5, 0.2777777777777778, 0.05603499],\n",
       " [18, 8, 0.4444444444444444, 0.05519385],\n",
       " [11, 5, 0.45454545454545453, 0.0414887],\n",
       " [13, 6, 0.46153846153846156, 0.021512691],\n",
       " [21, 8, 0.38095238095238093, 0.0778754],\n",
       " [36, 26, 0.7222222222222222, 0.042594783],\n",
       " [7, 4, 0.5714285714285714, 0.018884396],\n",
       " [18, 2, 0.1111111111111111, 0.1153571],\n",
       " [10, 6, 0.6, 0.011442032],\n",
       " [18, 3, 0.16666666666666666, 0.065001994],\n",
       " [18, 7, 0.3888888888888889, 0.06893406],\n",
       " [15, 4, 0.26666666666666666, 0.00843647],\n",
       " [23, 6, 0.2608695652173913, 0.05486859],\n",
       " [26, 4, 0.15384615384615385, 0.21849652],\n",
       " [17, 4, 0.23529411764705882, 0.044673648],\n",
       " [17, 4, 0.23529411764705882, 0.031898864],\n",
       " [25, 4, 0.16, 0.08116867],\n",
       " [16, 6, 0.375, 0.023770176],\n",
       " [19, 4, 0.21052631578947367, 0.07321986],\n",
       " [13, 4, 0.3076923076923077, 0.043692227],\n",
       " [16, 4, 0.25, 0.071276926],\n",
       " [28, 10, 0.35714285714285715, 0.042346362],\n",
       " [15, 5, 0.3333333333333333, 0.0244761],\n",
       " [18, 5, 0.2777777777777778, 0.045645382],\n",
       " [16, 4, 0.25, 0.028444976],\n",
       " [12, 5, 0.4166666666666667, 0.030790577],\n",
       " [22, 10, 0.45454545454545453, 0.07678007],\n",
       " [14, 4, 0.2857142857142857, 0.10092704],\n",
       " [17, 6, 0.35294117647058826, 0.04597234],\n",
       " [11, 5, 0.45454545454545453, 0.035218064],\n",
       " [19, 3, 0.15789473684210525, 0.08071756],\n",
       " [31, 15, 0.4838709677419355, 0.06104748],\n",
       " [29, 7, 0.2413793103448276, 0.06415202],\n",
       " [18, 5, 0.2777777777777778, 0.060067743],\n",
       " [21, 5, 0.23809523809523808, 0.1826507],\n",
       " [36, 8, 0.2222222222222222, 0.061239228],\n",
       " [13, 5, 0.38461538461538464, 0.047607575],\n",
       " [27, 9, 0.3333333333333333, 0.04873878],\n",
       " [9, 5, 0.5555555555555556, 0.020552844],\n",
       " [10, 5, 0.5, 0.018500408],\n",
       " [19, 4, 0.21052631578947367, 0.08320133],\n",
       " [17, 2, 0.11764705882352941, 0.0672455],\n",
       " [7, 1, 0.14285714285714285, 0.051154524],\n",
       " [24, 15, 0.625, 0.029167825],\n",
       " [9, 1, 0.1111111111111111, 0.043910693],\n",
       " [32, 14, 0.4375, 0.09564998],\n",
       " [10, 1, 0.1, 0.040940184],\n",
       " [12, 8, 0.6666666666666666, 0.0776304],\n",
       " [36, 8, 0.2222222222222222, 0.0751727],\n",
       " [17, 3, 0.17647058823529413, 0.12125757],\n",
       " [12, 3, 0.25, 0.09264814],\n",
       " [27, 7, 0.25925925925925924, 0.06264616],\n",
       " [22, 6, 0.2727272727272727, 0.077814415],\n",
       " [17, 5, 0.29411764705882354, 0.042275593],\n",
       " [18, 8, 0.4444444444444444, 0.12412569],\n",
       " [37, 17, 0.4594594594594595, 0.11690284],\n",
       " [31, 9, 0.2903225806451613, 0.09676135],\n",
       " [20, 6, 0.3, 0.028096529],\n",
       " [27, 14, 0.5185185185185185, 0.050576515],\n",
       " [26, 3, 0.11538461538461539, 0.11113827],\n",
       " [23, 5, 0.21739130434782608, 0.12981345],\n",
       " [13, 6, 0.46153846153846156, 0.0149050625],\n",
       " [18, 2, 0.1111111111111111, 0.061358318],\n",
       " [13, 6, 0.46153846153846156, 0.023313418],\n",
       " [16, 2, 0.125, 0.06595216],\n",
       " [17, 5, 0.29411764705882354, 0.042579543],\n",
       " [12, 5, 0.4166666666666667, 0.03192735],\n",
       " [21, 7, 0.3333333333333333, 0.09482804],\n",
       " [29, 7, 0.2413793103448276, 0.069431044],\n",
       " [18, 6, 0.3333333333333333, 0.06727328],\n",
       " [22, 7, 0.3181818181818182, 0.037195925],\n",
       " [29, 7, 0.2413793103448276, 0.13413331],\n",
       " [19, 5, 0.2631578947368421, 0.07472956],\n",
       " [20, 3, 0.15, 0.075999655],\n",
       " [14, 4, 0.2857142857142857, 0.05981373],\n",
       " [18, 5, 0.2777777777777778, 0.04618681],\n",
       " [14, 2, 0.14285714285714285, 0.07382659],\n",
       " [26, 3, 0.11538461538461539, 0.076601416],\n",
       " [13, 4, 0.3076923076923077, 0.04385902],\n",
       " [19, 11, 0.5789473684210527, 0.05516057],\n",
       " [14, 2, 0.14285714285714285, 0.10080195],\n",
       " [14, 6, 0.42857142857142855, 0.051309776],\n",
       " [38, 7, 0.18421052631578946, 0.23033285],\n",
       " [24, 8, 0.3333333333333333, 0.086478844],\n",
       " [17, 4, 0.23529411764705882, 0.06759319],\n",
       " [16, 5, 0.3125, 0.039403025],\n",
       " [13, 6, 0.46153846153846156, 0.032645013],\n",
       " [33, 18, 0.5454545454545454, 0.07523524],\n",
       " [13, 6, 0.46153846153846156, 0.056234162],\n",
       " [24, 6, 0.25, 0.17531809],\n",
       " [37, 4, 0.10810810810810811, 0.16576856],\n",
       " [13, 4, 0.3076923076923077, 0.044044744],\n",
       " [39, 5, 0.1282051282051282, 0.10683304],\n",
       " [24, 5, 0.20833333333333334, 0.051951755],\n",
       " [10, 7, 0.7, 0.008098286],\n",
       " [22, 7, 0.3181818181818182, 0.0883739],\n",
       " [12, 5, 0.4166666666666667, 0.029298902],\n",
       " [33, 10, 0.30303030303030304, 0.081646636],\n",
       " [12, 6, 0.5, 0.02906858],\n",
       " [13, 6, 0.46153846153846156, 0.027541708],\n",
       " [23, 13, 0.5652173913043478, 0.07967825],\n",
       " [14, 7, 0.5, 0.038113188],\n",
       " [9, 5, 0.5555555555555556, 0.01622596],\n",
       " [25, 5, 0.2, 0.1265697],\n",
       " [19, 9, 0.47368421052631576, 0.025335524],\n",
       " [19, 6, 0.3157894736842105, 0.067260504],\n",
       " [12, 4, 0.3333333333333333, 0.12692532],\n",
       " [15, 9, 0.6, 0.025609644],\n",
       " [25, 7, 0.28, 0.0910067],\n",
       " [14, 10, 0.7142857142857143, 0.019024782],\n",
       " [11, 6, 0.5454545454545454, 0.0715935],\n",
       " [29, 9, 0.3103448275862069, 0.05895267],\n",
       " [34, 7, 0.20588235294117646, 0.17650127],\n",
       " [29, 10, 0.3448275862068966, 0.05905419],\n",
       " [16, 4, 0.25, 0.04142156],\n",
       " [33, 4, 0.12121212121212122, 0.141257],\n",
       " [14, 5, 0.35714285714285715, 0.023623006],\n",
       " [15, 8, 0.5333333333333333, 0.07790397],\n",
       " [24, 8, 0.3333333333333333, 0.09386095],\n",
       " [18, 4, 0.2222222222222222, 0.037479095],\n",
       " [19, 2, 0.10526315789473684, 0.09517847],\n",
       " [9, 5, 0.5555555555555556, 0.031071793],\n",
       " [25, 10, 0.4, 0.107183315],\n",
       " [27, 5, 0.18518518518518517, 0.09095745],\n",
       " [28, 8, 0.2857142857142857, 0.14323053],\n",
       " [10, 4, 0.4, 0.03789252],\n",
       " [18, 2, 0.1111111111111111, 0.067946486],\n",
       " [22, 12, 0.5454545454545454, 0.052706674],\n",
       " [17, 2, 0.11764705882352941, 0.069027044],\n",
       " [20, 11, 0.55, 0.07504785],\n",
       " [16, 2, 0.125, 0.04554944],\n",
       " [27, 8, 0.2962962962962963, 0.11965301],\n",
       " [10, 2, 0.2, 0.032306384],\n",
       " [8, 2, 0.25, 0.023231788],\n",
       " [19, 5, 0.2631578947368421, 0.08891789],\n",
       " [20, 7, 0.35, 0.09160335],\n",
       " [15, 3, 0.2, 0.04277083],\n",
       " [14, 5, 0.35714285714285715, 0.035426594],\n",
       " [31, 7, 0.22580645161290322, 0.10505661],\n",
       " [23, 6, 0.2608695652173913, 0.09062594],\n",
       " [39, 5, 0.1282051282051282, 0.1259812],\n",
       " [20, 7, 0.35, 0.02443759],\n",
       " [21, 3, 0.14285714285714285, 0.111912325],\n",
       " [22, 4, 0.18181818181818182, 0.05909274],\n",
       " [19, 2, 0.10526315789473684, 0.061284788],\n",
       " [18, 2, 0.1111111111111111, 0.13469875],\n",
       " [19, 6, 0.3157894736842105, 0.024581669],\n",
       " [22, 3, 0.13636363636363635, 0.08306804],\n",
       " [22, 9, 0.4090909090909091, 0.028307427],\n",
       " [17, 2, 0.11764705882352941, 0.06556494],\n",
       " [13, 7, 0.5384615384615384, 0.03437644],\n",
       " [18, 5, 0.2777777777777778, 0.16230968],\n",
       " [17, 3, 0.17647058823529413, 0.030730719],\n",
       " [32, 7, 0.21875, 0.17011353],\n",
       " [32, 8, 0.25, 0.12064048],\n",
       " [20, 3, 0.15, 0.0796393],\n",
       " [10, 3, 0.3, 0.024464147],\n",
       " [15, 2, 0.13333333333333333, 0.061466627],\n",
       " [28, 6, 0.21428571428571427, 0.09610941],\n",
       " [29, 15, 0.5172413793103449, 0.040009484],\n",
       " [13, 2, 0.15384615384615385, 0.07164233],\n",
       " [13, 4, 0.3076923076923077, 0.043492686],\n",
       " [16, 9, 0.5625, 0.05729416],\n",
       " [16, 3, 0.1875, 0.036809],\n",
       " [17, 3, 0.17647058823529413, 0.07119571],\n",
       " [12, 2, 0.16666666666666666, 0.08845524],\n",
       " [13, 3, 0.23076923076923078, 0.10467198],\n",
       " [26, 5, 0.19230769230769232, 0.09298851],\n",
       " [27, 11, 0.4074074074074074, 0.06995413],\n",
       " [32, 11, 0.34375, 0.08455228],\n",
       " [28, 5, 0.17857142857142858, 0.16738418],\n",
       " [16, 3, 0.1875, 0.077685796],\n",
       " [12, 6, 0.5, 0.024810553],\n",
       " [33, 5, 0.15151515151515152, 0.18216376],\n",
       " [19, 6, 0.3157894736842105, 0.052915197],\n",
       " [26, 13, 0.5, 0.06299427],\n",
       " [26, 12, 0.46153846153846156, 0.06548421],\n",
       " [20, 8, 0.4, 0.044888385],\n",
       " [20, 5, 0.25, 0.17973381],\n",
       " [15, 6, 0.4, 0.0324132],\n",
       " [17, 4, 0.23529411764705882, 0.030510297],\n",
       " [9, 8, 0.8888888888888888, 0.012516283],\n",
       " [24, 5, 0.20833333333333334, 0.077744834],\n",
       " [26, 9, 0.34615384615384615, 0.09912589],\n",
       " [25, 3, 0.12, 0.08160434],\n",
       " [15, 5, 0.3333333333333333, 0.047693886],\n",
       " [24, 4, 0.16666666666666666, 0.105456054],\n",
       " [25, 5, 0.2, 0.09109967],\n",
       " [25, 9, 0.36, 0.06457103],\n",
       " [16, 5, 0.3125, 0.0545908],\n",
       " [9, 2, 0.2222222222222222, 0.07468562],\n",
       " [17, 6, 0.35294117647058826, 0.048220992],\n",
       " [16, 2, 0.125, 0.06825496],\n",
       " [19, 12, 0.631578947368421, 0.020754814],\n",
       " [15, 7, 0.4666666666666667, 0.02040595],\n",
       " [7, 3, 0.42857142857142855, 0.026485585],\n",
       " [4, 2, 0.5, 0.0435704],\n",
       " [17, 7, 0.4117647058823529, 0.027111813],\n",
       " [8, 2, 0.25, 0.022484185],\n",
       " [21, 5, 0.23809523809523808, 0.05690143],\n",
       " [28, 11, 0.39285714285714285, 0.084110506],\n",
       " [19, 9, 0.47368421052631576, 0.034367096],\n",
       " [17, 14, 0.8235294117647058, 0.022879979],\n",
       " [19, 6, 0.3157894736842105, 0.029176954],\n",
       " [32, 7, 0.21875, 0.03598325],\n",
       " [18, 2, 0.1111111111111111, 0.062376637],\n",
       " [20, 7, 0.35, 0.03530017],\n",
       " [30, 4, 0.13333333333333333, 0.08248954],\n",
       " [19, 4, 0.21052631578947367, 0.059431344],\n",
       " [20, 8, 0.4, 0.037462175],\n",
       " [15, 3, 0.2, 0.04182739],\n",
       " [19, 8, 0.42105263157894735, 0.024440441],\n",
       " [18, 8, 0.4444444444444444, 0.078148335],\n",
       " [18, 3, 0.16666666666666666, 0.10897335],\n",
       " [17, 3, 0.17647058823529413, 0.05767292],\n",
       " [27, 5, 0.18518518518518517, 0.06380792],\n",
       " [20, 4, 0.2, 0.101875655],\n",
       " [17, 4, 0.23529411764705882, 0.05731816],\n",
       " [28, 8, 0.2857142857142857, 0.09038827],\n",
       " [19, 6, 0.3157894736842105, 0.15505464],\n",
       " [18, 11, 0.6111111111111112, 0.016732123],\n",
       " [11, 2, 0.18181818181818182, 0.026494622],\n",
       " [25, 8, 0.32, 0.07244021],\n",
       " [28, 9, 0.32142857142857145, 0.05185881],\n",
       " [33, 6, 0.18181818181818182, 0.19980915],\n",
       " [12, 4, 0.3333333333333333, 0.04677729],\n",
       " [29, 3, 0.10344827586206896, 0.095328756],\n",
       " [20, 5, 0.25, 0.034946624],\n",
       " [18, 8, 0.4444444444444444, 0.03209324],\n",
       " [32, 12, 0.375, 0.045968365],\n",
       " [17, 5, 0.29411764705882354, 0.05439597],\n",
       " [18, 4, 0.2222222222222222, 0.06460909],\n",
       " [27, 7, 0.25925925925925924, 0.021464167],\n",
       " [13, 2, 0.15384615384615385, 0.07008423],\n",
       " [34, 9, 0.2647058823529412, 0.09868276],\n",
       " [12, 5, 0.4166666666666667, 0.06195885],\n",
       " [8, 7, 0.875, 0.027833782],\n",
       " [20, 3, 0.15, 0.05763616],\n",
       " [21, 5, 0.23809523809523808, 0.1294708],\n",
       " [20, 14, 0.7, 0.022608817],\n",
       " [19, 6, 0.3157894736842105, 0.078140035],\n",
       " [12, 3, 0.25, 0.037064575],\n",
       " [22, 4, 0.18181818181818182, 0.113541484],\n",
       " [17, 6, 0.35294117647058826, 0.08962483],\n",
       " [14, 4, 0.2857142857142857, 0.038198423],\n",
       " [17, 2, 0.11764705882352941, 0.03395318],\n",
       " [21, 9, 0.42857142857142855, 0.030893622],\n",
       " [21, 4, 0.19047619047619047, 0.17152487],\n",
       " [19, 13, 0.6842105263157895, 0.031375118]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(good_docs[3]['energies_per_step'])\n",
    "plt.show()\n",
    "plt.plot(good_docs[3]['distances_per_step'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, reduced, bad_docs, bad_result,good_docs,good_result = analysis(SDT_valid, docs_val, distance_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '% Reduced')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(reduced, bins=40)\n",
    "plt.title(\"Train\")\n",
    "plt.xlabel(\"% Reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'slab'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_train[0]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for doc in good_docs:\n",
    "    f.append(doc['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'surface': 228, 'slab': 367})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27353239056302664"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "natoms =[]\n",
    "types = []\n",
    "steps = []\n",
    "distances = []\n",
    "filtered_idx = []\n",
    "\n",
    "for doc in bad_docs:\n",
    "    natoms.append(doc['atoms']['natoms'])\n",
    "    types.extend(doc['atoms']['chemical_symbols'])\n",
    "    atoms = mongo.make_atoms_from_doc(doc, is_initial=True)\n",
    "    atoms_final = mongo.make_atoms_from_doc(doc, is_initial=False)\n",
    "    if atoms.constraints:\n",
    "        fixed_atom_idx = atoms.constraints[0].index\n",
    "        base = np.ones(len(atoms.positions))\n",
    "        base[fixed_atom_idx] = 0\n",
    "        free_atom_idx = np.where(base==1)[0]\n",
    "        \n",
    "    else:\n",
    "        free_atom_idx = np.arange(len(atoms))\n",
    "    difference = atoms.positions[free_atom_idx] - atoms_final.positions[free_atom_idx]\n",
    "    dist = np.sqrt(np.sum(difference**2, axis=1))\n",
    "    distances.append(dist)    \n",
    "    if np.mean(dist) > 0.05:\n",
    "        filtered_idx.append(doc['idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mean=[]\n",
    "for dist in distances:\n",
    "    d_mean.append(np.mean(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9., 5., 9., 3., 2., 2., 7., 8., 2., 4., 7., 4., 3., 2., 1., 1., 3.,\n",
       "        2., 1., 5., 3., 1., 1., 3., 1., 1., 1., 2., 0., 2., 0., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 2., 3., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.]),\n",
       " array([0.04009705, 0.04491276, 0.04972846, 0.05454417, 0.05935988,\n",
       "        0.06417559, 0.06899129, 0.073807  , 0.07862271, 0.08343841,\n",
       "        0.08825412, 0.09306983, 0.09788553, 0.10270124, 0.10751695,\n",
       "        0.11233266, 0.11714836, 0.12196407, 0.12677978, 0.13159548,\n",
       "        0.13641119, 0.1412269 , 0.14604261, 0.15085831, 0.15567402,\n",
       "        0.16048973, 0.16530543, 0.17012114, 0.17493685, 0.17975255,\n",
       "        0.18456826, 0.18938397, 0.19419968, 0.19901538, 0.20383109,\n",
       "        0.2086468 , 0.2134625 , 0.21827821, 0.22309392, 0.22790962,\n",
       "        0.23272533, 0.23754104, 0.24235675, 0.24717245, 0.25198816,\n",
       "        0.25680387, 0.26161957, 0.26643528, 0.27125099, 0.2760667 ,\n",
       "        0.2808824 ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(d_mean, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9., 5., 9., 3., 2., 2., 7., 8., 2., 4., 7., 4., 3., 2., 1., 1., 3.,\n",
       "        2., 1., 5., 3., 1., 1., 3., 1., 1., 1., 2., 0., 2., 0., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 2., 3., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.]),\n",
       " array([0.04009705, 0.04491276, 0.04972846, 0.05454417, 0.05935988,\n",
       "        0.06417559, 0.06899129, 0.073807  , 0.07862271, 0.08343841,\n",
       "        0.08825412, 0.09306983, 0.09788553, 0.10270124, 0.10751695,\n",
       "        0.11233266, 0.11714836, 0.12196407, 0.12677978, 0.13159548,\n",
       "        0.13641119, 0.1412269 , 0.14604261, 0.15085831, 0.15567402,\n",
       "        0.16048973, 0.16530543, 0.17012114, 0.17493685, 0.17975255,\n",
       "        0.18456826, 0.18938397, 0.19419968, 0.19901538, 0.20383109,\n",
       "        0.2086468 , 0.2134625 , 0.21827821, 0.22309392, 0.22790962,\n",
       "        0.23272533, 0.23754104, 0.24235675, 0.24717245, 0.25198816,\n",
       "        0.25680387, 0.26161957, 0.26643528, 0.27125099, 0.2760667 ,\n",
       "        0.2808824 ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(d_mean, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
