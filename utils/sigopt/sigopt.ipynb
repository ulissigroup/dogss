{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document demonstrates the making, training, saving, loading, and usage of a sklearn-compliant CGCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# sys.path.insert(0,'/home/junwoony/.local/lib/python3.6/site-packages')\n",
    "sys.path.insert(0,'../')\n",
    "import numpy as np\n",
    "#Select which GPU to use if necessary\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "import mongo\n",
    "# from torchviz import make_dot, make_dot_from_trace\n",
    "import time\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import pickle\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mongo\n",
    "# from cgcnn.data_icgcnn import StructureData, ListDataset, StructureDataTransformer\n",
    "from cgcnn.data_grad_surface import StructureData, ListDataset, StructureDataTransformer\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "import multiprocess as mp\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset as mongo docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pickle.load(open('../input/intermetallics_cleavage_energy_data.pkl', 'rb'))\n",
    "\n",
    "# random.seed(123)\n",
    "# random.shuffle(docs)\n",
    "for doc in docs:\n",
    "    doc[\"atoms\"] = doc['thinnest_structure']['atoms']\n",
    "    doc[\"results\"] = doc['thinnest_structure']['results']\n",
    "    doc[\"initial_configuration\"] = doc['thinnest_structure']['initial_configuration']\n",
    "    del doc[\"thinnest_structure\"]\n",
    "    \n",
    "SDT_list = pickle.load(open('../input/SDT_surface_new.pkl', 'rb'))\n",
    "structures = SDT_list[0]\n",
    "orig_atom_fea_len = structures[0].shape[-1]\n",
    "nbr_fea_len = structures[1].shape[-1]\n",
    "target_list = np.array([sdt[-1].numpy() for sdt in SDT_list]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3033 3033 3033\n"
     ]
    }
   ],
   "source": [
    "print(len(docs), len(SDT_list), len(target_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the size of the features from the data transformer, to be used in setting up the net model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "determine max connectivity value (for radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import mongo\n",
    "# from cgcnn.data import StructureData, ListDataset, StructureDataTransformer\n",
    "# import numpy as np\n",
    "# import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# SDT = StructureDataTransformer(atom_init_loc='/home/zulissi/software/cgcnn_sklearn/atom_init.json',\n",
    "#                               max_num_nbr=12,\n",
    "#                               step=0.2,\n",
    "#                               radius=1,\n",
    "#                               use_tag=False,\n",
    "#                               use_fixed_info=False)\n",
    "\n",
    "# SDT_out = SDT.transform(docs)\n",
    "\n",
    "# structures = SDT_out[0]\n",
    "# orig_atom_fea_len = structures[0].shape[-1]\n",
    "# nbr_fea_len = structures[1].shape[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 19\n"
     ]
    }
   ],
   "source": [
    "print(orig_atom_fea_len, nbr_fea_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CGCNN model with skorch to make it sklearn compliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from skorch.callbacks import Checkpoint, LoadInitState #needs skorch 0.4.0, conda-forge version at 0.3.0 doesn't cut it\n",
    "\n",
    "from cgcnn.data_grad_surface import collate_pool, MergeDataset\n",
    "from cgcnn.model_grad_2_surface_simple_sigopt import CrystalGraphConvNet\n",
    "from skorch import NeuralNetRegressor\n",
    "import torch\n",
    "import skorch.callbacks.base\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "if cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device='cpu'\n",
    "\n",
    "#Make a checkpoint to save parameters every time there is a new best for validation lost\n",
    "cp = Checkpoint(monitor='valid_loss_best',fn_prefix='valid_best_')\n",
    "\n",
    "#Callback to load the checkpoint with the best validation loss at the end of training\n",
    "\n",
    "class train_end_load_best_valid_loss(skorch.callbacks.base.Callback):\n",
    "    def on_train_end(self, net, X, y):\n",
    "        net.load_params('valid_best_params.pt')\n",
    "        \n",
    "load_best_valid_loss = train_end_load_best_valid_loss()\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example converting all the documents up front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Make the target list\n",
    "# import seaborn as sns\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# target_list = np.array(energies).reshape(-1,1)\n",
    "# sns.distplot(target_list, color='black')\n",
    "    \n",
    "# #scaler = StandardScaler().fit(energies.reshape(-1, 1))\n",
    "# scaler = MinMaxScaler().fit(energies.reshape(-1, 1))\n",
    "# target_list = scaler.transform(energies.reshape(-1,1))\n",
    "# print(type(target_list))\n",
    "\n",
    "# sns.distplot(target_list, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inversed_target_list = scaler.inverse_transform(target_list)\n",
    "# sns.distplot(inversed_target_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SDT_list= SDT_list\n",
    "target_list = target_list\n",
    "\n",
    "indices = np.arange(len(SDT_list))\n",
    "SDT_training, SDT_test, target_training, target_test, train_idx, test_idx \\\n",
    "= train_test_split(SDT_list, target_list, indices, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.dataset import CVSplit\n",
    "from skorch.callbacks.lr_scheduler import WarmRestartLR, LRScheduler\n",
    "from adamwr.adamw import AdamW\n",
    "from torch.optim.lbfgs import LBFGS\n",
    "\n",
    "from adamwr.cosine_scheduler import CosineLRWithRestarts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_test_splitter = ShuffleSplit(test_size=0.25, random_state=42)\n",
    "\n",
    "# batchsize = (10,300)\n",
    "# # warm restart scheduling from https://arxiv.org/pdf/1711.05101.pdf\n",
    "# LR_schedule = LRScheduler(CosineLRWithRestarts, batch_size=batchsize, epoch_size=len(SDT_training), restart_period=10, t_mult=1.2)\n",
    "LR_schedule = LRScheduler('MultiStepLR',milestones=[100],gamma=0.1)\n",
    "\n",
    "#############\n",
    "# To extract intermediate features, set the forward takes only the first return value to calculate loss\n",
    "class MyNet(NeuralNetRegressor):\n",
    "    def get_loss(self, y_pred, y_true, **kwargs):        \n",
    "        y_pred = y_pred[0] if isinstance(y_pred, tuple) else y_pred  # discard the 2nd output\n",
    "        differ=torch.sum((y_pred-y_true.cuda())**2.0,dim=1)\n",
    "        if torch.nonzero(differ).shape[0] != differ.shape[0]:\n",
    "            print('zero sqrt for Loss')\n",
    "#             zero_idx = (differ == 0).nonzero()\n",
    "#             differ[zero_idx] = 1e-6\n",
    "        differ = torch.clamp(differ, min=1e-8)\n",
    "        return torch.mean(torch.sqrt(differ))\n",
    "#         return torch.mean(torch.sqrt(torch.sum((y_pred-y_true.cuda())**2.0,dim=1)))\n",
    "#         return super().get_loss(y_pred, y_true, **kwargs)\n",
    "## return features = net.forward(SDT_test)\n",
    "\n",
    "\n",
    "net = MyNet(\n",
    "    CrystalGraphConvNet,\n",
    "    module__orig_atom_fea_len = orig_atom_fea_len,\n",
    "    module__nbr_fea_len = nbr_fea_len,\n",
    "#     module__angle_fea_len = 8, #angle_fea_len,\n",
    "    batch_size=(10,300), #214\n",
    "    module__classification=False,\n",
    "    lr=(np.exp(-15),np.exp(-3)),\n",
    "    max_epochs= (50, 800),\n",
    "    module__atom_fea_len=(4,256), #46,\n",
    "    module__h_fea_len=(32, 256),\n",
    "    module__n_conv=(1,10), #8\n",
    "    module__n_h=(1,10),\n",
    "    module__max_num_nbr=12, #9\n",
    "    module__opt_step_size=(0.01, 0.9), #0.3\n",
    "    module__min_opt_steps=30,\n",
    "    module__max_opt_steps=300,\n",
    "    module__momentum=(0.1,0.9),\n",
    "    module__dropout=(0, 0.3),\n",
    "    module__dropout_h=(0, 0.3),\n",
    "    optimizer__weight_decay=(1e-6, 1e-2),\n",
    "    optimizer=AdamW,\n",
    "    iterator_train__pin_memory=True,\n",
    "    iterator_train__num_workers=0,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__collate_fn = collate_pool,\n",
    "    iterator_valid__pin_memory=True,\n",
    "    iterator_valid__num_workers=0,\n",
    "    iterator_valid__collate_fn = collate_pool,\n",
    "    device=device,\n",
    "#     criterion=torch.nn.MSELoss,\n",
    "    criterion=torch.nn.L1Loss,\n",
    "    dataset=MergeDataset,\n",
    "    train_split = CVSplit(cv=train_test_splitter),\n",
    "    callbacks=[cp, LR_schedule, load_best_valid_loss] #    callbacks=[cp, load_best_valid_loss, LR_schedule]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sigopt_sklearn.search import SigOptSearchCV\n",
    "from sklearn.metrics import get_scorer\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "client_token = \"TSRIPFKLRAIMUDDVQEBJHVBQRVBCDJOSKJMKEQTXWCYZDNED\"\n",
    "net_parameters = {\n",
    "                'batch_size':(10,300),\n",
    "                'lr':(np.exp(-15),np.exp(-3)),\n",
    "                'max_epochs': (50, 800),\n",
    "                'module__atom_fea_len':(4,256), #46,\n",
    "                'module__h_fea_len':(32, 256),\n",
    "                'module__n_conv':(1,10), #8\n",
    "                'module__n_h':(1,10),\n",
    "                'module__opt_step_size':(0.01, 0.9), #0.3\n",
    "                'module__momentum':(0, 0.9),\n",
    "                'module__dropout':(0, 0.3),\n",
    "                'module__dropout_h':(0, 0.3),\n",
    "                'optimizer__weight_decay':(1e-6, 1e-2)\n",
    "                }\n",
    "\n",
    "clf = SigOptSearchCV(net, net_parameters, cv=train_test_splitter, client_token=client_token,\n",
    "                    n_jobs=1, n_iter=50, scoring=get_scorer('neg_mean_absolute_error'))\n",
    "\n",
    "len(net_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp     dur\n",
      "-------  ------------  ------------  ----  ------\n",
      "      1        \u001b[36m0.6802\u001b[0m        \u001b[32m1.2459\u001b[0m     +  5.0623\n",
      "      2        \u001b[36m0.3004\u001b[0m        \u001b[32m0.7220\u001b[0m     +  15.4242\n",
      "      3        0.5135        \u001b[32m0.1931\u001b[0m     +  15.6274\n",
      "      4        \u001b[36m0.1544\u001b[0m        \u001b[32m0.1553\u001b[0m     +  15.8103\n",
      "      5        \u001b[36m0.1467\u001b[0m        \u001b[32m0.1508\u001b[0m     +  15.9345\n",
      "      6        0.1494        0.1517        15.7745\n",
      "      7        0.1501        0.1521        15.6667\n",
      "      8        0.1478        0.1523        15.6091\n",
      "      9        0.1505        0.1523        15.6403\n",
      "     10        0.1565        0.1523        15.6972\n",
      "     11        0.1515        0.1523        15.7942\n",
      "     12        0.1501        0.1522        15.6900\n",
      "     13        0.1496        0.1521        15.8961\n",
      "     14        0.1489        0.1520        15.7871\n",
      "     15        0.1497        0.1518        15.6850\n",
      "     16        0.1484        0.1515        15.6130\n",
      "     17        0.1482        0.1512        15.7637\n",
      "     18        0.1517        \u001b[32m0.1508\u001b[0m     +  15.6651\n",
      "     19        0.1485        \u001b[32m0.1502\u001b[0m     +  15.7313\n",
      "     20        \u001b[36m0.1449\u001b[0m        \u001b[32m0.1492\u001b[0m     +  15.8679\n",
      "     21        0.1472        \u001b[32m0.1476\u001b[0m     +  15.7366\n",
      "     22        \u001b[36m0.1436\u001b[0m        \u001b[32m0.1456\u001b[0m     +  15.7367\n",
      "     23        \u001b[36m0.1395\u001b[0m        \u001b[32m0.1449\u001b[0m     +  15.6854\n",
      "     24        0.1474        \u001b[32m0.1442\u001b[0m     +  15.6504\n",
      "     25        0.1399        \u001b[32m0.1431\u001b[0m     +  15.6740\n",
      "     26        0.1437        \u001b[32m0.1425\u001b[0m     +  15.7847\n",
      "     27        0.1399        \u001b[32m0.1419\u001b[0m     +  15.7299\n",
      "     28        \u001b[36m0.1385\u001b[0m        0.1419        15.7665\n",
      "     29        \u001b[36m0.1373\u001b[0m        \u001b[32m0.1411\u001b[0m     +  15.8599\n",
      "     30        0.1378        \u001b[32m0.1407\u001b[0m     +  15.6811\n",
      "     31        \u001b[36m0.1373\u001b[0m        \u001b[32m0.1403\u001b[0m     +  15.6658\n",
      "     32        0.1423        \u001b[32m0.1399\u001b[0m     +  15.6430\n",
      "     33        \u001b[36m0.1362\u001b[0m        \u001b[32m0.1397\u001b[0m     +  15.6868\n",
      "     34        0.1366        \u001b[32m0.1391\u001b[0m     +  15.8221\n",
      "     35        \u001b[36m0.1356\u001b[0m        \u001b[32m0.1390\u001b[0m     +  15.9066\n",
      "     36        0.1359        \u001b[32m0.1386\u001b[0m     +  15.7142\n",
      "     37        \u001b[36m0.1350\u001b[0m        0.1389        15.6980\n",
      "     38        \u001b[36m0.1341\u001b[0m        \u001b[32m0.1381\u001b[0m     +  15.6899\n",
      "     39        0.1344        \u001b[32m0.1380\u001b[0m     +  15.7405\n",
      "     40        \u001b[36m0.1336\u001b[0m        0.1382        15.6360\n",
      "     41        0.1343        \u001b[32m0.1374\u001b[0m     +  15.7767\n",
      "     42        \u001b[36m0.1325\u001b[0m        0.1374        15.8585\n",
      "     43        0.1404        \u001b[32m0.1373\u001b[0m     +  15.7273\n",
      "     44        0.1341        \u001b[32m0.1369\u001b[0m     +  15.6527\n",
      "     45        0.1338        \u001b[32m0.1368\u001b[0m     +  15.6968\n",
      "     46        \u001b[36m0.1242\u001b[0m        \u001b[32m0.1365\u001b[0m     +  15.7205\n",
      "     47        0.1322        0.1367        15.7175\n",
      "     48        0.1326        \u001b[32m0.1361\u001b[0m     +  15.7077\n",
      "     49        0.1328        0.1362        15.7891\n",
      "     50        0.1339        0.1366        15.6908\n",
      "     51        0.1324        0.1363        15.7093\n",
      "     52        0.1319        \u001b[32m0.1360\u001b[0m     +  15.7071\n",
      "     53        0.1349        \u001b[32m0.1355\u001b[0m     +  15.8137\n",
      "     54        0.1307        0.1358        15.6536\n",
      "     55        0.1310        0.1359        15.7451\n",
      "     56        0.1317        0.1362        15.9247\n",
      "     57        0.1310        \u001b[32m0.1354\u001b[0m     +  15.6891\n",
      "     58        0.1297        0.1354        15.6041\n",
      "     59        0.1316        0.1354        15.7356\n",
      "     60        0.1301        \u001b[32m0.1354\u001b[0m     +  15.6720\n",
      "     61        0.1421        \u001b[32m0.1351\u001b[0m     +  15.7460\n",
      "     62        0.1289        0.1360        15.7361\n",
      "     63        0.1296        \u001b[32m0.1350\u001b[0m     +  16.0249\n",
      "     64        0.1310        0.1354        15.7749\n",
      "     65        0.1297        \u001b[32m0.1344\u001b[0m     +  15.7436\n",
      "     66        0.1300        0.1346        15.7831\n",
      "     67        0.1300        0.1351        15.7266\n",
      "     68        0.1266        0.1346        15.7169\n",
      "     69        0.1286        \u001b[32m0.1344\u001b[0m     +  15.6682\n",
      "     70        0.1288        \u001b[32m0.1341\u001b[0m     +  15.6847\n",
      "     71        0.1314        0.1344        15.8076\n",
      "     72        0.1271        \u001b[32m0.1338\u001b[0m     +  15.8612\n",
      "     73        0.1287        0.1344        15.8623\n",
      "     74        0.1281        \u001b[32m0.1337\u001b[0m     +  15.7177\n",
      "     75        0.1275        0.1347        15.7074\n",
      "     76        0.1268        \u001b[32m0.1335\u001b[0m     +  15.6964\n",
      "     77        0.1267        0.1343        15.8478\n",
      "     78        0.1297        0.1346        15.6647\n",
      "     79        0.1264        0.1343        15.7096\n",
      "     80        0.1294        0.1337        15.7550\n",
      "     81        0.1288        0.1337        15.8119\n",
      "     82        0.1265        \u001b[32m0.1329\u001b[0m     +  15.7112\n",
      "     83        0.1254        0.1331        15.7509\n",
      "     84        0.1259        0.1330        15.9451\n",
      "     85        0.1274        0.1333        15.7568\n",
      "     86        0.1297        \u001b[32m0.1329\u001b[0m     +  15.7084\n",
      "     87        0.1253        0.1339        15.7430\n",
      "     88        0.1249        0.1335        15.6593\n",
      "     89        0.1260        0.1339        15.8886\n",
      "     90        0.1283        \u001b[32m0.1324\u001b[0m     +  15.7017\n",
      "     91        0.1267        0.1329        15.8026\n",
      "     92        0.1244        0.1332        15.7461\n",
      "     93        \u001b[36m0.1168\u001b[0m        0.1331        15.7332\n",
      "     94        0.1240        0.1328        15.7397\n",
      "     95        0.1249        0.1331        15.7855\n",
      "     96        0.1238        0.1325        15.8990\n",
      "     97        0.1235        0.1327        15.7341\n",
      "     98        0.1236        \u001b[32m0.1322\u001b[0m     +  15.8382\n",
      "     99        0.1244        0.1330        15.7230\n",
      "    100        0.1226        \u001b[32m0.1319\u001b[0m     +  15.6942\n",
      "    101        0.1221        0.1320        15.8176\n",
      "    102        0.1210        0.1322        15.5669\n",
      "    103        0.1212        0.1320        15.6594\n",
      "    104        0.1209        \u001b[32m0.1319\u001b[0m     +  15.8944\n",
      "    105        \u001b[36m0.1153\u001b[0m        0.1320        15.7022\n",
      "    106        0.1219        \u001b[32m0.1318\u001b[0m     +  15.7414\n",
      "    107        0.1207        \u001b[32m0.1316\u001b[0m     +  15.9001\n",
      "    108        0.1198        0.1318        15.7865\n",
      "    109        0.1202        0.1317        15.8065\n",
      "    110        0.1158        0.1317        15.8538\n",
      "    111        0.1213        0.1318        15.7752\n",
      "    112        0.1200        0.1318        15.8498\n",
      "    113        0.1207        0.1321        15.9178\n",
      "    114        0.1203        0.1320        15.7682\n",
      "    115        0.1199        0.1318        15.7453\n",
      "    116        0.1191        0.1318        15.7624\n",
      "    117        0.1194        0.1319        15.7019\n",
      "    118        0.1212        0.1318        15.7081\n",
      "    119        0.1201        0.1319        15.7198\n",
      "    120        0.1220        0.1319        15.6787\n",
      "    121        0.1193        0.1318        15.7466\n",
      "    122        0.1201        0.1319        15.7455\n",
      "    123        0.1180        0.1320        15.6359\n",
      "    124        0.1202        0.1321        15.6366\n",
      "    125        0.1213        0.1317        15.8646\n",
      "    126        0.1207        0.1318        15.7667\n",
      "    127        0.1187        0.1322        15.8681\n",
      "    128        0.1212        0.1322        15.8305\n",
      "    129        0.1260        0.1322        15.7907\n",
      "    130        0.1262        \u001b[32m0.1314\u001b[0m     +  15.6149\n",
      "    131        0.1200        0.1316        15.8072\n",
      "    132        \u001b[36m0.1109\u001b[0m        0.1316        15.5977\n",
      "    133        0.1187        0.1316        15.7422\n",
      "    134        0.1183        0.1321        15.7402\n",
      "    135        0.1176        0.1318        15.7654\n",
      "    136        0.1168        0.1322        15.7219\n",
      "    137        0.1186        0.1325        15.7930\n",
      "    138        0.1200        0.1329        15.6767\n",
      "    139        0.1280        0.1322        15.6833\n",
      "    140        0.1207        0.1318        15.7546\n",
      "    141        0.1160        0.1323        15.8022\n",
      "    142        0.1189        0.1321        15.8010\n",
      "    143        0.1187        0.1322        15.8498\n",
      "    144        0.1226        0.1322        15.7122\n",
      "    145        0.1181        0.1323        15.7032\n",
      "    146        0.1138        0.1322        15.6941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    147        0.1194        0.1318        15.7032\n",
      "    148        0.1191        0.1319        15.7323\n",
      "    149        0.1177        0.1327        15.7728\n",
      "    150        0.1187        0.1327        15.7308\n",
      "    151        0.1186        0.1327        15.7951\n",
      "    152        0.1194        0.1327        15.9803\n",
      "    153        0.1176        0.1328        15.7441\n",
      "    154        0.1182        0.1332        15.7614\n",
      "    155        0.1253        0.1328        15.7473\n",
      "    156        0.1183        0.1317        15.6710\n",
      "    157        0.1180        0.1324        15.8182\n",
      "    158        0.1194        0.1322        15.8515\n",
      "    159        0.1136        0.1328        15.7835\n",
      "    160        0.1190        0.1323        15.8576\n",
      "    161        0.1150        0.1325        15.8225\n",
      "    162        0.1158        0.1326        15.7819\n",
      "    163        0.1175        0.1324        15.6516\n",
      "    164        0.1161        0.1315        15.6828\n",
      "    165        0.1172        0.1323        15.8302\n",
      "    166        0.1169        \u001b[32m0.1313\u001b[0m     +  15.7155\n",
      "    167        0.1166        0.1319        15.5769\n",
      "    168        0.1118        0.1326        15.5701\n",
      "    169        0.1167        0.1321        15.7715\n",
      "    170        0.1172        0.1316        15.7937\n",
      "    171        0.1172        0.1327        15.7449\n",
      "    172        0.1161        0.1320        15.7099\n",
      "    173        0.1158        0.1317        15.6780\n",
      "    174        0.1180        0.1321        15.7165\n",
      "    175        0.1206        0.1317        15.6457\n",
      "    176        0.1162        0.1332        15.7543\n",
      "    177        0.1167        0.1319        15.7015\n",
      "    178        0.1171        0.1324        15.6161\n",
      "    179        0.1176        \u001b[32m0.1313\u001b[0m     +  15.8774\n",
      "    180        0.1242        0.1314        15.8229\n",
      "    181        0.1157        0.1314        15.8068\n",
      "    182        0.1159        0.1319        15.7480\n",
      "    183        0.1154        0.1317        15.8290\n",
      "    184        0.1173        0.1322        15.7600\n",
      "    185        0.1144        0.1318        15.8072\n",
      "    186        0.1158        0.1327        15.6868\n",
      "    187        0.1129        0.1324        15.6944\n",
      "    188        0.1153        0.1318        15.8841\n",
      "    189        0.1159        0.1323        15.6996\n",
      "    190        0.1156        0.1328        15.6920\n",
      "    191        0.1151        0.1316        15.7828\n",
      "    192        0.1168        0.1315        15.7161\n",
      "    193        0.1146        0.1320        15.7653\n",
      "    194        0.1155        \u001b[32m0.1313\u001b[0m     +  15.6656\n",
      "    195        0.1146        \u001b[32m0.1307\u001b[0m     +  15.7454\n",
      "    196        0.1137        0.1313        15.7512\n",
      "    197        0.1127        0.1313        15.7738\n",
      "    198        0.1144        0.1312        15.7170\n",
      "    199        0.1145        0.1326        15.7187\n",
      "    200        0.1136        0.1316        15.7866\n",
      "    201        0.1137        0.1317        15.6783\n",
      "    202        0.1135        0.1323        15.7863\n",
      "    203        \u001b[36m0.1100\u001b[0m        \u001b[32m0.1304\u001b[0m     +  15.7870\n",
      "    204        0.1143        0.1318        15.7585\n",
      "    205        \u001b[36m0.1084\u001b[0m        0.1305        15.7017\n",
      "    206        0.1135        0.1307        15.8404\n",
      "    207        0.1134        0.1306        15.7315\n",
      "    208        0.1126        0.1309        15.7642\n",
      "    209        0.1136        0.1314        15.9249\n",
      "    210        0.1131        0.1314        15.6873\n",
      "    211        0.1170        0.1306        15.8126\n",
      "    212        0.1137        \u001b[32m0.1297\u001b[0m     +  15.6199\n",
      "    213        0.1146        0.1302        15.7033\n",
      "    214        0.1121        0.1300        15.7064\n",
      "    215        0.1136        0.1302        15.7371\n",
      "    216        0.1130        0.1298        15.7405\n",
      "    217        0.1138        0.1300        15.8289\n",
      "    218        0.1117        \u001b[32m0.1289\u001b[0m     +  15.8482\n",
      "    219        0.1146        0.1299        15.6345\n",
      "    220        0.1127        0.1293        15.6841\n",
      "    221        0.1121        0.1301        15.7598\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [607, 9211]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-dc91ee164eb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSDT_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/sigopt_sklearn/search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munsupervised\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \"\"\"\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/sigopt_sklearn/search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable, **fit_params)\u001b[0m\n\u001b[1;32m    377\u001b[0m                                             \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                                             error_score=self.error_score)\n\u001b[0;32m--> 379\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_configs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m                         for train, test in cv_iter)\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/joblib-0.14.1.dev0-py3.7.egg/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/joblib-0.14.1.dev0-py3.7.egg/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/joblib-0.14.1.dev0-py3.7.egg/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/joblib-0.14.1.dev0-py3.7.egg/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/joblib-0.14.1.dev0-py3.7.egg/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/joblib-0.14.1.dev0-py3.7.egg/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/joblib-0.14.1.dev0-py3.7.egg/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m---> 98\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \"\"\"\n\u001b[1;32m    169\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 170\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     output_errors = np.average(np.abs(y_pred - y_true),\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/schnet2/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [607, 9211]"
     ]
    }
   ],
   "source": [
    "clf.fit(SDT_training, target_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.174629324546952"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9211/607"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-baba530bc70f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "clf.best_params_, clf.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size\t74\n",
    "lr\t0.010390047081273095\n",
    "max_epochs\t272\n",
    "module__atom_fea_len\t82\n",
    "module__h_fea_len\t120\n",
    "module__n_conv\t4\n",
    "module__n_h\t3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
